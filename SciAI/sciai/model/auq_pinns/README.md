ENGLISH | [简体中文](README_CN.md)

# Contents

- [Adversarial Uncertainty Quantification PINNs Description](#adversarial-uncertainty-quantification-PINNs-description)
- [Dataset](#dataset)
- [Environment Requirements](#environment-requirements)
- [Quick Start](#quick-start)
- [Script Description](#script-description)
    - [Script and Sample Code](#script-and-sample-code)
    - [Script Parameters](#script-parameters)
    - [Training Process](#training-process)
    - [Evaluation Process](#evaluation-process)

## [Adversarial Uncertainty Quantification PINNs Description](#contents)

This model reproduces a deep learning framework for quantifying and propagating uncertainty in systems governed by
non-linear differential equations using physics-informed neural networks.
Specifically, the model employs latent variable models to construct probabilistic representations for the system states,
and put forth an adversarial inference procedure for training them on data, while constraining their predictions to
satisfy given physical laws expressed by partial differential equations.
This provides a flexible framework for characterizing uncertainty in the outputs of physical systems.

> [paper](https://www.sciencedirect.com/science/article/pii/S0021999119303584):
> Yibo Yang, Paris Perdikaris, Adversarial uncertainty quantification in physics-informed neural networks, Journal of
> Computational Physics, 2019, ISSN 0021-9991

## [Dataset](#contents)

For the training process, the training dataset is generated during runtime. No extra data is necessary.
The validation data and pretrained checkpoint files will be downloaded automatically at the first launch.

The size of training dataset is controlled by parameter `n_col` and `n_bound` in `config.yaml`,
and by default is 100 and 20, respectively.

For validation process, the outputs, which are obtained numerically by Monte-Carlo method w.r.t the stochastic latent
variable with the same distribution, are provided in file `./data/ODE2000.mat`.

- Dataset size
    - U: (2000, 201) in [-1, 1]

If you need to download the validation dataset or checkpoint files manually,
please visit [this link](https://download.mindspore.cn/mindscience/SciAI/sciai/model/auq_pinns/).

## [Environment Requirements](#contents)

- Hardware(Ascend/GPU)
    - Prepare hardware environment with Ascend or GPU processor.
- Framework
    - [MindSpore](https://www.mindspore.cn/install/en)
- For more information, please check the resources below:
    - [MindSpore Tutorials](https://www.mindspore.cn/tutorials/en/master/index.html)
    - [MindSpore Python API](https://www.mindspore.cn/docs/en/master/index.html)

## [Quick Start](#contents)

After installing MindSpore via the official website and the required [dataset](#dataset) above, you can start training
and evaluation as follows:

- running on Ascend or on GPU

Default:

```bash
python train.py
```

Full command:

```bash
python train.py \
    --layers_p 2 50 50 50 50 1 \
    --layers_q 2 50 50 50 50 1 \
    --layers_t 2 50 50 1 \
    --print_interval 100 \
    --save_fig true \
    --save_ckpt true \
    --load_ckpt false \
    --save_ckpt_path ./checkpoints \
    --load_ckpt_path \
        ./checkpoints/discriminator/model_iter_30000_float32.ckpt \
        ./checkpoints/generator/model_iter_150000_float32.ckpt \
    --ckpt_interval 400 \
    --figures_path ./figures \
    --load_data_path ./data \
    --log_path ./logs \
    --lam 1.5 \
    --beta 1 \
    --n_col 100 \
    --n_bound 20 \
    --epochs 30001 \
    --lr 1e-4 \
    --term_t 1 \
    --term_kl 5 \
    --download_data auq_pinns \
    --force_download false \
    --amp_level O2 \
    --device_id 0 \
    --mode 0
```

## [Script Description](#contents)

### [Script and Sample Code](#contents)

```text
├── auq_pinns
│   ├── checkpoints                # checkpoints files
│   ├── data                       # data files
│   │   └── ODE2000.mat            # results generated by Monte-Carlo, for validation
│   ├── figures                    # plot figures
│   ├── logs                       # log files
│   ├── src                        # source codes
│   │   ├── network.py             # network architecture
│   │   ├── plot.py                # plotting results
│   │   └── process.py             # data process
│   ├── config.yaml                # hyper-parameters configuration
│   ├── README.md                  # English model descriptions
│   ├── README_CN.md               # Chinese model description
│   ├── train.py                   # python training script
│   └── eval.py                    # python evaluation script
```

### [Script Parameters](#contents)

Important parameters in `train.py` are as follows:

| parameter      | description                                    | default value                                                                                                         |
|----------------|------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|
| layers_p       | decoder neural network widths                  | 2 50 50 50 50 1                                                                                                       |
| layers_q       | encoder neural network widths                  | 2 50 50 50 50 1                                                                                                       |
| layers_t       | discriminator neural network widths            | 2 50 50 1                                                                                                             |
| print_interval | interval for loss printing                     | 100                                                                                                                   |
| save_fig       | whether save and plot figures or not           | true                                                                                                                  |
| save_ckpt      | whether save checkpoint or not                 | true                                                                                                                  |
| load_ckpt      | whether load checkpoint or not                 | false                                                                                                                 |
| save_ckpt_path | checkpoint saving path                         | ./checkpoints                                                                                                         |
| load_ckpt_path | checkpoint loading path                        | ./checkpoints/discriminator/model_iter_30000_float32.ckpt <br/>./checkpoints/generator/model_iter_150000_float32.ckpt |
| ckpt_interval  | interval for saving checkpoint file            | 400                                                                                                                   |
| figures_path   | figures saving path                            | ./figures                                                                                                             |
| load_data_path | path to load validation data                   | ./data                                                                                                                |
| log_path       | log saving path                                | ./logs                                                                                                                |
| lam            | generator loss coefficient                     | 1.5                                                                                                                   |
| beta           | pde loss coefficient                           | 1                                                                                                                     |
| n_col          | number of collocation training data            | 100                                                                                                                   |
| n_bound        | number of boundary training data               | 20                                                                                                                    |
| epochs         | number of training epochs                      | 30001                                                                                                                 |
| lr             | learning rate                                  | 1e-4                                                                                                                  |
| term_t         | training times for discriminator in each epoch | 1                                                                                                                     |
| term_kl        | training times for generator in each epoch     | 5                                                                                                                     |
| download_data  | necessary dataset and/or checkpoints           | auq_pinns                                                                                                             |
| force_download | whether download the dataset or not by force   | false                                                                                                                 |
| amp_level      | MindSpore auto mixed precision level           | O2                                                                                                                    |
| device_id      | device id to set                               | None                                                                                                                  |
| mode           | MindSpore Graph mode(0) or Pynative mode(1)    | 0                                                                                                                     |

### [Training Process](#contents)

- running on GPU/Ascend

  ```bash
  python train.py
  ```

  The loss values during training will be printed in the console, which can also be inspected after training in log
  file.

  ```bash
  # grep "G_loss:" log
  step: 0, G_loss: 56.84, KL_loss: -0.00947, recon_loss: 0.6465, pde_loss: 56.22, interval: 30.575496435165405s, total: 30.575496435165405s
  step: 100, G_loss: 35.56, KL_loss: 0.00891, recon_loss: 0.2842, pde_loss: 35.28, interval: 0.31897568702697754s, total: 30.894472122192383s
  step: 200, G_loss: 12.83, KL_loss: 0.10864, recon_loss: 0.5396, pde_loss: 12.18, interval: 0.2951545715332031s, total: 31.189626693725586s
  step: 300, G_loss: 10.03, KL_loss: 0.1841, recon_loss: 0.393, pde_loss: 9.45, interval: 0.28347206115722656s, total: 31.473098754882812s
  step: 400, G_loss: 8.9, KL_loss: 0.2262, recon_loss: 0.3416, pde_loss: 8.33, interval: 0.28740811347961426s, total: 31.760506868362427s
  step: 500, G_loss: 6.773, KL_loss: 0.2179, recon_loss: 0.4636, pde_loss: 6.094, interval: 0.28986334800720215s, total: 32.05037021636963s
  step: 600, G_loss: 3.385, KL_loss: -0.09106, recon_loss: 0.4062, pde_loss: 3.07, interval: 0.289898157119751s, total: 32.34026837348938s
  step: 700, G_loss: 1.025, KL_loss: -0.254, recon_loss: 0.3726, pde_loss: 0.9067, interval: 0.28998303413391113s, total: 32.63025140762329s
  ...
  ```

- After training, you can still review the training process through the log file saved in `log_path`, `./logs` directory
  by default.

- The model checkpoint will be saved in `save_ckpt_path`, `./checkpoint` directory by default.

### [Evaluation Process](#contents)

Before running the command below, please check the checkpoint loading path `load_ckpt_path` specified
in `config.yaml` for evaluation.

- running on GPU/Ascend

  ```bash
  python eval.py
  ```

  You can view the process and results through the `log_path`, `./logs` by default.
  The result pictures are saved in `figures_path`, [`./figures`](./figures) by default.