ENGLISH | [简体中文](README_CN.md)

# Contents

- [Forward-Backward Stochastic Neural Networks](#forward-backward-stochastic-neural-networks)
- [Dataset](#dataset)
- [Environment Requirements](#environment-requirements)
- [Quick Start](#quick-start)
- [Script Description](#script-description)
    - [Script and Sample Code](#script-and-sample-code)
    - [Script Parameters](#script-parameters)
    - [Training Process](#training-process)
    - [Evaluation Process](#evaluation-process)

## [Forward-Backward Stochastic Neural Networks](#contents)

Classical numerical methods for solving partial differential equations (PDEs) are known to be suffered from
the curse of dimensionality, due to their reliance on meticulously generated spatio-temporal grids.
Inspired by modern deep learning based techniques for solving forward and inverse problems associated with PDEs,
Raissi approximates the unknown solution by a deep neural network and leverages the well-known connection between
high-dimensional partial differential equations and forward-backward stochastic differential equations.

In this repository, the algorithm of Raissi is reproduced with Black-Scholes-Barenblatt equation in 100D and
Allen-Cahn equation in 20D.

> [paper](https://arxiv.org/abs/1804.07010):
> Raissi, Maziar. Forward-Backward Stochastic Neural Networks: Deep Learning of High-dimensional Partial Differential
> Equations. ArXiv preprint arXiv:1804.07010 (2018).

## [Dataset](#contents)

The training data is generated by `fetch_minibatch` in `class Problem`,
and the dimension is controlled by following parameters in `config.yaml`:

- batch_size (m): number of trajectories
- num_snapshots (n): number of time snapshots
- layers[0] (dim): number of dimensions

The generated training data:

- t: (m, n+1, 1)
- w: (m, n+1, dim-1)

The pretrained checkpoint files will be downloaded automatically at the first launch.
If you need to download the checkpoint files manually,
please visit [this link](https://download.mindspore.cn/mindscience/SciAI/sciai/model/fbsnns/).

## [Environment Requirements](#contents)

- Hardware(Ascend/GPU)
    - Prepare hardware environment with Ascend or GPU processor.
- Framework
    - [MindSpore](https://www.mindspore.cn/install/en)
- For more information, please check the resources below:
    - [MindSpore Tutorials](https://www.mindspore.cn/tutorials/en/master/index.html)
    - [MindSpore Python API](https://www.mindspore.cn/docs/en/master/index.html)

## [Quick Start](#contents)

After installing MindSpore via the official website, you can start training and evaluation as follows:

- running on Ascend or on GPU

```bash
python train.py
```

A full command for AllenCahn20D case is as follows:

```bash
python train.py \
    --problem allen_cahn_20D \
    --layers 21 256 256 256 256 1 \
    --save_ckpt true \
    --load_ckpt false \
    --save_fig true \
    --save_ckpt_path ./checkpoints/ac \
    --load_ckpt_path ./checkpoints/ac/model_100000_float16.ckpt \
    --figures_path ./figures/ac \
    --lr 1e-3 1e-4 1e-5 1e-6 \
    --epochs 20000 30000 30000 20000 \
    --batch_size 100 \
    --num_snapshots 15 \
    --terminal_time 0.3 \
    --log_path ./logs/ac \
    --download_data fbsnns \
    --force_download false \
    --amp_level O3 \
    --device_id 0 \
    --mode 0
```

If you want to run full command for BlackScholesBarenblatt100D case, please change the `problem` field in `config.yaml`.

## [Script Description](#contents)

### [Script and Sample Code](#contents)

File structures are as follows:

```text
├── fbsnns
│   ├── checkpoints                               # checkpoints files
│   ├── data                                      # data files
│   ├── figures                                   # plot figures
│   ├── logs                                      # log files
│   ├── src                                       # source codes
│   │   ├── allen_cahn_20d.py                     # problem case AllenChan20D
│   │   ├── black_scholes_barenblatt_100_d.py     # problem case BlackScholesBarenblatt100D
│   │   ├── problem.py                            # definition for problem base
│   │   ├── network.py                            # neural network definition
│   │   └── utils.py                              # methods for some common patterns
│   ├── config.yaml                               # hyper-parameters configuration
│   ├── README.md                                 # English model descriptions
│   ├── README_CN.md                              # Chinese model description
│   ├── train.py                                  # python training script
│   └── eval.py                                   # python evaluation script
```

### [Script Parameters](#contents)

There are two problem cases. In `config.yaml` or command parameter, the case can be chosen by the parameter `problem`.

| parameter | description                                                                    | default value  |
|-----------|--------------------------------------------------------------------------------|----------------|
| problem   | problem case to be solved, `allen_cahn_20D` or `black_scholes_barenblatt_100D` | allen_cahn_20D |

For each problem case, the parameters are as follows:

| parameter      | description                                  | default value                                     |
|----------------|----------------------------------------------|---------------------------------------------------|
| layers         | layer-wise width                             | 21 256 256 256 256 1                              |
| save_ckpt      | whether save checkpoint or not               | true                                              |
| save_fig       | whether save and plot figures or not         | true                                              |
| load_ckpt      | whether load checkpoint or not               | false                                             |
| save_ckpt_path | checkpoint saving path                       | ./checkpoints/[problem]                           |
| load_ckpt_path | checkpoint loading path                      | ./checkpoints/[problem]/model_100000_float16.ckpt |
| figures_path   | figures saving path                          | ./figures/[problem]                               |
| log_path       | log saving path                              | ./logs/[problem]                                  |
| lr             | learning rate                                | 1e-3 1e-4 1e-5 1e-6                               |
| epochs         | number of epochs                             | 20000 30000 30000 20000                           |
| batch_size     | training batch size                          | 100                                               |
| num_snapshots  | number of time snapshots                     | 15                                                |
| terminal_time  | terminal time                                | 0.3                                               |
| download_data  | necessary dataset and/or checkpoints         | fbsnns                                            |
| force_download | whether download the dataset or not by force | false                                             |
| amp_level      | MindSpore auto mixed precision level         | O3                                                |
| device_id      | device id to set                             | None                                              |
| mode           | MindSpore Graph mode(0) or Pynative mode(1)  | 0                                                 |

### [Training Process](#contents)

- Running on GPU/Ascend

  ```bash
  python train.py
  ```

  The loss values during training will be printed in the console, which can also be inspected after training in log
  file.

  ```bash
  # grep "loss:" log
  step: 0, loss: 0.0629, interval: 89.23714256286621s, total: 89.23714256286621s
  step: 500, loss: 0.002146, interval: 6.8948588371276855s, total: 96.1320013999939s
  step: 1000, loss: 0.002295, interval: 6.947064161300659s, total: 103.07906556129456s
  step: 1500, loss: 0.001376, interval: 6.927499055862427s, total: 110.00656461715698s
  step: 2000, loss: 0.00161, interval: 7.066746950149536s, total: 117.07331156730652s
  step: 2500, loss: 0.0009484, interval: 7.003252267837524s, total: 124.07656383514404s
  step: 3000, loss: 0.001128, interval: 6.8707005977630615s, total: 130.9472644329071s
  ...
  ```

- After training, you can still review the training process through the log file saved in `log_path`, `./logs` directory
  by default.

- The model checkpoint will be saved in `save_ckpt_path`, `./checkpoint/[case]` directory by default.

### [Evaluation Process](#evaluation-process)

Before running the command below, please check the checkpoint loading path `load_ckpt_path` specified
in `config.yaml` for evaluation.

- running on GPU/Ascend

```bash
  python eval.py
  ```

You can view the process and results through the `log_path`, `./logs/[case]` by default.
The result pictures are saved in `figures_path`, `./figures/[case]` by default.