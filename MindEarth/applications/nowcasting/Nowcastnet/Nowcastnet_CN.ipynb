{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# NowcastNet: 融入物理机制的生成式短临降水预报模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 概述\n",
    "\n",
    "NowcastNet是由清华大学龙明盛老师团队开发的一个基于雷达数据的短临降水预报模型。 它提供了0-3h的短临降水预报结果，空间分辨率为1km左右。\n",
    "该模型主要分为evolution和generation两大模块，其中evolution模块融入了物理机制，给出一个粗糙的预测结果。接着，generation模块在此\n",
    "基础上生成精细化的结果，从而得到最终的降水预报。模型框架图入下图所示(图片来源于论文 [Skilful nowcasting of extreme precipitation with NowcastNet](https://www.nature.com/articles/s41586-023-06184-4))\n",
    "\n",
    "![nowcastnet](images/nowcastnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## NowcastNet\n",
    "\n",
    "NowcastNet网络框架如下图所示\n",
    "\n",
    "![nowcastnet](images/nowcastnet.png)\n",
    "\n",
    "1. Evolution network：融入物理机制，以历史的$x_{-T:0}$为输入，通过U-Net预测动量$v$和残差$s$，再经过evolution operator得到预测$x_{1:T}^{''}$。形式如下：\n",
    "\n",
    "$$\n",
    "x_{1:T}^{''} = Evolution(x_{-T:0})\n",
    "$$\n",
    "\n",
    "2. Nowcast encoder & decoder：采用[Semantic Image Synthesis with Spatially-Adaptive Normalization](https://openaccess.thecvf.com/content_CVPR_2019/papers/Park_Semantic_Image_Synthesis_With_Spatially-Adaptive_Normalization_CVPR_2019_paper.pdf)架构把Evolution network的输出$x_{1:T}^{''}$做为conditioning进行GAN训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 技术路径\n",
    "\n",
    "MindSpore Earth求解该问题的具体流程如下:\n",
    "\n",
    "1. 创建数据集\n",
    "2. 模型构建\n",
    "3. 损失函数\n",
    "4. 模型训练\n",
    "5. 模型评估与可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "训练和测试所用的数据集可以在: [Nowcastnet/dataset]() 下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T12:21:07.849115100Z",
     "start_time": "2024-01-30T12:21:01.986652Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(4138269:281473304481824,MainProcess):2024-01-30-20:21:30.197.025 [mindspore/run_check/_check_version.py:348] Using custom Ascend AI software package (Ascend Data Center Solution) path, package version checking is skipped. Please make sure Ascend AI software package (Ascend Data Center Solution) version is supported. For details, refer to the installation guidelines https://www.mindspore.cn/install\n",
      "[WARNING] ME(4138269:281473304481824,MainProcess):2024-01-30-20:21:30.201.206 [mindspore/run_check/_check_version.py:461] Can not find the tbe operator implementation(need by mindspore-ascend). Please check whether the Environment Variable PYTHONPATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(4138269:281473304481824,MainProcess):2024-01-30-20:21:30.202.274 [mindspore/run_check/_check_version.py:468] Can not find driver so(need by mindspore-ascend). Please check whether the Environment Variable LD_LIBRARY_PATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import mindspore as ms\n",
    "import numpy as np\n",
    "from mindspore import context, nn, amp, set_seed\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T05:59:25.475709500Z",
     "start_time": "2024-01-31T05:59:25.432825200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src import get_logger\n",
    "from src import EvolutionTrainer, GenerationTrainer, GenerateLoss, DiscriminatorLoss, EvolutionLoss\n",
    "from src import EvolutionPredictor, GenerationPredictor\n",
    "from src import RadarData, NowcastDataset\n",
    "from src.evolution import EvolutionNet\n",
    "from src.generator import GenerationNet\n",
    "from src.discriminator import TemporalDiscriminator\n",
    "from src.visual import plt_img\n",
    "from mindearth.utils.tools import load_yaml_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T12:21:12.488547200Z",
     "start_time": "2024-01-30T12:21:12.479570700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "set_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T12:21:14.948562900Z",
     "start_time": "2024-01-30T12:21:14.931578100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = load_yaml_config(\"./configs/Nowcastnet.yaml\")\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\", device_id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 创建数据集\n",
    "\n",
    "在[dataset]()路径下，下载训练数据集，验证数据集到`./dataset`目录，修改`./configs/Nowcastnet.yaml`配置文件中的`root_dir`。\n",
    "\n",
    "`./dataset`中的目录结构如下所示：\n",
    "\n",
    "```markdown\n",
    "├── train\n",
    "├── valid\n",
    "├── test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T12:21:28.111872100Z",
     "start_time": "2024-01-30T12:21:19.226508600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 20:21:45,539 - utils.py[line:55] - INFO: {'name': 'NowcastNet', 'ngf': 32, 'pool_ensemble_num': 4, 'module_name': 'generation'}\n",
      "2024-01-30 20:21:45,539 - utils.py[line:55] - INFO: {'name': 'us', 'root_dir': '/data/zmmVol1/cszhou/usa_datasets', 't_in': 9, 't_out': 20, 'h_size': 512, 'w_size': 512, 'time_interval': 10, 'num_workers': 1, 'data_sink': False, 'batch_size': 1, 'noise_scale': 32}\n",
      "2024-01-30 20:21:45,540 - utils.py[line:55] - INFO: {'name': 'adam', 'beta1': 0.01, 'beta2': 0.9, 'g_lr': 1.5e-05, 'd_lr': '6e-5', 'epochs': 10}\n",
      "2024-01-30 20:21:45,541 - utils.py[line:55] - INFO: {'name': 'adam', 'lr': 0.001, 'weight_decay': 0.1, 'gamma': 0.5, 'epochs': 5}\n",
      "2024-01-30 20:21:45,541 - utils.py[line:55] - INFO: {'summary_dir': './summary/', 'eval_interval': 2, 'save_checkpoint_epochs': 2, 'keep_checkpoint_max': 4, 'key_info_timestep': [10, 60, 120], 'generate_ckpt_path': '/data/zmmVol1/cszhou/nowcastnet_final/applications/nowcasting/Nowcastnet/ckpt/generator-device13.ckpt', 'evolution_ckpt_path': '/data/zmmVol1/cszhou/nowcastnet_final/applications/nowcasting/Nowcastnet/ckpt/EvolutionNet-device2-4_motion.ckpt', 'visual': True, 'csin_threshold': 16}\n",
      "2024-01-30 20:21:45,542 - utils.py[line:55] - INFO: {'distribute': False, 'mixed_precision': True, 'amp_level': 'O2', 'load_ckpt': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvolutionNet<\n",
       "  (evo_net): EvolutionNetwork<\n",
       "    (inc): DoubleConv<\n",
       "      (single_conv): SequentialCell<\n",
       "        (0): BatchNorm2d<num_features=9, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.inc.single_conv.0.gamma, shape=(9,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.inc.single_conv.0.beta, shape=(9,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.inc.single_conv.0.moving_mean, shape=(9,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.inc.single_conv.0.moving_variance, shape=(9,), dtype=Float32, requires_grad=False)>\n",
       "        (1): SpectralNormal<\n",
       "          (parametrizations): Conv2d<input_channels=9, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe7c6c2df0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe777e12b0>, format=NCHW>\n",
       "          >\n",
       "        >\n",
       "      (double_conv): SequentialCell<\n",
       "        (0): BatchNorm2d<num_features=9, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.inc.double_conv.0.gamma, shape=(9,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.inc.double_conv.0.beta, shape=(9,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.inc.double_conv.0.moving_mean, shape=(9,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.inc.double_conv.0.moving_variance, shape=(9,), dtype=Float32, requires_grad=False)>\n",
       "        (1): ReLU<>\n",
       "        (2): SpectralNormal<\n",
       "          (parametrizations): Conv2d<input_channels=9, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe777f1d90>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe777f1f10>, format=NCHW>\n",
       "          >\n",
       "        (3): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.inc.double_conv.3.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.inc.double_conv.3.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.inc.double_conv.3.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.inc.double_conv.3.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "        (4): ReLU<>\n",
       "        (5): SpectralNormal<\n",
       "          (parametrizations): Conv2d<input_channels=32, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74306640>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe743067c0>, format=NCHW>\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (down1): Down<\n",
       "      (maxpool_conv): SequentialCell<\n",
       "        (0): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n",
       "        (1): DoubleConv<\n",
       "          (single_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down1.maxpool_conv.1.single_conv.0.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down1.maxpool_conv.1.single_conv.0.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down1.maxpool_conv.1.single_conv.0.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down1.maxpool_conv.1.single_conv.0.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "            (1): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=32, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74306a30>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74306a60>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          (double_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.0.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.0.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.0.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.0.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "            (1): ReLU<>\n",
       "            (2): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=32, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74306c10>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe7cec2e20>, format=NCHW>\n",
       "              >\n",
       "            (3): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.3.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.3.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.3.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.3.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "            (4): ReLU<>\n",
       "            (5): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74306e80>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74306f40>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (down2): Down<\n",
       "      (maxpool_conv): SequentialCell<\n",
       "        (0): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n",
       "        (1): DoubleConv<\n",
       "          (single_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down2.maxpool_conv.1.single_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down2.maxpool_conv.1.single_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down2.maxpool_conv.1.single_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down2.maxpool_conv.1.single_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "            (1): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=64, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742d1070>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742d11c0>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          (double_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "            (1): ReLU<>\n",
       "            (2): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=64, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742d1490>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742d1550>, format=NCHW>\n",
       "              >\n",
       "            (3): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.3.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.3.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.3.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.3.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "            (4): ReLU<>\n",
       "            (5): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=128, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742d1310>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742d1610>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (down3): Down<\n",
       "      (maxpool_conv): SequentialCell<\n",
       "        (0): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n",
       "        (1): DoubleConv<\n",
       "          (single_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down3.maxpool_conv.1.single_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down3.maxpool_conv.1.single_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down3.maxpool_conv.1.single_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down3.maxpool_conv.1.single_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "            (1): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=128, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742d13a0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742d1760>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          (double_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "            (1): ReLU<>\n",
       "            (2): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=128, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742d1a90>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742d1b50>, format=NCHW>\n",
       "              >\n",
       "            (3): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.3.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.3.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.3.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.3.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "            (4): ReLU<>\n",
       "            (5): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742d1a00>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742d19d0>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (down4): Down<\n",
       "      (maxpool_conv): SequentialCell<\n",
       "        (0): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n",
       "        (1): DoubleConv<\n",
       "          (single_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down4.maxpool_conv.1.single_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down4.maxpool_conv.1.single_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down4.maxpool_conv.1.single_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down4.maxpool_conv.1.single_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "            (1): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742d1f40>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742d1f10>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          (double_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "            (1): ReLU<>\n",
       "            (2): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74243130>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742431f0>, format=NCHW>\n",
       "              >\n",
       "            (3): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.3.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.3.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.3.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.3.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "            (4): ReLU<>\n",
       "            (5): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742d1940>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742d16d0>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up1): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1.conv.single_conv.0.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1.conv.single_conv.0.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1.conv.single_conv.0.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1.conv.single_conv.0.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=512, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74243760>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74243790>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1.conv.double_conv.0.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1.conv.double_conv.0.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1.conv.double_conv.0.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1.conv.double_conv.0.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=512, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74243670>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe742434c0>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1.conv.double_conv.3.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1.conv.double_conv.3.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1.conv.double_conv.3.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1.conv.double_conv.3.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74243b50>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74243c10>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up2): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2.conv.single_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2.conv.single_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2.conv.single_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2.conv.single_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74243cd0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74243df0>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2.conv.double_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2.conv.double_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2.conv.double_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2.conv.double_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742340a0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74243e50>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2.conv.double_conv.3.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2.conv.double_conv.3.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2.conv.double_conv.3.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2.conv.double_conv.3.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74234130>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74234220>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up3): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3.conv.single_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3.conv.single_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3.conv.single_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3.conv.single_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74243a90>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74234460>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3.conv.double_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3.conv.double_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3.conv.double_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3.conv.double_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742346d0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74234790>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3.conv.double_conv.3.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3.conv.double_conv.3.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3.conv.double_conv.3.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3.conv.double_conv.3.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742348e0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74234400>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up4): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4.conv.single_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4.conv.single_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4.conv.single_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4.conv.single_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74234be0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74306d30>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4.conv.double_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4.conv.double_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4.conv.double_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4.conv.double_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74234940>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74234cd0>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4.conv.double_conv.3.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4.conv.double_conv.3.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4.conv.double_conv.3.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4.conv.double_conv.3.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=32, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74234d90>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe741a1100>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (outc): OutConv<\n",
       "      (conv): Conv2d<input_channels=32, output_channels=20, kernel_size=(1, 1), stride=(1, 1), pad_mode=pad, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe742342b0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74234d00>, format=NCHW>\n",
       "      >\n",
       "    (up1_v): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1_v.conv.single_conv.0.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1_v.conv.single_conv.0.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1_v.conv.single_conv.0.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1_v.conv.single_conv.0.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=512, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe741a1400>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe741a1430>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1_v.conv.double_conv.0.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1_v.conv.double_conv.0.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1_v.conv.double_conv.0.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1_v.conv.double_conv.0.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=512, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe741a1610>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe741a10a0>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1_v.conv.double_conv.3.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1_v.conv.double_conv.3.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1_v.conv.double_conv.3.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1_v.conv.double_conv.3.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe741a1820>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe741a18e0>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up2_v): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2_v.conv.single_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2_v.conv.single_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2_v.conv.single_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2_v.conv.single_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe741a19d0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe741a19a0>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2_v.conv.double_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2_v.conv.double_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2_v.conv.double_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2_v.conv.double_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe741a1d00>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe741a1af0>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2_v.conv.double_conv.3.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2_v.conv.double_conv.3.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2_v.conv.double_conv.3.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2_v.conv.double_conv.3.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe741a1e20>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe741a1ee0>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up3_v): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3_v.conv.single_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3_v.conv.single_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3_v.conv.single_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3_v.conv.single_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe741a1a60>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe741a1ac0>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3_v.conv.double_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3_v.conv.double_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3_v.conv.double_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3_v.conv.double_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74111370>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74111430>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3_v.conv.double_conv.3.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3_v.conv.double_conv.3.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3_v.conv.double_conv.3.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3_v.conv.double_conv.3.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74111490>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74111400>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up4_v): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4_v.conv.single_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4_v.conv.single_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4_v.conv.single_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4_v.conv.single_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe741118e0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74111910>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4_v.conv.double_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4_v.conv.double_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4_v.conv.double_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4_v.conv.double_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe741117c0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74111a00>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4_v.conv.double_conv.3.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4_v.conv.double_conv.3.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4_v.conv.double_conv.3.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4_v.conv.double_conv.3.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=32, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74111cd0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe74111d90>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (outc_v): OutConv<\n",
       "      (conv): Conv2d<input_channels=32, output_channels=40, kernel_size=(1, 1), stride=(1, 1), pad_mode=pad, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffe74111c10>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffe741116a0>, format=NCHW>\n",
       "      >\n",
       "    >\n",
       "  >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = get_logger(config)\n",
    "config[\"model\"][\"module_name\"] = 'evolution'\n",
    "config[\"data\"][\"batch_size\"] = 4\n",
    "config[\"summary\"][\"eval_interval\"] = 1\n",
    "config[\"summary\"][\"visual\"] = False\n",
    "train_params = config.get(\"train\")\n",
    "summary_params = config.get(\"summary\")\n",
    "evo_model = EvolutionNet(config)\n",
    "evo_model.set_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T03:24:30.164901700Z",
     "start_time": "2024-01-31T01:01:39.614516800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(4138269,fffcfb65b120,python):2024-01-31-09:02:51.669.590 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:231] operator()] Bad performance attention, it takes more than 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 16.964931\n",
      "epoch: 1 step: 2, loss is 14.502213\n",
      "epoch: 1 step: 3, loss is 10.780349\n",
      "epoch: 1 step: 4, loss is 11.027175\n",
      "epoch: 1 step: 5, loss is 3.8108711\n",
      "epoch: 1 step: 6, loss is 13.924669\n",
      "epoch: 1 step: 7, loss is 12.181091\n",
      "epoch: 1 step: 8, loss is 4.613654\n",
      "epoch: 1 step: 9, loss is 4.306578\n",
      "epoch: 1 step: 10, loss is 4.932178\n",
      "epoch: 1 step: 11, loss is 6.628277\n",
      "epoch: 1 step: 12, loss is 3.5065076\n",
      "epoch: 1 step: 13, loss is 20.65365\n",
      "epoch: 1 step: 14, loss is 17.443842\n",
      "epoch: 1 step: 15, loss is 7.5954895\n",
      "epoch: 1 step: 16, loss is 7.138162\n",
      "epoch: 1 step: 17, loss is 6.9041977\n",
      "epoch: 1 step: 18, loss is 19.990036\n",
      "epoch: 1 step: 19, loss is 9.513996\n",
      "epoch: 1 step: 20, loss is 7.3165126\n",
      "epoch: 1 step: 21, loss is 6.1689415\n",
      "epoch: 1 step: 22, loss is 6.158663\n",
      "epoch: 1 step: 23, loss is 9.237205\n",
      "epoch: 1 step: 24, loss is 7.669189\n",
      "epoch: 1 step: 25, loss is 5.0312796\n",
      "epoch: 1 step: 26, loss is 6.590024\n",
      "epoch: 1 step: 27, loss is 15.463813\n",
      "epoch: 1 step: 28, loss is 7.9854445\n",
      "epoch: 1 step: 29, loss is 4.398997\n",
      "epoch: 1 step: 30, loss is 4.5272164\n",
      "epoch: 1 step: 31, loss is 11.291908\n",
      "epoch: 1 step: 32, loss is 4.758201\n",
      "epoch: 1 step: 33, loss is 12.15818\n",
      "epoch: 1 step: 34, loss is 9.617511\n",
      "epoch: 1 step: 35, loss is 10.697494\n",
      "epoch: 1 step: 36, loss is 9.898358\n",
      "epoch: 1 step: 37, loss is 9.26039\n",
      "epoch: 1 step: 38, loss is 6.876935\n",
      "epoch: 1 step: 39, loss is 19.414267\n",
      "epoch: 1 step: 40, loss is 6.9686904\n",
      "epoch: 1 step: 41, loss is 8.792517\n",
      "epoch: 1 step: 42, loss is 5.86637\n",
      "epoch: 1 step: 43, loss is 13.445674\n",
      "epoch: 1 step: 44, loss is 15.180026\n",
      "epoch: 1 step: 45, loss is 11.377322\n",
      "epoch: 1 step: 46, loss is 8.324775\n",
      "epoch: 1 step: 47, loss is 10.875625\n",
      "epoch: 1 step: 48, loss is 6.671407\n",
      "epoch: 1 step: 49, loss is 7.2738595\n",
      "epoch: 1 step: 50, loss is 2.5302095\n",
      "epoch: 1 step: 51, loss is 12.482405\n",
      "epoch: 1 step: 52, loss is 10.49932\n",
      "epoch: 1 step: 53, loss is 8.723933\n",
      "epoch: 1 step: 54, loss is 5.7406073\n",
      "epoch: 1 step: 55, loss is 8.1165085\n",
      "epoch: 1 step: 56, loss is 5.586655\n",
      "epoch: 1 step: 57, loss is 10.743989\n",
      "epoch: 1 step: 58, loss is 2.4052536\n",
      "epoch: 1 step: 59, loss is 7.8741846\n",
      "epoch: 1 step: 60, loss is 15.538988\n",
      "epoch: 1 step: 61, loss is 9.297923\n",
      "epoch: 1 step: 62, loss is 5.390023\n",
      "epoch: 1 step: 63, loss is 5.696861\n",
      "epoch: 1 step: 64, loss is 8.24357\n",
      "epoch: 1 step: 65, loss is 4.29499\n",
      "epoch: 1 step: 66, loss is 4.2717934\n",
      "epoch: 1 step: 67, loss is 10.973701\n",
      "epoch: 1 step: 68, loss is 14.457351\n",
      "epoch: 1 step: 69, loss is 6.1116934\n",
      "epoch: 1 step: 70, loss is 10.326851\n",
      "epoch: 1 step: 71, loss is 7.462485\n",
      "epoch: 1 step: 72, loss is 12.940358\n",
      "epoch: 1 step: 73, loss is 4.1140833\n",
      "epoch: 1 step: 74, loss is 10.428161\n",
      "epoch: 1 step: 75, loss is 3.6108303\n",
      "epoch: 1 step: 76, loss is 16.931557\n",
      "epoch: 1 step: 77, loss is 13.471918\n",
      "epoch: 1 step: 78, loss is 14.105043\n",
      "epoch: 1 step: 79, loss is 20.49185\n",
      "epoch: 1 step: 80, loss is 7.827617\n",
      "epoch: 1 step: 81, loss is 15.288184\n",
      "epoch: 1 step: 82, loss is 21.24135\n",
      "epoch: 1 step: 83, loss is 7.5578628\n",
      "epoch: 1 step: 84, loss is 3.9976785\n",
      "epoch: 1 step: 85, loss is 11.95989\n",
      "epoch: 1 step: 86, loss is 4.5543447\n",
      "epoch: 1 step: 87, loss is 6.509666\n",
      "epoch: 1 step: 88, loss is 8.042537\n",
      "epoch: 1 step: 89, loss is 7.300719\n",
      "epoch: 1 step: 90, loss is 3.464943\n",
      "epoch: 1 step: 91, loss is 9.632981\n",
      "epoch: 1 step: 92, loss is 7.315619\n",
      "epoch: 1 step: 93, loss is 7.2241855\n",
      "epoch: 1 step: 94, loss is 8.3599\n",
      "epoch: 1 step: 95, loss is 2.32561\n",
      "epoch: 1 step: 96, loss is 9.266434\n",
      "epoch: 1 step: 97, loss is 10.457726\n",
      "epoch: 1 step: 98, loss is 4.792747\n",
      "epoch: 1 step: 99, loss is 4.498106\n",
      "epoch: 1 step: 100, loss is 7.439522\n",
      "epoch: 1 step: 101, loss is 10.878738\n",
      "epoch: 1 step: 102, loss is 5.3957043\n",
      "epoch: 1 step: 103, loss is 6.0373197\n",
      "epoch: 1 step: 104, loss is 6.7042694\n",
      "epoch: 1 step: 105, loss is 6.3693085\n",
      "epoch: 1 step: 106, loss is 7.909204\n",
      "epoch: 1 step: 107, loss is 13.680556\n",
      "epoch: 1 step: 108, loss is 6.0075154\n",
      "epoch: 1 step: 109, loss is 9.484731\n",
      "epoch: 1 step: 110, loss is 11.522829\n",
      "epoch: 1 step: 111, loss is 10.184873\n",
      "epoch: 1 step: 112, loss is 5.731665\n",
      "epoch: 1 step: 113, loss is 3.8105686\n",
      "epoch: 1 step: 114, loss is 9.551883\n",
      "epoch: 1 step: 115, loss is 14.625876\n",
      "epoch: 1 step: 116, loss is 14.840924\n",
      "epoch: 1 step: 117, loss is 5.2914557\n",
      "epoch: 1 step: 118, loss is 5.4606357\n",
      "epoch: 1 step: 119, loss is 4.2632265\n",
      "epoch: 1 step: 120, loss is 14.183838\n",
      "epoch: 1 step: 121, loss is 13.063286\n",
      "epoch: 1 step: 122, loss is 18.90632\n",
      "epoch: 1 step: 123, loss is 14.5564575\n",
      "epoch: 1 step: 124, loss is 4.44399\n",
      "epoch: 1 step: 125, loss is 7.264557\n",
      "epoch: 1 step: 126, loss is 12.214412\n",
      "epoch: 1 step: 127, loss is 11.335418\n",
      "epoch: 1 step: 128, loss is 12.424735\n",
      "epoch: 1 step: 129, loss is 11.148064\n",
      "epoch: 1 step: 130, loss is 3.0634212\n",
      "epoch: 1 step: 131, loss is 9.569626\n",
      "epoch: 1 step: 132, loss is 13.128596\n",
      "epoch: 1 step: 133, loss is 12.354448\n",
      "epoch: 1 step: 134, loss is 9.601986\n",
      "epoch: 1 step: 135, loss is 2.7166932\n",
      "epoch: 1 step: 136, loss is 4.251752\n",
      "epoch: 1 step: 137, loss is 23.482744\n",
      "epoch: 1 step: 138, loss is 5.436116\n",
      "epoch: 1 step: 139, loss is 4.289401\n",
      "epoch: 1 step: 140, loss is 7.24936\n",
      "epoch: 1 step: 141, loss is 8.673624\n",
      "epoch: 1 step: 142, loss is 9.799458\n",
      "epoch: 1 step: 143, loss is 7.263776\n",
      "epoch: 1 step: 144, loss is 8.3800125\n",
      "epoch: 1 step: 145, loss is 9.532288\n",
      "epoch: 1 step: 146, loss is 17.03655\n",
      "epoch: 1 step: 147, loss is 7.8191466\n",
      "epoch: 1 step: 148, loss is 11.993373\n",
      "epoch: 1 step: 149, loss is 12.577567\n",
      "epoch: 1 step: 150, loss is 8.181959\n",
      "epoch: 1 step: 151, loss is 6.631215\n",
      "epoch: 1 step: 152, loss is 13.766024\n",
      "epoch: 1 step: 153, loss is 9.468322\n",
      "epoch: 1 step: 154, loss is 9.816963\n",
      "epoch: 1 step: 155, loss is 8.041017\n",
      "epoch: 1 step: 156, loss is 4.829606\n",
      "epoch: 1 step: 157, loss is 6.762423\n",
      "epoch: 1 step: 158, loss is 12.020473\n",
      "epoch: 1 step: 159, loss is 7.8607407\n",
      "epoch: 1 step: 160, loss is 4.0203385\n",
      "epoch: 1 step: 161, loss is 6.353967\n",
      "epoch: 1 step: 162, loss is 4.0598826\n",
      "epoch: 1 step: 163, loss is 3.6132944\n",
      "epoch: 1 step: 164, loss is 11.348147\n",
      "epoch: 1 step: 165, loss is 11.713739\n",
      "epoch: 1 step: 166, loss is 18.555906\n",
      "epoch: 1 step: 167, loss is 7.0928855\n",
      "epoch: 1 step: 168, loss is 8.019599\n",
      "epoch: 1 step: 169, loss is 6.473865\n",
      "epoch: 1 step: 170, loss is 8.242885\n",
      "epoch: 1 step: 171, loss is 4.784219\n",
      "epoch: 1 step: 172, loss is 13.512122\n",
      "epoch: 1 step: 173, loss is 9.940894\n",
      "epoch: 1 step: 174, loss is 7.437154\n",
      "epoch: 1 step: 175, loss is 4.4937067\n",
      "epoch: 1 step: 176, loss is 14.391604\n",
      "epoch: 1 step: 177, loss is 2.2355168\n",
      "epoch: 1 step: 178, loss is 7.665934\n",
      "epoch: 1 step: 179, loss is 10.328207\n",
      "epoch: 1 step: 180, loss is 14.156844\n",
      "epoch: 1 step: 181, loss is 6.245267\n",
      "epoch: 1 step: 182, loss is 15.584538\n",
      "epoch: 1 step: 183, loss is 2.1077874\n",
      "epoch: 1 step: 184, loss is 3.5419939\n",
      "epoch: 1 step: 185, loss is 5.6080604\n",
      "epoch: 1 step: 186, loss is 10.985804\n",
      "epoch: 1 step: 187, loss is 8.52919\n",
      "epoch: 1 step: 188, loss is 7.9665284\n",
      "epoch: 1 step: 189, loss is 7.1876893\n",
      "epoch: 1 step: 190, loss is 13.44533\n",
      "epoch: 1 step: 191, loss is 13.128505\n",
      "epoch: 1 step: 192, loss is 8.743109\n",
      "epoch: 1 step: 193, loss is 6.9234285\n",
      "epoch: 1 step: 194, loss is 8.952152\n",
      "epoch: 1 step: 195, loss is 13.811938\n",
      "epoch: 1 step: 196, loss is 11.274354\n",
      "epoch: 1 step: 197, loss is 10.706752\n",
      "epoch: 1 step: 198, loss is 6.335921\n",
      "epoch: 1 step: 199, loss is 19.018145\n",
      "epoch: 1 step: 200, loss is 5.913008\n",
      "epoch: 1 step: 201, loss is 5.8782706\n",
      "epoch: 1 step: 202, loss is 12.370498\n",
      "epoch: 1 step: 203, loss is 6.653756\n",
      "epoch: 1 step: 204, loss is 6.2753673\n",
      "epoch: 1 step: 205, loss is 8.764506\n",
      "epoch: 1 step: 206, loss is 13.218335\n",
      "epoch: 1 step: 207, loss is 10.977753\n",
      "epoch: 1 step: 208, loss is 6.318348\n",
      "epoch: 1 step: 209, loss is 6.7571025\n",
      "epoch: 1 step: 210, loss is 8.462529\n",
      "epoch: 1 step: 211, loss is 10.625142\n",
      "epoch: 1 step: 212, loss is 12.006033\n",
      "epoch: 1 step: 213, loss is 18.857683\n",
      "epoch: 1 step: 214, loss is 6.3117485\n",
      "epoch: 1 step: 215, loss is 7.57649\n",
      "epoch: 1 step: 216, loss is 7.947931\n",
      "epoch: 1 step: 217, loss is 6.690007\n",
      "epoch: 1 step: 218, loss is 7.4355044\n",
      "epoch: 1 step: 219, loss is 5.8383784\n",
      "epoch: 1 step: 220, loss is 7.9469423\n",
      "epoch: 1 step: 221, loss is 9.972283\n",
      "epoch: 1 step: 222, loss is 7.680134\n",
      "epoch: 1 step: 223, loss is 9.293043\n",
      "epoch: 1 step: 224, loss is 7.799268\n",
      "epoch: 1 step: 225, loss is 9.68341\n",
      "epoch: 1 step: 226, loss is 14.760447\n",
      "epoch: 1 step: 227, loss is 8.728953\n",
      "epoch: 1 step: 228, loss is 12.804427\n",
      "epoch: 1 step: 229, loss is 9.576239\n",
      "epoch: 1 step: 230, loss is 8.50848\n",
      "epoch: 1 step: 231, loss is 11.705716\n",
      "epoch: 1 step: 232, loss is 3.6493626\n",
      "epoch: 1 step: 233, loss is 8.572134\n",
      "epoch: 1 step: 234, loss is 13.613303\n",
      "epoch: 1 step: 235, loss is 9.064838\n",
      "epoch: 1 step: 236, loss is 16.527098\n",
      "epoch: 1 step: 237, loss is 14.337552\n",
      "epoch: 1 step: 238, loss is 11.650723\n",
      "epoch: 1 step: 239, loss is 9.424839\n",
      "epoch: 1 step: 240, loss is 11.140727\n",
      "epoch: 1 step: 241, loss is 6.140134\n",
      "epoch: 1 step: 242, loss is 6.678531\n",
      "epoch: 1 step: 243, loss is 5.3360233\n",
      "epoch: 1 step: 244, loss is 13.993085\n",
      "epoch: 1 step: 245, loss is 11.521411\n",
      "epoch: 1 step: 246, loss is 20.689844\n",
      "epoch: 1 step: 247, loss is 7.0184073\n",
      "epoch: 1 step: 248, loss is 4.3469954\n",
      "epoch: 1 step: 249, loss is 13.18764\n",
      "epoch: 1 step: 250, loss is 11.985401\n",
      "epoch: 1 step: 251, loss is 15.475783\n",
      "epoch: 1 step: 252, loss is 5.469285\n",
      "epoch: 1 step: 253, loss is 13.345296\n",
      "epoch: 1 step: 254, loss is 6.699672\n",
      "epoch: 1 step: 255, loss is 8.804835\n",
      "epoch: 1 step: 256, loss is 10.055738\n",
      "epoch: 1 step: 257, loss is 17.492495\n",
      "epoch: 1 step: 258, loss is 7.796107\n",
      "epoch: 1 step: 259, loss is 12.960048\n",
      "epoch: 1 step: 260, loss is 8.516406\n",
      "epoch: 1 step: 261, loss is 7.0510254\n",
      "epoch: 1 step: 262, loss is 6.873712\n",
      "epoch: 1 step: 263, loss is 3.8377035\n",
      "epoch: 1 step: 264, loss is 8.718678\n",
      "epoch: 1 step: 265, loss is 7.1279716\n",
      "epoch: 1 step: 266, loss is 7.9922028\n",
      "epoch: 1 step: 267, loss is 4.747283\n",
      "epoch: 1 step: 268, loss is 8.433405\n",
      "epoch: 1 step: 269, loss is 4.706301\n",
      "epoch: 1 step: 270, loss is 14.584383\n",
      "epoch: 1 step: 271, loss is 6.509504\n",
      "epoch: 1 step: 272, loss is 8.290088\n",
      "epoch: 1 step: 273, loss is 4.737615\n",
      "epoch: 1 step: 274, loss is 10.970706\n",
      "epoch: 1 step: 275, loss is 8.109492\n",
      "epoch: 1 step: 276, loss is 6.9756775\n",
      "epoch: 1 step: 277, loss is 10.41698\n",
      "epoch: 1 step: 278, loss is 13.584566\n",
      "epoch: 1 step: 279, loss is 7.0505614\n",
      "epoch: 1 step: 280, loss is 8.139429\n",
      "epoch: 1 step: 281, loss is 7.9716525\n",
      "epoch: 1 step: 282, loss is 10.396158\n",
      "epoch: 1 step: 283, loss is 15.148501\n",
      "epoch: 1 step: 284, loss is 4.380001\n",
      "epoch: 1 step: 285, loss is 4.0754213\n",
      "epoch: 1 step: 286, loss is 15.811124\n",
      "epoch: 1 step: 287, loss is 12.500298\n",
      "epoch: 1 step: 288, loss is 10.110407\n",
      "epoch: 1 step: 289, loss is 10.692337\n",
      "epoch: 1 step: 290, loss is 12.567976\n",
      "epoch: 1 step: 291, loss is 10.914864\n",
      "epoch: 1 step: 292, loss is 5.941654\n",
      "epoch: 1 step: 293, loss is 5.6451206\n",
      "epoch: 1 step: 294, loss is 2.7260299\n",
      "epoch: 1 step: 295, loss is 7.996601\n",
      "epoch: 1 step: 296, loss is 7.4386406\n",
      "epoch: 1 step: 297, loss is 8.1776495\n",
      "epoch: 1 step: 298, loss is 7.7091117\n",
      "epoch: 1 step: 299, loss is 8.312502\n",
      "epoch: 1 step: 300, loss is 8.100204\n",
      "epoch: 1 step: 301, loss is 6.3468375\n",
      "epoch: 1 step: 302, loss is 7.523632\n",
      "epoch: 1 step: 303, loss is 4.7613688\n",
      "epoch: 1 step: 304, loss is 19.382504\n",
      "epoch: 1 step: 305, loss is 2.661499\n",
      "epoch: 1 step: 306, loss is 6.581848\n",
      "epoch: 1 step: 307, loss is 17.015114\n",
      "epoch: 1 step: 308, loss is 5.368159\n",
      "epoch: 1 step: 309, loss is 6.088465\n",
      "epoch: 1 step: 310, loss is 11.750272\n",
      "epoch: 1 step: 311, loss is 11.693415\n",
      "epoch: 1 step: 312, loss is 13.704157\n",
      "epoch: 1 step: 313, loss is 11.232135\n",
      "epoch: 1 step: 314, loss is 3.6701562\n",
      "epoch: 1 step: 315, loss is 10.623233\n",
      "epoch: 1 step: 316, loss is 4.281273\n",
      "epoch: 1 step: 317, loss is 8.660683\n",
      "epoch: 1 step: 318, loss is 14.607958\n",
      "epoch: 1 step: 319, loss is 6.1075015\n",
      "epoch: 1 step: 320, loss is 6.1718245\n",
      "epoch: 1 step: 321, loss is 7.783943\n",
      "epoch: 1 step: 322, loss is 7.4864097\n",
      "epoch: 1 step: 323, loss is 12.649513\n",
      "epoch: 1 step: 324, loss is 10.401742\n",
      "epoch: 1 step: 325, loss is 8.134112\n",
      "epoch: 1 step: 326, loss is 4.4953103\n",
      "epoch: 1 step: 327, loss is 1.972975\n",
      "epoch: 1 step: 328, loss is 15.003345\n",
      "epoch: 1 step: 329, loss is 8.12178\n",
      "epoch: 1 step: 330, loss is 5.370235\n",
      "epoch: 1 step: 331, loss is 4.20061\n",
      "epoch: 1 step: 332, loss is 12.827085\n",
      "epoch: 1 step: 333, loss is 11.595283\n",
      "epoch: 1 step: 334, loss is 8.555338\n",
      "epoch: 1 step: 335, loss is 17.14596\n",
      "epoch: 1 step: 336, loss is 4.805692\n",
      "epoch: 1 step: 337, loss is 5.3607078\n",
      "epoch: 1 step: 338, loss is 18.441927\n",
      "epoch: 1 step: 339, loss is 11.609587\n",
      "epoch: 1 step: 340, loss is 6.3581595\n",
      "epoch: 1 step: 341, loss is 4.8234067\n",
      "epoch: 1 step: 342, loss is 9.863045\n",
      "epoch: 1 step: 343, loss is 10.113366\n",
      "epoch: 1 step: 344, loss is 11.9911995\n",
      "epoch: 1 step: 345, loss is 14.107406\n",
      "epoch: 1 step: 346, loss is 10.610396\n",
      "epoch: 1 step: 347, loss is 11.898156\n",
      "epoch: 1 step: 348, loss is 8.802024\n",
      "epoch: 1 step: 349, loss is 18.567091\n",
      "epoch: 1 step: 350, loss is 5.8980117\n",
      "epoch: 1 step: 351, loss is 16.104399\n",
      "epoch: 1 step: 352, loss is 7.775352\n",
      "epoch: 1 step: 353, loss is 5.3579774\n",
      "epoch: 1 step: 354, loss is 4.0566053\n",
      "epoch: 1 step: 355, loss is 6.556756\n",
      "epoch: 1 step: 356, loss is 1.8250645\n",
      "epoch: 1 step: 357, loss is 5.080116\n",
      "epoch: 1 step: 358, loss is 4.5969048\n",
      "epoch: 1 step: 359, loss is 4.02367\n",
      "epoch: 1 step: 360, loss is 18.282087\n",
      "epoch: 1 step: 361, loss is 12.694061\n",
      "epoch: 1 step: 362, loss is 12.354276\n",
      "epoch: 1 step: 363, loss is 7.8570275\n",
      "epoch: 1 step: 364, loss is 2.7255073\n",
      "epoch: 1 step: 365, loss is 13.490703\n",
      "epoch: 1 step: 366, loss is 7.2164245\n",
      "epoch: 1 step: 367, loss is 13.530998\n",
      "epoch: 1 step: 368, loss is 11.5138035\n",
      "epoch: 1 step: 369, loss is 13.798487\n",
      "epoch: 1 step: 370, loss is 4.251083\n",
      "epoch: 1 step: 371, loss is 5.4539146\n",
      "epoch: 1 step: 372, loss is 5.3844047\n",
      "epoch: 1 step: 373, loss is 4.1161246\n",
      "epoch: 1 step: 374, loss is 10.430495\n",
      "epoch: 1 step: 375, loss is 7.321725\n",
      "epoch: 1 step: 376, loss is 7.896744\n",
      "epoch: 1 step: 377, loss is 5.5631166\n",
      "epoch: 1 step: 378, loss is 12.331556\n",
      "epoch: 1 step: 379, loss is 1.9966191\n",
      "epoch: 1 step: 380, loss is 4.4902163\n",
      "epoch: 1 step: 381, loss is 4.982368\n",
      "epoch: 1 step: 382, loss is 11.313365\n",
      "epoch: 1 step: 383, loss is 12.783118\n",
      "epoch: 1 step: 384, loss is 4.868557\n",
      "epoch: 1 step: 385, loss is 7.2009416\n",
      "epoch: 1 step: 386, loss is 4.927545\n",
      "epoch: 1 step: 387, loss is 7.1093187\n",
      "epoch: 1 step: 388, loss is 5.77129\n",
      "epoch: 1 step: 389, loss is 8.019076\n",
      "epoch: 1 step: 390, loss is 9.89576\n",
      "epoch: 1 step: 391, loss is 11.473057\n",
      "epoch: 1 step: 392, loss is 3.8957233\n",
      "epoch: 1 step: 393, loss is 1.7264107\n",
      "epoch: 1 step: 394, loss is 9.8388815\n",
      "epoch: 1 step: 395, loss is 6.835823\n",
      "epoch: 1 step: 396, loss is 5.9300346\n",
      "epoch: 1 step: 397, loss is 13.365226\n",
      "epoch: 1 step: 398, loss is 6.6358147\n",
      "epoch: 1 step: 399, loss is 11.47153\n",
      "epoch: 1 step: 400, loss is 7.2303286\n",
      "Train epoch time: 1794325.439 ms, per step time: 4485.814 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 09:32:00,659 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 09:32:00,661 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 09:32:04,107 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.4054458796087876 T+60 min: 0.16474475307855177 T+120 min: 0.09442198339292594\n",
      "2024-01-31 09:32:04,181 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1, loss is 3.5902307\n",
      "epoch: 2 step: 2, loss is 6.164537\n",
      "epoch: 2 step: 3, loss is 11.180219\n",
      "epoch: 2 step: 4, loss is 11.332051\n",
      "epoch: 2 step: 5, loss is 4.4809947\n",
      "epoch: 2 step: 6, loss is 6.9257097\n",
      "epoch: 2 step: 7, loss is 7.415494\n",
      "epoch: 2 step: 8, loss is 11.204009\n",
      "epoch: 2 step: 9, loss is 8.37794\n",
      "epoch: 2 step: 10, loss is 9.490828\n",
      "epoch: 2 step: 11, loss is 2.3988461\n",
      "epoch: 2 step: 12, loss is 6.1954045\n",
      "epoch: 2 step: 13, loss is 12.88989\n",
      "epoch: 2 step: 14, loss is 14.573158\n",
      "epoch: 2 step: 15, loss is 6.751909\n",
      "epoch: 2 step: 16, loss is 6.6825066\n",
      "epoch: 2 step: 17, loss is 8.922988\n",
      "epoch: 2 step: 18, loss is 10.171614\n",
      "epoch: 2 step: 19, loss is 21.820257\n",
      "epoch: 2 step: 20, loss is 8.730773\n",
      "epoch: 2 step: 21, loss is 11.956616\n",
      "epoch: 2 step: 22, loss is 12.381399\n",
      "epoch: 2 step: 23, loss is 6.375179\n",
      "epoch: 2 step: 24, loss is 6.8310676\n",
      "epoch: 2 step: 25, loss is 9.096922\n",
      "epoch: 2 step: 26, loss is 8.052887\n",
      "epoch: 2 step: 27, loss is 10.0189085\n",
      "epoch: 2 step: 28, loss is 6.9568367\n",
      "epoch: 2 step: 29, loss is 8.110953\n",
      "epoch: 2 step: 30, loss is 7.743202\n",
      "epoch: 2 step: 31, loss is 9.142183\n",
      "epoch: 2 step: 32, loss is 3.963022\n",
      "epoch: 2 step: 33, loss is 10.550201\n",
      "epoch: 2 step: 34, loss is 12.281748\n",
      "epoch: 2 step: 35, loss is 13.465476\n",
      "epoch: 2 step: 36, loss is 12.146997\n",
      "epoch: 2 step: 37, loss is 5.2931256\n",
      "epoch: 2 step: 38, loss is 12.128537\n",
      "epoch: 2 step: 39, loss is 4.236503\n",
      "epoch: 2 step: 40, loss is 12.060542\n",
      "epoch: 2 step: 41, loss is 3.402657\n",
      "epoch: 2 step: 42, loss is 15.347463\n",
      "epoch: 2 step: 43, loss is 8.246298\n",
      "epoch: 2 step: 44, loss is 10.587758\n",
      "epoch: 2 step: 45, loss is 12.190825\n",
      "epoch: 2 step: 46, loss is 12.451841\n",
      "epoch: 2 step: 47, loss is 7.1361947\n",
      "epoch: 2 step: 48, loss is 11.336909\n",
      "epoch: 2 step: 49, loss is 7.309054\n",
      "epoch: 2 step: 50, loss is 4.2109222\n",
      "epoch: 2 step: 51, loss is 13.240636\n",
      "epoch: 2 step: 52, loss is 9.888194\n",
      "epoch: 2 step: 53, loss is 13.570625\n",
      "epoch: 2 step: 54, loss is 13.212143\n",
      "epoch: 2 step: 55, loss is 8.365734\n",
      "epoch: 2 step: 56, loss is 7.16347\n",
      "epoch: 2 step: 57, loss is 5.101911\n",
      "epoch: 2 step: 58, loss is 4.6784286\n",
      "epoch: 2 step: 59, loss is 6.5032053\n",
      "epoch: 2 step: 60, loss is 6.365212\n",
      "epoch: 2 step: 61, loss is 9.545447\n",
      "epoch: 2 step: 62, loss is 5.310281\n",
      "epoch: 2 step: 63, loss is 5.344236\n",
      "epoch: 2 step: 64, loss is 4.1562037\n",
      "epoch: 2 step: 65, loss is 5.8225923\n",
      "epoch: 2 step: 66, loss is 4.090275\n",
      "epoch: 2 step: 67, loss is 11.484424\n",
      "epoch: 2 step: 68, loss is 7.546144\n",
      "epoch: 2 step: 69, loss is 8.047069\n",
      "epoch: 2 step: 70, loss is 11.787371\n",
      "epoch: 2 step: 71, loss is 7.0848565\n",
      "epoch: 2 step: 72, loss is 6.30876\n",
      "epoch: 2 step: 73, loss is 12.056404\n",
      "epoch: 2 step: 74, loss is 12.668941\n",
      "epoch: 2 step: 75, loss is 8.926393\n",
      "epoch: 2 step: 76, loss is 2.7328854\n",
      "epoch: 2 step: 77, loss is 9.116481\n",
      "epoch: 2 step: 78, loss is 3.9502122\n",
      "epoch: 2 step: 79, loss is 14.535497\n",
      "epoch: 2 step: 80, loss is 13.295636\n",
      "epoch: 2 step: 81, loss is 10.152904\n",
      "epoch: 2 step: 82, loss is 9.260558\n",
      "epoch: 2 step: 83, loss is 16.8603\n",
      "epoch: 2 step: 84, loss is 11.238963\n",
      "epoch: 2 step: 85, loss is 6.2139883\n",
      "epoch: 2 step: 86, loss is 2.766853\n",
      "epoch: 2 step: 87, loss is 16.447927\n",
      "epoch: 2 step: 88, loss is 10.797151\n",
      "epoch: 2 step: 89, loss is 8.251236\n",
      "epoch: 2 step: 90, loss is 5.7845345\n",
      "epoch: 2 step: 91, loss is 5.6928062\n",
      "epoch: 2 step: 92, loss is 11.224189\n",
      "epoch: 2 step: 93, loss is 15.644973\n",
      "epoch: 2 step: 94, loss is 7.944646\n",
      "epoch: 2 step: 95, loss is 11.027203\n",
      "epoch: 2 step: 96, loss is 16.354975\n",
      "epoch: 2 step: 97, loss is 12.1733\n",
      "epoch: 2 step: 98, loss is 8.86968\n",
      "epoch: 2 step: 99, loss is 5.985891\n",
      "epoch: 2 step: 100, loss is 13.9713745\n",
      "epoch: 2 step: 101, loss is 9.478367\n",
      "epoch: 2 step: 102, loss is 13.662224\n",
      "epoch: 2 step: 103, loss is 11.494834\n",
      "epoch: 2 step: 104, loss is 11.579443\n",
      "epoch: 2 step: 105, loss is 12.76338\n",
      "epoch: 2 step: 106, loss is 6.647256\n",
      "epoch: 2 step: 107, loss is 6.5973277\n",
      "epoch: 2 step: 108, loss is 23.077032\n",
      "epoch: 2 step: 109, loss is 8.376225\n",
      "epoch: 2 step: 110, loss is 8.016612\n",
      "epoch: 2 step: 111, loss is 4.042365\n",
      "epoch: 2 step: 112, loss is 11.550816\n",
      "epoch: 2 step: 113, loss is 9.601252\n",
      "epoch: 2 step: 114, loss is 7.6853943\n",
      "epoch: 2 step: 115, loss is 7.0721946\n",
      "epoch: 2 step: 116, loss is 3.6418023\n",
      "epoch: 2 step: 117, loss is 2.6425476\n",
      "epoch: 2 step: 118, loss is 3.4654794\n",
      "epoch: 2 step: 119, loss is 7.8887343\n",
      "epoch: 2 step: 120, loss is 7.913855\n",
      "epoch: 2 step: 121, loss is 8.613564\n",
      "epoch: 2 step: 122, loss is 8.014841\n",
      "epoch: 2 step: 123, loss is 11.698581\n",
      "epoch: 2 step: 124, loss is 7.009118\n",
      "epoch: 2 step: 125, loss is 3.2938175\n",
      "epoch: 2 step: 126, loss is 11.201624\n",
      "epoch: 2 step: 127, loss is 10.113303\n",
      "epoch: 2 step: 128, loss is 5.4597983\n",
      "epoch: 2 step: 129, loss is 6.9519067\n",
      "epoch: 2 step: 130, loss is 3.3263035\n",
      "epoch: 2 step: 131, loss is 13.771629\n",
      "epoch: 2 step: 132, loss is 8.181102\n",
      "epoch: 2 step: 133, loss is 4.8423343\n",
      "epoch: 2 step: 134, loss is 6.2169724\n",
      "epoch: 2 step: 135, loss is 6.5294876\n",
      "epoch: 2 step: 136, loss is 4.0749464\n",
      "epoch: 2 step: 137, loss is 4.970653\n",
      "epoch: 2 step: 138, loss is 2.545008\n",
      "epoch: 2 step: 139, loss is 6.7413993\n",
      "epoch: 2 step: 140, loss is 5.195244\n",
      "epoch: 2 step: 141, loss is 11.366359\n",
      "epoch: 2 step: 142, loss is 12.9999695\n",
      "epoch: 2 step: 143, loss is 9.889552\n",
      "epoch: 2 step: 144, loss is 11.725775\n",
      "epoch: 2 step: 145, loss is 8.922037\n",
      "epoch: 2 step: 146, loss is 9.956292\n",
      "epoch: 2 step: 147, loss is 3.9910653\n",
      "epoch: 2 step: 148, loss is 4.125259\n",
      "epoch: 2 step: 149, loss is 5.675421\n",
      "epoch: 2 step: 150, loss is 10.2696295\n",
      "epoch: 2 step: 151, loss is 14.99657\n",
      "epoch: 2 step: 152, loss is 12.620851\n",
      "epoch: 2 step: 153, loss is 10.539119\n",
      "epoch: 2 step: 154, loss is 7.774999\n",
      "epoch: 2 step: 155, loss is 14.334155\n",
      "epoch: 2 step: 156, loss is 3.2186348\n",
      "epoch: 2 step: 157, loss is 10.7718115\n",
      "epoch: 2 step: 158, loss is 15.400685\n",
      "epoch: 2 step: 159, loss is 7.9398394\n",
      "epoch: 2 step: 160, loss is 4.3938217\n",
      "epoch: 2 step: 161, loss is 12.714574\n",
      "epoch: 2 step: 162, loss is 3.2595139\n",
      "epoch: 2 step: 163, loss is 12.930966\n",
      "epoch: 2 step: 164, loss is 6.246062\n",
      "epoch: 2 step: 165, loss is 16.100668\n",
      "epoch: 2 step: 166, loss is 12.145316\n",
      "epoch: 2 step: 167, loss is 7.848287\n",
      "epoch: 2 step: 168, loss is 7.352586\n",
      "epoch: 2 step: 169, loss is 7.0305924\n",
      "epoch: 2 step: 170, loss is 2.8503387\n",
      "epoch: 2 step: 171, loss is 4.4784603\n",
      "epoch: 2 step: 172, loss is 8.702354\n",
      "epoch: 2 step: 173, loss is 4.5586495\n",
      "epoch: 2 step: 174, loss is 10.117444\n",
      "epoch: 2 step: 175, loss is 9.310026\n",
      "epoch: 2 step: 176, loss is 4.739387\n",
      "epoch: 2 step: 177, loss is 17.377935\n",
      "epoch: 2 step: 178, loss is 17.068823\n",
      "epoch: 2 step: 179, loss is 13.092015\n",
      "epoch: 2 step: 180, loss is 15.346863\n",
      "epoch: 2 step: 181, loss is 3.5874317\n",
      "epoch: 2 step: 182, loss is 12.904947\n",
      "epoch: 2 step: 183, loss is 16.304346\n",
      "epoch: 2 step: 184, loss is 7.8395343\n",
      "epoch: 2 step: 185, loss is 5.1330028\n",
      "epoch: 2 step: 186, loss is 10.590071\n",
      "epoch: 2 step: 187, loss is 3.4636362\n",
      "epoch: 2 step: 188, loss is 11.427713\n",
      "epoch: 2 step: 189, loss is 5.3968816\n",
      "epoch: 2 step: 190, loss is 10.040416\n",
      "epoch: 2 step: 191, loss is 9.07088\n",
      "epoch: 2 step: 192, loss is 5.1004047\n",
      "epoch: 2 step: 193, loss is 12.069837\n",
      "epoch: 2 step: 194, loss is 13.48926\n",
      "epoch: 2 step: 195, loss is 9.757981\n",
      "epoch: 2 step: 196, loss is 16.034136\n",
      "epoch: 2 step: 197, loss is 13.260974\n",
      "epoch: 2 step: 198, loss is 6.974724\n",
      "epoch: 2 step: 199, loss is 6.953617\n",
      "epoch: 2 step: 200, loss is 4.634584\n",
      "epoch: 2 step: 201, loss is 7.028338\n",
      "epoch: 2 step: 202, loss is 11.323602\n",
      "epoch: 2 step: 203, loss is 5.562336\n",
      "epoch: 2 step: 204, loss is 8.291891\n",
      "epoch: 2 step: 205, loss is 2.1244857\n",
      "epoch: 2 step: 206, loss is 3.8604717\n",
      "epoch: 2 step: 207, loss is 12.692039\n",
      "epoch: 2 step: 208, loss is 6.9932733\n",
      "epoch: 2 step: 209, loss is 9.076287\n",
      "epoch: 2 step: 210, loss is 9.723704\n",
      "epoch: 2 step: 211, loss is 5.2368865\n",
      "epoch: 2 step: 212, loss is 5.199726\n",
      "epoch: 2 step: 213, loss is 7.7142577\n",
      "epoch: 2 step: 214, loss is 12.54171\n",
      "epoch: 2 step: 215, loss is 9.585287\n",
      "epoch: 2 step: 216, loss is 5.419639\n",
      "epoch: 2 step: 217, loss is 9.889884\n",
      "epoch: 2 step: 218, loss is 10.124169\n",
      "epoch: 2 step: 219, loss is 6.3251414\n",
      "epoch: 2 step: 220, loss is 4.730331\n",
      "epoch: 2 step: 221, loss is 4.8017716\n",
      "epoch: 2 step: 222, loss is 6.314808\n",
      "epoch: 2 step: 223, loss is 11.345702\n",
      "epoch: 2 step: 224, loss is 12.907297\n",
      "epoch: 2 step: 225, loss is 8.3995285\n",
      "epoch: 2 step: 226, loss is 13.3998995\n",
      "epoch: 2 step: 227, loss is 11.626922\n",
      "epoch: 2 step: 228, loss is 16.938524\n",
      "epoch: 2 step: 229, loss is 7.875486\n",
      "epoch: 2 step: 230, loss is 1.01351\n",
      "epoch: 2 step: 231, loss is 9.103618\n",
      "epoch: 2 step: 232, loss is 6.10383\n",
      "epoch: 2 step: 233, loss is 4.0472193\n",
      "epoch: 2 step: 234, loss is 4.7144976\n",
      "epoch: 2 step: 235, loss is 5.9155507\n",
      "epoch: 2 step: 236, loss is 16.520493\n",
      "epoch: 2 step: 237, loss is 4.443886\n",
      "epoch: 2 step: 238, loss is 10.625236\n",
      "epoch: 2 step: 239, loss is 6.502607\n",
      "epoch: 2 step: 240, loss is 7.6038527\n",
      "epoch: 2 step: 241, loss is 7.593755\n",
      "epoch: 2 step: 242, loss is 12.446227\n",
      "epoch: 2 step: 243, loss is 6.950078\n",
      "epoch: 2 step: 244, loss is 10.6412\n",
      "epoch: 2 step: 245, loss is 16.961386\n",
      "epoch: 2 step: 246, loss is 12.671943\n",
      "epoch: 2 step: 247, loss is 10.83973\n",
      "epoch: 2 step: 248, loss is 4.867165\n",
      "epoch: 2 step: 249, loss is 4.085074\n",
      "epoch: 2 step: 250, loss is 15.363601\n",
      "epoch: 2 step: 251, loss is 13.196632\n",
      "epoch: 2 step: 252, loss is 8.090506\n",
      "epoch: 2 step: 253, loss is 4.4392686\n",
      "epoch: 2 step: 254, loss is 6.09036\n",
      "epoch: 2 step: 255, loss is 8.64077\n",
      "epoch: 2 step: 256, loss is 9.250715\n",
      "epoch: 2 step: 257, loss is 8.768018\n",
      "epoch: 2 step: 258, loss is 16.663458\n",
      "epoch: 2 step: 259, loss is 8.535916\n",
      "epoch: 2 step: 260, loss is 6.805487\n",
      "epoch: 2 step: 261, loss is 2.2531843\n",
      "epoch: 2 step: 262, loss is 7.893066\n",
      "epoch: 2 step: 263, loss is 19.049095\n",
      "epoch: 2 step: 264, loss is 7.469293\n",
      "epoch: 2 step: 265, loss is 5.9620824\n",
      "epoch: 2 step: 266, loss is 18.863585\n",
      "epoch: 2 step: 267, loss is 9.773634\n",
      "epoch: 2 step: 268, loss is 14.89872\n",
      "epoch: 2 step: 269, loss is 5.6893783\n",
      "epoch: 2 step: 270, loss is 5.9205475\n",
      "epoch: 2 step: 271, loss is 12.429119\n",
      "epoch: 2 step: 272, loss is 5.094901\n",
      "epoch: 2 step: 273, loss is 11.725877\n",
      "epoch: 2 step: 274, loss is 4.596536\n",
      "epoch: 2 step: 275, loss is 7.5479484\n",
      "epoch: 2 step: 276, loss is 9.535804\n",
      "epoch: 2 step: 277, loss is 13.170703\n",
      "epoch: 2 step: 278, loss is 2.9478254\n",
      "epoch: 2 step: 279, loss is 5.497151\n",
      "epoch: 2 step: 280, loss is 7.469646\n",
      "epoch: 2 step: 281, loss is 2.7707424\n",
      "epoch: 2 step: 282, loss is 6.3240294\n",
      "epoch: 2 step: 283, loss is 10.455788\n",
      "epoch: 2 step: 284, loss is 3.974795\n",
      "epoch: 2 step: 285, loss is 10.164766\n",
      "epoch: 2 step: 286, loss is 8.665133\n",
      "epoch: 2 step: 287, loss is 15.268677\n",
      "epoch: 2 step: 288, loss is 12.318749\n",
      "epoch: 2 step: 289, loss is 10.5265\n",
      "epoch: 2 step: 290, loss is 8.4838295\n",
      "epoch: 2 step: 291, loss is 11.364627\n",
      "epoch: 2 step: 292, loss is 16.513672\n",
      "epoch: 2 step: 293, loss is 16.86052\n",
      "epoch: 2 step: 294, loss is 13.195221\n",
      "epoch: 2 step: 295, loss is 13.271289\n",
      "epoch: 2 step: 296, loss is 4.1092906\n",
      "epoch: 2 step: 297, loss is 11.367045\n",
      "epoch: 2 step: 298, loss is 10.060623\n",
      "epoch: 2 step: 299, loss is 6.2831507\n",
      "epoch: 2 step: 300, loss is 5.819244\n",
      "epoch: 2 step: 301, loss is 4.459101\n",
      "epoch: 2 step: 302, loss is 13.922836\n",
      "epoch: 2 step: 303, loss is 4.2946906\n",
      "epoch: 2 step: 304, loss is 4.33151\n",
      "epoch: 2 step: 305, loss is 14.268569\n",
      "epoch: 2 step: 306, loss is 4.8524013\n",
      "epoch: 2 step: 307, loss is 15.420482\n",
      "epoch: 2 step: 308, loss is 5.64585\n",
      "epoch: 2 step: 309, loss is 16.402136\n",
      "epoch: 2 step: 310, loss is 10.513843\n",
      "epoch: 2 step: 311, loss is 12.488105\n",
      "epoch: 2 step: 312, loss is 6.0826755\n",
      "epoch: 2 step: 313, loss is 3.4336698\n",
      "epoch: 2 step: 314, loss is 7.6654787\n",
      "epoch: 2 step: 315, loss is 12.411796\n",
      "epoch: 2 step: 316, loss is 7.0432773\n",
      "epoch: 2 step: 317, loss is 12.285403\n",
      "epoch: 2 step: 318, loss is 2.9164684\n",
      "epoch: 2 step: 319, loss is 6.997214\n",
      "epoch: 2 step: 320, loss is 6.231052\n",
      "epoch: 2 step: 321, loss is 6.1908035\n",
      "epoch: 2 step: 322, loss is 3.4095154\n",
      "epoch: 2 step: 323, loss is 8.235909\n",
      "epoch: 2 step: 324, loss is 3.839009\n",
      "epoch: 2 step: 325, loss is 7.9122095\n",
      "epoch: 2 step: 326, loss is 10.4650755\n",
      "epoch: 2 step: 327, loss is 6.0926514\n",
      "epoch: 2 step: 328, loss is 10.687957\n",
      "epoch: 2 step: 329, loss is 7.848503\n",
      "epoch: 2 step: 330, loss is 12.805781\n",
      "epoch: 2 step: 331, loss is 6.375276\n",
      "epoch: 2 step: 332, loss is 8.033614\n",
      "epoch: 2 step: 333, loss is 12.198896\n",
      "epoch: 2 step: 334, loss is 6.2554355\n",
      "epoch: 2 step: 335, loss is 7.6766396\n",
      "epoch: 2 step: 336, loss is 8.579577\n",
      "epoch: 2 step: 337, loss is 10.6671095\n",
      "epoch: 2 step: 338, loss is 8.020312\n",
      "epoch: 2 step: 339, loss is 9.489757\n",
      "epoch: 2 step: 340, loss is 12.269236\n",
      "epoch: 2 step: 341, loss is 27.296696\n",
      "epoch: 2 step: 342, loss is 5.171322\n",
      "epoch: 2 step: 343, loss is 11.728749\n",
      "epoch: 2 step: 344, loss is 11.169777\n",
      "epoch: 2 step: 345, loss is 5.458398\n",
      "epoch: 2 step: 346, loss is 5.78911\n",
      "epoch: 2 step: 347, loss is 2.9274514\n",
      "epoch: 2 step: 348, loss is 7.4018693\n",
      "epoch: 2 step: 349, loss is 9.33463\n",
      "epoch: 2 step: 350, loss is 9.200088\n",
      "epoch: 2 step: 351, loss is 6.134559\n",
      "epoch: 2 step: 352, loss is 5.7578588\n",
      "epoch: 2 step: 353, loss is 8.868519\n",
      "epoch: 2 step: 354, loss is 2.8058476\n",
      "epoch: 2 step: 355, loss is 8.246224\n",
      "epoch: 2 step: 356, loss is 6.90008\n",
      "epoch: 2 step: 357, loss is 11.968184\n",
      "epoch: 2 step: 358, loss is 12.93239\n",
      "epoch: 2 step: 359, loss is 5.4736686\n",
      "epoch: 2 step: 360, loss is 13.29988\n",
      "epoch: 2 step: 361, loss is 8.791315\n",
      "epoch: 2 step: 362, loss is 11.016503\n",
      "epoch: 2 step: 363, loss is 16.835129\n",
      "epoch: 2 step: 364, loss is 11.18768\n",
      "epoch: 2 step: 365, loss is 17.12584\n",
      "epoch: 2 step: 366, loss is 5.4613247\n",
      "epoch: 2 step: 367, loss is 9.642198\n",
      "epoch: 2 step: 368, loss is 6.4991746\n",
      "epoch: 2 step: 369, loss is 10.14177\n",
      "epoch: 2 step: 370, loss is 6.7438393\n",
      "epoch: 2 step: 371, loss is 10.260614\n",
      "epoch: 2 step: 372, loss is 2.3388724\n",
      "epoch: 2 step: 373, loss is 10.906717\n",
      "epoch: 2 step: 374, loss is 4.3277445\n",
      "epoch: 2 step: 375, loss is 9.924989\n",
      "epoch: 2 step: 376, loss is 10.085904\n",
      "epoch: 2 step: 377, loss is 8.016669\n",
      "epoch: 2 step: 378, loss is 9.791915\n",
      "epoch: 2 step: 379, loss is 13.639999\n",
      "epoch: 2 step: 380, loss is 12.051585\n",
      "epoch: 2 step: 381, loss is 9.764248\n",
      "epoch: 2 step: 382, loss is 10.555309\n",
      "epoch: 2 step: 383, loss is 13.815684\n",
      "epoch: 2 step: 384, loss is 4.407768\n",
      "epoch: 2 step: 385, loss is 14.262488\n",
      "epoch: 2 step: 386, loss is 10.830002\n",
      "epoch: 2 step: 387, loss is 10.928685\n",
      "epoch: 2 step: 388, loss is 7.9791884\n",
      "epoch: 2 step: 389, loss is 15.709459\n",
      "epoch: 2 step: 390, loss is 15.412381\n",
      "epoch: 2 step: 391, loss is 9.153276\n",
      "epoch: 2 step: 392, loss is 9.770236\n",
      "epoch: 2 step: 393, loss is 13.901111\n",
      "epoch: 2 step: 394, loss is 8.2784195\n",
      "epoch: 2 step: 395, loss is 5.905315\n",
      "epoch: 2 step: 396, loss is 13.185033\n",
      "epoch: 2 step: 397, loss is 12.38396\n",
      "epoch: 2 step: 398, loss is 7.7851076\n",
      "epoch: 2 step: 399, loss is 6.364196\n",
      "epoch: 2 step: 400, loss is 11.064963\n",
      "Train epoch time: 1688639.108 ms, per step time: 4221.598 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:00:12,836 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 10:00:12,838 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:00:16,213 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.41709989523909563 T+60 min: 0.16894114336218546 T+120 min: 0.10467792846088278\n",
      "2024-01-31 10:00:16,291 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1, loss is 7.1252494\n",
      "epoch: 3 step: 2, loss is 11.036712\n",
      "epoch: 3 step: 3, loss is 5.4519153\n",
      "epoch: 3 step: 4, loss is 5.8808107\n",
      "epoch: 3 step: 5, loss is 4.4894466\n",
      "epoch: 3 step: 6, loss is 4.2037396\n",
      "epoch: 3 step: 7, loss is 7.131599\n",
      "epoch: 3 step: 8, loss is 7.6371865\n",
      "epoch: 3 step: 9, loss is 10.900062\n",
      "epoch: 3 step: 10, loss is 6.7450824\n",
      "epoch: 3 step: 11, loss is 8.569858\n",
      "epoch: 3 step: 12, loss is 12.626097\n",
      "epoch: 3 step: 13, loss is 16.801985\n",
      "epoch: 3 step: 14, loss is 12.869039\n",
      "epoch: 3 step: 15, loss is 12.314567\n",
      "epoch: 3 step: 16, loss is 10.593638\n",
      "epoch: 3 step: 17, loss is 7.0162005\n",
      "epoch: 3 step: 18, loss is 14.256413\n",
      "epoch: 3 step: 19, loss is 6.391328\n",
      "epoch: 3 step: 20, loss is 6.419895\n",
      "epoch: 3 step: 21, loss is 12.473334\n",
      "epoch: 3 step: 22, loss is 10.50286\n",
      "epoch: 3 step: 23, loss is 6.199636\n",
      "epoch: 3 step: 24, loss is 12.170155\n",
      "epoch: 3 step: 25, loss is 10.767848\n",
      "epoch: 3 step: 26, loss is 3.7217011\n",
      "epoch: 3 step: 27, loss is 7.41636\n",
      "epoch: 3 step: 28, loss is 8.754957\n",
      "epoch: 3 step: 29, loss is 10.721056\n",
      "epoch: 3 step: 30, loss is 13.41573\n",
      "epoch: 3 step: 31, loss is 12.369431\n",
      "epoch: 3 step: 32, loss is 12.527661\n",
      "epoch: 3 step: 33, loss is 8.318936\n",
      "epoch: 3 step: 34, loss is 6.968779\n",
      "epoch: 3 step: 35, loss is 10.02579\n",
      "epoch: 3 step: 36, loss is 10.751868\n",
      "epoch: 3 step: 37, loss is 7.629959\n",
      "epoch: 3 step: 38, loss is 5.0034227\n",
      "epoch: 3 step: 39, loss is 4.653483\n",
      "epoch: 3 step: 40, loss is 8.515567\n",
      "epoch: 3 step: 41, loss is 8.258481\n",
      "epoch: 3 step: 42, loss is 12.310803\n",
      "epoch: 3 step: 43, loss is 8.894664\n",
      "epoch: 3 step: 44, loss is 8.478974\n",
      "epoch: 3 step: 45, loss is 11.548934\n",
      "epoch: 3 step: 46, loss is 11.114578\n",
      "epoch: 3 step: 47, loss is 11.374794\n",
      "epoch: 3 step: 48, loss is 12.539844\n",
      "epoch: 3 step: 49, loss is 8.426234\n",
      "epoch: 3 step: 50, loss is 13.767882\n",
      "epoch: 3 step: 51, loss is 16.16264\n",
      "epoch: 3 step: 52, loss is 11.728778\n",
      "epoch: 3 step: 53, loss is 13.91986\n",
      "epoch: 3 step: 54, loss is 8.307953\n",
      "epoch: 3 step: 55, loss is 11.460391\n",
      "epoch: 3 step: 56, loss is 4.677033\n",
      "epoch: 3 step: 57, loss is 10.287713\n",
      "epoch: 3 step: 58, loss is 4.0899553\n",
      "epoch: 3 step: 59, loss is 13.14405\n",
      "epoch: 3 step: 60, loss is 9.926351\n",
      "epoch: 3 step: 61, loss is 3.4921708\n",
      "epoch: 3 step: 62, loss is 9.957998\n",
      "epoch: 3 step: 63, loss is 9.321293\n",
      "epoch: 3 step: 64, loss is 11.367603\n",
      "epoch: 3 step: 65, loss is 3.9579086\n",
      "epoch: 3 step: 66, loss is 13.182986\n",
      "epoch: 3 step: 67, loss is 10.440848\n",
      "epoch: 3 step: 68, loss is 7.2526407\n",
      "epoch: 3 step: 69, loss is 11.419489\n",
      "epoch: 3 step: 70, loss is 11.404378\n",
      "epoch: 3 step: 71, loss is 12.730815\n",
      "epoch: 3 step: 72, loss is 8.048335\n",
      "epoch: 3 step: 73, loss is 3.4358842\n",
      "epoch: 3 step: 74, loss is 5.516293\n",
      "epoch: 3 step: 75, loss is 4.7600703\n",
      "epoch: 3 step: 76, loss is 10.421222\n",
      "epoch: 3 step: 77, loss is 10.347287\n",
      "epoch: 3 step: 78, loss is 6.4398055\n",
      "epoch: 3 step: 79, loss is 9.895462\n",
      "epoch: 3 step: 80, loss is 3.4589546\n",
      "epoch: 3 step: 81, loss is 5.2512436\n",
      "epoch: 3 step: 82, loss is 12.645004\n",
      "epoch: 3 step: 83, loss is 2.219214\n",
      "epoch: 3 step: 84, loss is 9.147678\n",
      "epoch: 3 step: 85, loss is 5.455143\n",
      "epoch: 3 step: 86, loss is 3.0193756\n",
      "epoch: 3 step: 87, loss is 11.154009\n",
      "epoch: 3 step: 88, loss is 17.096634\n",
      "epoch: 3 step: 89, loss is 9.082738\n",
      "epoch: 3 step: 90, loss is 13.794395\n",
      "epoch: 3 step: 91, loss is 13.460361\n",
      "epoch: 3 step: 92, loss is 6.4926515\n",
      "epoch: 3 step: 93, loss is 17.863716\n",
      "epoch: 3 step: 94, loss is 5.6714053\n",
      "epoch: 3 step: 95, loss is 10.452785\n",
      "epoch: 3 step: 96, loss is 5.5571895\n",
      "epoch: 3 step: 97, loss is 9.122199\n",
      "epoch: 3 step: 98, loss is 13.007586\n",
      "epoch: 3 step: 99, loss is 12.274165\n",
      "epoch: 3 step: 100, loss is 12.593251\n",
      "epoch: 3 step: 101, loss is 19.453524\n",
      "epoch: 3 step: 102, loss is 12.323127\n",
      "epoch: 3 step: 103, loss is 15.943438\n",
      "epoch: 3 step: 104, loss is 7.048824\n",
      "epoch: 3 step: 105, loss is 5.1395874\n",
      "epoch: 3 step: 106, loss is 13.605034\n",
      "epoch: 3 step: 107, loss is 7.143197\n",
      "epoch: 3 step: 108, loss is 16.594166\n",
      "epoch: 3 step: 109, loss is 8.751489\n",
      "epoch: 3 step: 110, loss is 8.513526\n",
      "epoch: 3 step: 111, loss is 15.462524\n",
      "epoch: 3 step: 112, loss is 11.62522\n",
      "epoch: 3 step: 113, loss is 5.876299\n",
      "epoch: 3 step: 114, loss is 9.593172\n",
      "epoch: 3 step: 115, loss is 13.139612\n",
      "epoch: 3 step: 116, loss is 2.3185706\n",
      "epoch: 3 step: 117, loss is 5.492456\n",
      "epoch: 3 step: 118, loss is 21.601189\n",
      "epoch: 3 step: 119, loss is 4.4091845\n",
      "epoch: 3 step: 120, loss is 4.1444793\n",
      "epoch: 3 step: 121, loss is 4.400072\n",
      "epoch: 3 step: 122, loss is 3.8407102\n",
      "epoch: 3 step: 123, loss is 11.795681\n",
      "epoch: 3 step: 124, loss is 14.003606\n",
      "epoch: 3 step: 125, loss is 12.342367\n",
      "epoch: 3 step: 126, loss is 17.124807\n",
      "epoch: 3 step: 127, loss is 5.140582\n",
      "epoch: 3 step: 128, loss is 8.453563\n",
      "epoch: 3 step: 129, loss is 6.9804244\n",
      "epoch: 3 step: 130, loss is 13.676351\n",
      "epoch: 3 step: 131, loss is 5.977342\n",
      "epoch: 3 step: 132, loss is 9.535567\n",
      "epoch: 3 step: 133, loss is 4.9637423\n",
      "epoch: 3 step: 134, loss is 7.6738977\n",
      "epoch: 3 step: 135, loss is 8.824555\n",
      "epoch: 3 step: 136, loss is 4.2818284\n",
      "epoch: 3 step: 137, loss is 7.8294916\n",
      "epoch: 3 step: 138, loss is 9.811589\n",
      "epoch: 3 step: 139, loss is 8.319696\n",
      "epoch: 3 step: 140, loss is 11.833242\n",
      "epoch: 3 step: 141, loss is 9.337647\n",
      "epoch: 3 step: 142, loss is 7.990991\n",
      "epoch: 3 step: 143, loss is 10.311142\n",
      "epoch: 3 step: 144, loss is 8.755572\n",
      "epoch: 3 step: 145, loss is 13.015883\n",
      "epoch: 3 step: 146, loss is 8.193568\n",
      "epoch: 3 step: 147, loss is 7.7664948\n",
      "epoch: 3 step: 148, loss is 6.6714754\n",
      "epoch: 3 step: 149, loss is 12.959691\n",
      "epoch: 3 step: 150, loss is 3.9051225\n",
      "epoch: 3 step: 151, loss is 14.532422\n",
      "epoch: 3 step: 152, loss is 8.112529\n",
      "epoch: 3 step: 153, loss is 3.8627934\n",
      "epoch: 3 step: 154, loss is 6.464882\n",
      "epoch: 3 step: 155, loss is 10.866905\n",
      "epoch: 3 step: 156, loss is 5.3408937\n",
      "epoch: 3 step: 157, loss is 4.6901617\n",
      "epoch: 3 step: 158, loss is 3.9422233\n",
      "epoch: 3 step: 159, loss is 6.9413466\n",
      "epoch: 3 step: 160, loss is 8.41715\n",
      "epoch: 3 step: 161, loss is 18.038269\n",
      "epoch: 3 step: 162, loss is 10.890504\n",
      "epoch: 3 step: 163, loss is 10.213196\n",
      "epoch: 3 step: 164, loss is 5.8512273\n",
      "epoch: 3 step: 165, loss is 19.224508\n",
      "epoch: 3 step: 166, loss is 1.6743206\n",
      "epoch: 3 step: 167, loss is 4.0736403\n",
      "epoch: 3 step: 168, loss is 6.568725\n",
      "epoch: 3 step: 169, loss is 6.5036163\n",
      "epoch: 3 step: 170, loss is 3.2806041\n",
      "epoch: 3 step: 171, loss is 17.350594\n",
      "epoch: 3 step: 172, loss is 10.720379\n",
      "epoch: 3 step: 173, loss is 14.819077\n",
      "epoch: 3 step: 174, loss is 9.348502\n",
      "epoch: 3 step: 175, loss is 8.403157\n",
      "epoch: 3 step: 176, loss is 15.955768\n",
      "epoch: 3 step: 177, loss is 9.932305\n",
      "epoch: 3 step: 178, loss is 8.917662\n",
      "epoch: 3 step: 179, loss is 11.369731\n",
      "epoch: 3 step: 180, loss is 8.441173\n",
      "epoch: 3 step: 181, loss is 3.2800446\n",
      "epoch: 3 step: 182, loss is 18.221891\n",
      "epoch: 3 step: 183, loss is 12.966662\n",
      "epoch: 3 step: 184, loss is 8.09284\n",
      "epoch: 3 step: 185, loss is 12.851425\n",
      "epoch: 3 step: 186, loss is 7.9701095\n",
      "epoch: 3 step: 187, loss is 9.386691\n",
      "epoch: 3 step: 188, loss is 5.9600296\n",
      "epoch: 3 step: 189, loss is 6.260385\n",
      "epoch: 3 step: 190, loss is 6.286342\n",
      "epoch: 3 step: 191, loss is 5.661381\n",
      "epoch: 3 step: 192, loss is 5.211166\n",
      "epoch: 3 step: 193, loss is 4.9982123\n",
      "epoch: 3 step: 194, loss is 12.869987\n",
      "epoch: 3 step: 195, loss is 9.14388\n",
      "epoch: 3 step: 196, loss is 17.957191\n",
      "epoch: 3 step: 197, loss is 4.8586283\n",
      "epoch: 3 step: 198, loss is 15.078257\n",
      "epoch: 3 step: 199, loss is 3.8004525\n",
      "epoch: 3 step: 200, loss is 8.943662\n",
      "epoch: 3 step: 201, loss is 12.095364\n",
      "epoch: 3 step: 202, loss is 7.0641365\n",
      "epoch: 3 step: 203, loss is 14.842824\n",
      "epoch: 3 step: 204, loss is 7.708806\n",
      "epoch: 3 step: 205, loss is 8.222194\n",
      "epoch: 3 step: 206, loss is 10.447627\n",
      "epoch: 3 step: 207, loss is 13.507117\n",
      "epoch: 3 step: 208, loss is 15.489845\n",
      "epoch: 3 step: 209, loss is 8.031699\n",
      "epoch: 3 step: 210, loss is 8.591907\n",
      "epoch: 3 step: 211, loss is 11.864071\n",
      "epoch: 3 step: 212, loss is 12.0543585\n",
      "epoch: 3 step: 213, loss is 19.549475\n",
      "epoch: 3 step: 214, loss is 6.766399\n",
      "epoch: 3 step: 215, loss is 8.157355\n",
      "epoch: 3 step: 216, loss is 16.210495\n",
      "epoch: 3 step: 217, loss is 12.308489\n",
      "epoch: 3 step: 218, loss is 4.317367\n",
      "epoch: 3 step: 219, loss is 15.444658\n",
      "epoch: 3 step: 220, loss is 14.04983\n",
      "epoch: 3 step: 221, loss is 7.7229385\n",
      "epoch: 3 step: 222, loss is 6.3145714\n",
      "epoch: 3 step: 223, loss is 12.22589\n",
      "epoch: 3 step: 224, loss is 14.212875\n",
      "epoch: 3 step: 225, loss is 5.5329223\n",
      "epoch: 3 step: 226, loss is 4.68029\n",
      "epoch: 3 step: 227, loss is 8.454091\n",
      "epoch: 3 step: 228, loss is 17.012182\n",
      "epoch: 3 step: 229, loss is 12.586389\n",
      "epoch: 3 step: 230, loss is 11.180295\n",
      "epoch: 3 step: 231, loss is 9.299583\n",
      "epoch: 3 step: 232, loss is 11.515103\n",
      "epoch: 3 step: 233, loss is 7.7277017\n",
      "epoch: 3 step: 234, loss is 4.2447343\n",
      "epoch: 3 step: 235, loss is 9.053782\n",
      "epoch: 3 step: 236, loss is 5.730511\n",
      "epoch: 3 step: 237, loss is 14.744601\n",
      "epoch: 3 step: 238, loss is 5.662766\n",
      "epoch: 3 step: 239, loss is 5.059889\n",
      "epoch: 3 step: 240, loss is 6.8456607\n",
      "epoch: 3 step: 241, loss is 9.886804\n",
      "epoch: 3 step: 242, loss is 4.11713\n",
      "epoch: 3 step: 243, loss is 5.5154166\n",
      "epoch: 3 step: 244, loss is 3.542528\n",
      "epoch: 3 step: 245, loss is 7.7595096\n",
      "epoch: 3 step: 246, loss is 6.097282\n",
      "epoch: 3 step: 247, loss is 5.7261677\n",
      "epoch: 3 step: 248, loss is 2.6028702\n",
      "epoch: 3 step: 249, loss is 6.0603204\n",
      "epoch: 3 step: 250, loss is 7.755925\n",
      "epoch: 3 step: 251, loss is 7.668538\n",
      "epoch: 3 step: 252, loss is 6.292173\n",
      "epoch: 3 step: 253, loss is 10.9022255\n",
      "epoch: 3 step: 254, loss is 4.363937\n",
      "epoch: 3 step: 255, loss is 6.8618746\n",
      "epoch: 3 step: 256, loss is 6.3894386\n",
      "epoch: 3 step: 257, loss is 12.534091\n",
      "epoch: 3 step: 258, loss is 6.53219\n",
      "epoch: 3 step: 259, loss is 7.040326\n",
      "epoch: 3 step: 260, loss is 17.305487\n",
      "epoch: 3 step: 261, loss is 8.674139\n",
      "epoch: 3 step: 262, loss is 9.027857\n",
      "epoch: 3 step: 263, loss is 8.337772\n",
      "epoch: 3 step: 264, loss is 2.7621582\n",
      "epoch: 3 step: 265, loss is 14.380831\n",
      "epoch: 3 step: 266, loss is 10.283586\n",
      "epoch: 3 step: 267, loss is 13.8352585\n",
      "epoch: 3 step: 268, loss is 4.777553\n",
      "epoch: 3 step: 269, loss is 8.521775\n",
      "epoch: 3 step: 270, loss is 2.294319\n",
      "epoch: 3 step: 271, loss is 8.853145\n",
      "epoch: 3 step: 272, loss is 9.4030695\n",
      "epoch: 3 step: 273, loss is 9.127052\n",
      "epoch: 3 step: 274, loss is 12.889727\n",
      "epoch: 3 step: 275, loss is 2.5375266\n",
      "epoch: 3 step: 276, loss is 8.43682\n",
      "epoch: 3 step: 277, loss is 9.189303\n",
      "epoch: 3 step: 278, loss is 9.4796\n",
      "epoch: 3 step: 279, loss is 5.526674\n",
      "epoch: 3 step: 280, loss is 5.4248643\n",
      "epoch: 3 step: 281, loss is 11.679728\n",
      "epoch: 3 step: 282, loss is 9.076962\n",
      "epoch: 3 step: 283, loss is 7.0416245\n",
      "epoch: 3 step: 284, loss is 13.959948\n",
      "epoch: 3 step: 285, loss is 16.823256\n",
      "epoch: 3 step: 286, loss is 8.523455\n",
      "epoch: 3 step: 287, loss is 9.888581\n",
      "epoch: 3 step: 288, loss is 5.2833495\n",
      "epoch: 3 step: 289, loss is 6.734751\n",
      "epoch: 3 step: 290, loss is 12.886375\n",
      "epoch: 3 step: 291, loss is 8.421905\n",
      "epoch: 3 step: 292, loss is 11.43323\n",
      "epoch: 3 step: 293, loss is 4.6211596\n",
      "epoch: 3 step: 294, loss is 7.200006\n",
      "epoch: 3 step: 295, loss is 6.660711\n",
      "epoch: 3 step: 296, loss is 8.5496855\n",
      "epoch: 3 step: 297, loss is 6.457355\n",
      "epoch: 3 step: 298, loss is 6.649246\n",
      "epoch: 3 step: 299, loss is 7.6583915\n",
      "epoch: 3 step: 300, loss is 12.627669\n",
      "epoch: 3 step: 301, loss is 12.514285\n",
      "epoch: 3 step: 302, loss is 10.519188\n",
      "epoch: 3 step: 303, loss is 10.342556\n",
      "epoch: 3 step: 304, loss is 12.685178\n",
      "epoch: 3 step: 305, loss is 8.385439\n",
      "epoch: 3 step: 306, loss is 5.5591493\n",
      "epoch: 3 step: 307, loss is 7.975984\n",
      "epoch: 3 step: 308, loss is 5.823359\n",
      "epoch: 3 step: 309, loss is 9.8139105\n",
      "epoch: 3 step: 310, loss is 6.145803\n",
      "epoch: 3 step: 311, loss is 6.2630115\n",
      "epoch: 3 step: 312, loss is 11.048338\n",
      "epoch: 3 step: 313, loss is 7.979239\n",
      "epoch: 3 step: 314, loss is 11.66101\n",
      "epoch: 3 step: 315, loss is 14.647682\n",
      "epoch: 3 step: 316, loss is 7.6165605\n",
      "epoch: 3 step: 317, loss is 5.5190253\n",
      "epoch: 3 step: 318, loss is 2.8864295\n",
      "epoch: 3 step: 319, loss is 4.916617\n",
      "epoch: 3 step: 320, loss is 6.548047\n",
      "epoch: 3 step: 321, loss is 9.262445\n",
      "epoch: 3 step: 322, loss is 11.501224\n",
      "epoch: 3 step: 323, loss is 12.685979\n",
      "epoch: 3 step: 324, loss is 8.252933\n",
      "epoch: 3 step: 325, loss is 14.539726\n",
      "epoch: 3 step: 326, loss is 5.4665966\n",
      "epoch: 3 step: 327, loss is 5.227836\n",
      "epoch: 3 step: 328, loss is 7.1446824\n",
      "epoch: 3 step: 329, loss is 1.7398499\n",
      "epoch: 3 step: 330, loss is 10.756945\n",
      "epoch: 3 step: 331, loss is 9.303668\n",
      "epoch: 3 step: 332, loss is 7.2474976\n",
      "epoch: 3 step: 333, loss is 11.460282\n",
      "epoch: 3 step: 334, loss is 8.950673\n",
      "epoch: 3 step: 335, loss is 5.9494348\n",
      "epoch: 3 step: 336, loss is 7.9552536\n",
      "epoch: 3 step: 337, loss is 9.6694355\n",
      "epoch: 3 step: 338, loss is 3.2072227\n",
      "epoch: 3 step: 339, loss is 8.702727\n",
      "epoch: 3 step: 340, loss is 11.835588\n",
      "epoch: 3 step: 341, loss is 9.234789\n",
      "epoch: 3 step: 342, loss is 1.7095547\n",
      "epoch: 3 step: 343, loss is 4.4285936\n",
      "epoch: 3 step: 344, loss is 4.8690267\n",
      "epoch: 3 step: 345, loss is 6.0651603\n",
      "epoch: 3 step: 346, loss is 11.606653\n",
      "epoch: 3 step: 347, loss is 14.800946\n",
      "epoch: 3 step: 348, loss is 4.9116244\n",
      "epoch: 3 step: 349, loss is 14.010162\n",
      "epoch: 3 step: 350, loss is 8.38638\n",
      "epoch: 3 step: 351, loss is 5.9482946\n",
      "epoch: 3 step: 352, loss is 8.202174\n",
      "epoch: 3 step: 353, loss is 5.358973\n",
      "epoch: 3 step: 354, loss is 6.0181065\n",
      "epoch: 3 step: 355, loss is 15.355827\n",
      "epoch: 3 step: 356, loss is 8.254792\n",
      "epoch: 3 step: 357, loss is 9.294754\n",
      "epoch: 3 step: 358, loss is 1.4971765\n",
      "epoch: 3 step: 359, loss is 19.25026\n",
      "epoch: 3 step: 360, loss is 10.0901375\n",
      "epoch: 3 step: 361, loss is 14.025174\n",
      "epoch: 3 step: 362, loss is 7.563031\n",
      "epoch: 3 step: 363, loss is 8.445477\n",
      "epoch: 3 step: 364, loss is 7.2591414\n",
      "epoch: 3 step: 365, loss is 3.5900161\n",
      "epoch: 3 step: 366, loss is 12.366282\n",
      "epoch: 3 step: 367, loss is 15.282715\n",
      "epoch: 3 step: 368, loss is 9.450681\n",
      "epoch: 3 step: 369, loss is 7.346142\n",
      "epoch: 3 step: 370, loss is 12.328713\n",
      "epoch: 3 step: 371, loss is 9.652606\n",
      "epoch: 3 step: 372, loss is 18.507063\n",
      "epoch: 3 step: 373, loss is 17.365095\n",
      "epoch: 3 step: 374, loss is 10.517929\n",
      "epoch: 3 step: 375, loss is 6.246998\n",
      "epoch: 3 step: 376, loss is 4.0740523\n",
      "epoch: 3 step: 377, loss is 5.074087\n",
      "epoch: 3 step: 378, loss is 10.842862\n",
      "epoch: 3 step: 379, loss is 12.703062\n",
      "epoch: 3 step: 380, loss is 8.071118\n",
      "epoch: 3 step: 381, loss is 11.336051\n",
      "epoch: 3 step: 382, loss is 10.191779\n",
      "epoch: 3 step: 383, loss is 13.273868\n",
      "epoch: 3 step: 384, loss is 7.1373506\n",
      "epoch: 3 step: 385, loss is 9.659966\n",
      "epoch: 3 step: 386, loss is 7.5409546\n",
      "epoch: 3 step: 387, loss is 7.9206767\n",
      "epoch: 3 step: 388, loss is 7.165996\n",
      "epoch: 3 step: 389, loss is 4.672729\n",
      "epoch: 3 step: 390, loss is 3.9680245\n",
      "epoch: 3 step: 391, loss is 8.9942875\n",
      "epoch: 3 step: 392, loss is 5.0241065\n",
      "epoch: 3 step: 393, loss is 6.1589537\n",
      "epoch: 3 step: 394, loss is 3.548375\n",
      "epoch: 3 step: 395, loss is 6.6165423\n",
      "epoch: 3 step: 396, loss is 4.777743\n",
      "epoch: 3 step: 397, loss is 3.6817207\n",
      "epoch: 3 step: 398, loss is 5.818244\n",
      "epoch: 3 step: 399, loss is 6.7248154\n",
      "epoch: 3 step: 400, loss is 10.864609\n",
      "Train epoch time: 1690693.724 ms, per step time: 4226.734 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:28:27,000 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 10:28:27,002 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:28:30,512 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.3993438740760541 T+60 min: 0.16725303802177002 T+120 min: 0.0959103616970071\n",
      "2024-01-31 10:28:30,583 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1, loss is 3.676213\n",
      "epoch: 4 step: 2, loss is 6.1458254\n",
      "epoch: 4 step: 3, loss is 3.8185475\n",
      "epoch: 4 step: 4, loss is 6.627117\n",
      "epoch: 4 step: 5, loss is 6.9782486\n",
      "epoch: 4 step: 6, loss is 6.811868\n",
      "epoch: 4 step: 7, loss is 6.6884317\n",
      "epoch: 4 step: 8, loss is 7.3477755\n",
      "epoch: 4 step: 9, loss is 5.200476\n",
      "epoch: 4 step: 10, loss is 12.155771\n",
      "epoch: 4 step: 11, loss is 11.58068\n",
      "epoch: 4 step: 12, loss is 5.4448733\n",
      "epoch: 4 step: 13, loss is 10.812689\n",
      "epoch: 4 step: 14, loss is 12.388344\n",
      "epoch: 4 step: 15, loss is 5.3166175\n",
      "epoch: 4 step: 16, loss is 7.333459\n",
      "epoch: 4 step: 17, loss is 9.206997\n",
      "epoch: 4 step: 18, loss is 3.0782144\n",
      "epoch: 4 step: 19, loss is 5.3736815\n",
      "epoch: 4 step: 20, loss is 12.703902\n",
      "epoch: 4 step: 21, loss is 11.112024\n",
      "epoch: 4 step: 22, loss is 9.309543\n",
      "epoch: 4 step: 23, loss is 16.022741\n",
      "epoch: 4 step: 24, loss is 14.004642\n",
      "epoch: 4 step: 25, loss is 7.8977027\n",
      "epoch: 4 step: 26, loss is 2.6011\n",
      "epoch: 4 step: 27, loss is 4.357134\n",
      "epoch: 4 step: 28, loss is 10.371706\n",
      "epoch: 4 step: 29, loss is 7.375095\n",
      "epoch: 4 step: 30, loss is 7.5128417\n",
      "epoch: 4 step: 31, loss is 7.1043024\n",
      "epoch: 4 step: 32, loss is 6.3426604\n",
      "epoch: 4 step: 33, loss is 4.9876103\n",
      "epoch: 4 step: 34, loss is 5.7143807\n",
      "epoch: 4 step: 35, loss is 23.054178\n",
      "epoch: 4 step: 36, loss is 8.410891\n",
      "epoch: 4 step: 37, loss is 2.590817\n",
      "epoch: 4 step: 38, loss is 13.101186\n",
      "epoch: 4 step: 39, loss is 10.384282\n",
      "epoch: 4 step: 40, loss is 15.3681135\n",
      "epoch: 4 step: 41, loss is 3.6147048\n",
      "epoch: 4 step: 42, loss is 5.2593803\n",
      "epoch: 4 step: 43, loss is 6.159233\n",
      "epoch: 4 step: 44, loss is 14.822476\n",
      "epoch: 4 step: 45, loss is 9.855629\n",
      "epoch: 4 step: 46, loss is 2.013343\n",
      "epoch: 4 step: 47, loss is 5.9026637\n",
      "epoch: 4 step: 48, loss is 6.8767333\n",
      "epoch: 4 step: 49, loss is 11.081061\n",
      "epoch: 4 step: 50, loss is 8.160582\n",
      "epoch: 4 step: 51, loss is 7.699431\n",
      "epoch: 4 step: 52, loss is 9.594963\n",
      "epoch: 4 step: 53, loss is 5.246492\n",
      "epoch: 4 step: 54, loss is 9.238589\n",
      "epoch: 4 step: 55, loss is 12.828422\n",
      "epoch: 4 step: 56, loss is 3.5254242\n",
      "epoch: 4 step: 57, loss is 6.440239\n",
      "epoch: 4 step: 58, loss is 24.6152\n",
      "epoch: 4 step: 59, loss is 19.360817\n",
      "epoch: 4 step: 60, loss is 17.859755\n",
      "epoch: 4 step: 61, loss is 2.831498\n",
      "epoch: 4 step: 62, loss is 7.422414\n",
      "epoch: 4 step: 63, loss is 2.1120486\n",
      "epoch: 4 step: 64, loss is 14.740466\n",
      "epoch: 4 step: 65, loss is 17.857216\n",
      "epoch: 4 step: 66, loss is 10.600756\n",
      "epoch: 4 step: 67, loss is 4.2868834\n",
      "epoch: 4 step: 68, loss is 4.944597\n",
      "epoch: 4 step: 69, loss is 17.163239\n",
      "epoch: 4 step: 70, loss is 4.2221103\n",
      "epoch: 4 step: 71, loss is 10.387584\n",
      "epoch: 4 step: 72, loss is 9.282251\n",
      "epoch: 4 step: 73, loss is 9.199167\n",
      "epoch: 4 step: 74, loss is 6.785553\n",
      "epoch: 4 step: 75, loss is 14.524498\n",
      "epoch: 4 step: 76, loss is 11.74334\n",
      "epoch: 4 step: 77, loss is 6.27148\n",
      "epoch: 4 step: 78, loss is 10.0393305\n",
      "epoch: 4 step: 79, loss is 6.0050945\n",
      "epoch: 4 step: 80, loss is 10.229861\n",
      "epoch: 4 step: 81, loss is 11.787543\n",
      "epoch: 4 step: 82, loss is 4.7233157\n",
      "epoch: 4 step: 83, loss is 6.637301\n",
      "epoch: 4 step: 84, loss is 7.719641\n",
      "epoch: 4 step: 85, loss is 4.12404\n",
      "epoch: 4 step: 86, loss is 17.521246\n",
      "epoch: 4 step: 87, loss is 17.507727\n",
      "epoch: 4 step: 88, loss is 7.7966228\n",
      "epoch: 4 step: 89, loss is 11.815755\n",
      "epoch: 4 step: 90, loss is 9.160973\n",
      "epoch: 4 step: 91, loss is 7.896972\n",
      "epoch: 4 step: 92, loss is 15.70753\n",
      "epoch: 4 step: 93, loss is 6.5210557\n",
      "epoch: 4 step: 94, loss is 6.6325717\n",
      "epoch: 4 step: 95, loss is 11.314981\n",
      "epoch: 4 step: 96, loss is 5.9632664\n",
      "epoch: 4 step: 97, loss is 8.22915\n",
      "epoch: 4 step: 98, loss is 12.918307\n",
      "epoch: 4 step: 99, loss is 4.414189\n",
      "epoch: 4 step: 100, loss is 11.192988\n",
      "epoch: 4 step: 101, loss is 4.5086946\n",
      "epoch: 4 step: 102, loss is 7.328501\n",
      "epoch: 4 step: 103, loss is 4.1611032\n",
      "epoch: 4 step: 104, loss is 14.200145\n",
      "epoch: 4 step: 105, loss is 9.492152\n",
      "epoch: 4 step: 106, loss is 4.991545\n",
      "epoch: 4 step: 107, loss is 5.7460485\n",
      "epoch: 4 step: 108, loss is 6.549302\n",
      "epoch: 4 step: 109, loss is 7.381531\n",
      "epoch: 4 step: 110, loss is 14.290914\n",
      "epoch: 4 step: 111, loss is 6.1140246\n",
      "epoch: 4 step: 112, loss is 6.148664\n",
      "epoch: 4 step: 113, loss is 7.8371353\n",
      "epoch: 4 step: 114, loss is 11.339846\n",
      "epoch: 4 step: 115, loss is 7.606468\n",
      "epoch: 4 step: 116, loss is 7.9452233\n",
      "epoch: 4 step: 117, loss is 6.0036664\n",
      "epoch: 4 step: 118, loss is 10.471092\n",
      "epoch: 4 step: 119, loss is 8.270972\n",
      "epoch: 4 step: 120, loss is 10.283503\n",
      "epoch: 4 step: 121, loss is 12.491603\n",
      "epoch: 4 step: 122, loss is 8.554973\n",
      "epoch: 4 step: 123, loss is 13.23322\n",
      "epoch: 4 step: 124, loss is 13.755976\n",
      "epoch: 4 step: 125, loss is 5.5793405\n",
      "epoch: 4 step: 126, loss is 4.885715\n",
      "epoch: 4 step: 127, loss is 5.8129454\n",
      "epoch: 4 step: 128, loss is 4.6696568\n",
      "epoch: 4 step: 129, loss is 10.603922\n",
      "epoch: 4 step: 130, loss is 13.363962\n",
      "epoch: 4 step: 131, loss is 10.523055\n",
      "epoch: 4 step: 132, loss is 5.512915\n",
      "epoch: 4 step: 133, loss is 13.945411\n",
      "epoch: 4 step: 134, loss is 10.778062\n",
      "epoch: 4 step: 135, loss is 8.135046\n",
      "epoch: 4 step: 136, loss is 13.848558\n",
      "epoch: 4 step: 137, loss is 4.459125\n",
      "epoch: 4 step: 138, loss is 17.83843\n",
      "epoch: 4 step: 139, loss is 10.091002\n",
      "epoch: 4 step: 140, loss is 8.051492\n",
      "epoch: 4 step: 141, loss is 9.495379\n",
      "epoch: 4 step: 142, loss is 13.894305\n",
      "epoch: 4 step: 143, loss is 18.18354\n",
      "epoch: 4 step: 144, loss is 9.4925\n",
      "epoch: 4 step: 145, loss is 2.1044579\n",
      "epoch: 4 step: 146, loss is 9.420735\n",
      "epoch: 4 step: 147, loss is 10.54213\n",
      "epoch: 4 step: 148, loss is 14.165033\n",
      "epoch: 4 step: 149, loss is 5.624727\n",
      "epoch: 4 step: 150, loss is 5.493815\n",
      "epoch: 4 step: 151, loss is 10.743982\n",
      "epoch: 4 step: 152, loss is 3.0974233\n",
      "epoch: 4 step: 153, loss is 13.217432\n",
      "epoch: 4 step: 154, loss is 18.763859\n",
      "epoch: 4 step: 155, loss is 6.541345\n",
      "epoch: 4 step: 156, loss is 13.719568\n",
      "epoch: 4 step: 157, loss is 10.15655\n",
      "epoch: 4 step: 158, loss is 9.503666\n",
      "epoch: 4 step: 159, loss is 5.086662\n",
      "epoch: 4 step: 160, loss is 10.235117\n",
      "epoch: 4 step: 161, loss is 3.839955\n",
      "epoch: 4 step: 162, loss is 5.3130574\n",
      "epoch: 4 step: 163, loss is 6.0059114\n",
      "epoch: 4 step: 164, loss is 6.031484\n",
      "epoch: 4 step: 165, loss is 6.352182\n",
      "epoch: 4 step: 166, loss is 8.588338\n",
      "epoch: 4 step: 167, loss is 5.5310936\n",
      "epoch: 4 step: 168, loss is 10.252608\n",
      "epoch: 4 step: 169, loss is 2.4737244\n",
      "epoch: 4 step: 170, loss is 13.21802\n",
      "epoch: 4 step: 171, loss is 21.14692\n",
      "epoch: 4 step: 172, loss is 3.6985261\n",
      "epoch: 4 step: 173, loss is 6.6554766\n",
      "epoch: 4 step: 174, loss is 17.723349\n",
      "epoch: 4 step: 175, loss is 12.393163\n",
      "epoch: 4 step: 176, loss is 10.612553\n",
      "epoch: 4 step: 177, loss is 6.868173\n",
      "epoch: 4 step: 178, loss is 8.517087\n",
      "epoch: 4 step: 179, loss is 3.8414834\n",
      "epoch: 4 step: 180, loss is 11.700546\n",
      "epoch: 4 step: 181, loss is 3.4552376\n",
      "epoch: 4 step: 182, loss is 10.322907\n",
      "epoch: 4 step: 183, loss is 12.58256\n",
      "epoch: 4 step: 184, loss is 13.516565\n",
      "epoch: 4 step: 185, loss is 7.3142495\n",
      "epoch: 4 step: 186, loss is 8.524318\n",
      "epoch: 4 step: 187, loss is 15.444776\n",
      "epoch: 4 step: 188, loss is 10.324603\n",
      "epoch: 4 step: 189, loss is 2.3947856\n",
      "epoch: 4 step: 190, loss is 7.7508845\n",
      "epoch: 4 step: 191, loss is 6.8893623\n",
      "epoch: 4 step: 192, loss is 11.779426\n",
      "epoch: 4 step: 193, loss is 7.783684\n",
      "epoch: 4 step: 194, loss is 5.559186\n",
      "epoch: 4 step: 195, loss is 12.33841\n",
      "epoch: 4 step: 196, loss is 3.10277\n",
      "epoch: 4 step: 197, loss is 11.593186\n",
      "epoch: 4 step: 198, loss is 8.362334\n",
      "epoch: 4 step: 199, loss is 4.3570304\n",
      "epoch: 4 step: 200, loss is 9.075495\n",
      "epoch: 4 step: 201, loss is 3.0587902\n",
      "epoch: 4 step: 202, loss is 8.793173\n",
      "epoch: 4 step: 203, loss is 9.160072\n",
      "epoch: 4 step: 204, loss is 9.996168\n",
      "epoch: 4 step: 205, loss is 4.4661884\n",
      "epoch: 4 step: 206, loss is 12.07717\n",
      "epoch: 4 step: 207, loss is 9.499755\n",
      "epoch: 4 step: 208, loss is 7.9330635\n",
      "epoch: 4 step: 209, loss is 9.918828\n",
      "epoch: 4 step: 210, loss is 11.348759\n",
      "epoch: 4 step: 211, loss is 14.074396\n",
      "epoch: 4 step: 212, loss is 12.478229\n",
      "epoch: 4 step: 213, loss is 5.991877\n",
      "epoch: 4 step: 214, loss is 10.43513\n",
      "epoch: 4 step: 215, loss is 6.452308\n",
      "epoch: 4 step: 216, loss is 11.93827\n",
      "epoch: 4 step: 217, loss is 15.703278\n",
      "epoch: 4 step: 218, loss is 9.217426\n",
      "epoch: 4 step: 219, loss is 10.627667\n",
      "epoch: 4 step: 220, loss is 6.635383\n",
      "epoch: 4 step: 221, loss is 10.326945\n",
      "epoch: 4 step: 222, loss is 10.12241\n",
      "epoch: 4 step: 223, loss is 6.9434175\n",
      "epoch: 4 step: 224, loss is 17.091703\n",
      "epoch: 4 step: 225, loss is 11.446109\n",
      "epoch: 4 step: 226, loss is 9.434878\n",
      "epoch: 4 step: 227, loss is 10.74102\n",
      "epoch: 4 step: 228, loss is 8.835663\n",
      "epoch: 4 step: 229, loss is 15.326393\n",
      "epoch: 4 step: 230, loss is 10.077687\n",
      "epoch: 4 step: 231, loss is 11.318299\n",
      "epoch: 4 step: 232, loss is 5.291282\n",
      "epoch: 4 step: 233, loss is 10.002483\n",
      "epoch: 4 step: 234, loss is 2.5099685\n",
      "epoch: 4 step: 235, loss is 7.1666236\n",
      "epoch: 4 step: 236, loss is 13.010958\n",
      "epoch: 4 step: 237, loss is 8.899947\n",
      "epoch: 4 step: 238, loss is 8.618236\n",
      "epoch: 4 step: 239, loss is 8.771242\n",
      "epoch: 4 step: 240, loss is 14.431208\n",
      "epoch: 4 step: 241, loss is 10.483966\n",
      "epoch: 4 step: 242, loss is 5.6612062\n",
      "epoch: 4 step: 243, loss is 4.2863727\n",
      "epoch: 4 step: 244, loss is 3.0027046\n",
      "epoch: 4 step: 245, loss is 4.438354\n",
      "epoch: 4 step: 246, loss is 6.52958\n",
      "epoch: 4 step: 247, loss is 3.0307872\n",
      "epoch: 4 step: 248, loss is 9.385951\n",
      "epoch: 4 step: 249, loss is 8.068754\n",
      "epoch: 4 step: 250, loss is 11.730714\n",
      "epoch: 4 step: 251, loss is 2.195976\n",
      "epoch: 4 step: 252, loss is 9.411709\n",
      "epoch: 4 step: 253, loss is 19.269846\n",
      "epoch: 4 step: 254, loss is 8.46624\n",
      "epoch: 4 step: 255, loss is 11.38557\n",
      "epoch: 4 step: 256, loss is 11.96028\n",
      "epoch: 4 step: 257, loss is 4.257151\n",
      "epoch: 4 step: 258, loss is 7.614395\n",
      "epoch: 4 step: 259, loss is 3.947626\n",
      "epoch: 4 step: 260, loss is 17.896894\n",
      "epoch: 4 step: 261, loss is 7.5754213\n",
      "epoch: 4 step: 262, loss is 13.038469\n",
      "epoch: 4 step: 263, loss is 10.510594\n",
      "epoch: 4 step: 264, loss is 16.152983\n",
      "epoch: 4 step: 265, loss is 3.1057775\n",
      "epoch: 4 step: 266, loss is 11.86877\n",
      "epoch: 4 step: 267, loss is 14.262515\n",
      "epoch: 4 step: 268, loss is 18.942148\n",
      "epoch: 4 step: 269, loss is 13.272494\n",
      "epoch: 4 step: 270, loss is 2.750522\n",
      "epoch: 4 step: 271, loss is 9.770556\n",
      "epoch: 4 step: 272, loss is 14.897692\n",
      "epoch: 4 step: 273, loss is 5.36881\n",
      "epoch: 4 step: 274, loss is 5.537888\n",
      "epoch: 4 step: 275, loss is 3.613037\n",
      "epoch: 4 step: 276, loss is 4.3828106\n",
      "epoch: 4 step: 277, loss is 15.002818\n",
      "epoch: 4 step: 278, loss is 8.434581\n",
      "epoch: 4 step: 279, loss is 10.029888\n",
      "epoch: 4 step: 280, loss is 8.948175\n",
      "epoch: 4 step: 281, loss is 8.584951\n",
      "epoch: 4 step: 282, loss is 7.5333133\n",
      "epoch: 4 step: 283, loss is 6.416717\n",
      "epoch: 4 step: 284, loss is 8.40339\n",
      "epoch: 4 step: 285, loss is 9.977886\n",
      "epoch: 4 step: 286, loss is 7.452141\n",
      "epoch: 4 step: 287, loss is 15.941347\n",
      "epoch: 4 step: 288, loss is 17.368036\n",
      "epoch: 4 step: 289, loss is 5.150826\n",
      "epoch: 4 step: 290, loss is 9.903787\n",
      "epoch: 4 step: 291, loss is 11.5694475\n",
      "epoch: 4 step: 292, loss is 8.215062\n",
      "epoch: 4 step: 293, loss is 16.685926\n",
      "epoch: 4 step: 294, loss is 8.113766\n",
      "epoch: 4 step: 295, loss is 1.0069968\n",
      "epoch: 4 step: 296, loss is 5.023268\n",
      "epoch: 4 step: 297, loss is 6.1058106\n",
      "epoch: 4 step: 298, loss is 7.959131\n",
      "epoch: 4 step: 299, loss is 9.037157\n",
      "epoch: 4 step: 300, loss is 1.342965\n",
      "epoch: 4 step: 301, loss is 9.047324\n",
      "epoch: 4 step: 302, loss is 7.529364\n",
      "epoch: 4 step: 303, loss is 5.397156\n",
      "epoch: 4 step: 304, loss is 10.451912\n",
      "epoch: 4 step: 305, loss is 12.45346\n",
      "epoch: 4 step: 306, loss is 6.912183\n",
      "epoch: 4 step: 307, loss is 5.581401\n",
      "epoch: 4 step: 308, loss is 10.474632\n",
      "epoch: 4 step: 309, loss is 8.47137\n",
      "epoch: 4 step: 310, loss is 11.21259\n",
      "epoch: 4 step: 311, loss is 8.1547\n",
      "epoch: 4 step: 312, loss is 5.7790904\n",
      "epoch: 4 step: 313, loss is 9.919932\n",
      "epoch: 4 step: 314, loss is 5.7779565\n",
      "epoch: 4 step: 315, loss is 10.513469\n",
      "epoch: 4 step: 316, loss is 5.898944\n",
      "epoch: 4 step: 317, loss is 2.5560396\n",
      "epoch: 4 step: 318, loss is 2.6284294\n",
      "epoch: 4 step: 319, loss is 7.526073\n",
      "epoch: 4 step: 320, loss is 6.662506\n",
      "epoch: 4 step: 321, loss is 18.26149\n",
      "epoch: 4 step: 322, loss is 14.512451\n",
      "epoch: 4 step: 323, loss is 9.068983\n",
      "epoch: 4 step: 324, loss is 8.694118\n",
      "epoch: 4 step: 325, loss is 13.520667\n",
      "epoch: 4 step: 326, loss is 8.416137\n",
      "epoch: 4 step: 327, loss is 11.744475\n",
      "epoch: 4 step: 328, loss is 5.1127934\n",
      "epoch: 4 step: 329, loss is 8.381087\n",
      "epoch: 4 step: 330, loss is 19.403856\n",
      "epoch: 4 step: 331, loss is 8.697036\n",
      "epoch: 4 step: 332, loss is 5.1610827\n",
      "epoch: 4 step: 333, loss is 14.558612\n",
      "epoch: 4 step: 334, loss is 7.422728\n",
      "epoch: 4 step: 335, loss is 6.563929\n",
      "epoch: 4 step: 336, loss is 10.003052\n",
      "epoch: 4 step: 337, loss is 7.613647\n",
      "epoch: 4 step: 338, loss is 5.840883\n",
      "epoch: 4 step: 339, loss is 4.81624\n",
      "epoch: 4 step: 340, loss is 11.951698\n",
      "epoch: 4 step: 341, loss is 14.603927\n",
      "epoch: 4 step: 342, loss is 8.533343\n",
      "epoch: 4 step: 343, loss is 9.096772\n",
      "epoch: 4 step: 344, loss is 10.441264\n",
      "epoch: 4 step: 345, loss is 11.458043\n",
      "epoch: 4 step: 346, loss is 16.871424\n",
      "epoch: 4 step: 347, loss is 10.138394\n",
      "epoch: 4 step: 348, loss is 5.1306887\n",
      "epoch: 4 step: 349, loss is 5.430984\n",
      "epoch: 4 step: 350, loss is 7.727433\n",
      "epoch: 4 step: 351, loss is 10.3026495\n",
      "epoch: 4 step: 352, loss is 4.307813\n",
      "epoch: 4 step: 353, loss is 7.772714\n",
      "epoch: 4 step: 354, loss is 13.533885\n",
      "epoch: 4 step: 355, loss is 8.837291\n",
      "epoch: 4 step: 356, loss is 3.503616\n",
      "epoch: 4 step: 357, loss is 7.3944473\n",
      "epoch: 4 step: 358, loss is 5.5632763\n",
      "epoch: 4 step: 359, loss is 19.481575\n",
      "epoch: 4 step: 360, loss is 8.963536\n",
      "epoch: 4 step: 361, loss is 4.429003\n",
      "epoch: 4 step: 362, loss is 6.3598213\n",
      "epoch: 4 step: 363, loss is 3.8078454\n",
      "epoch: 4 step: 364, loss is 25.479204\n",
      "epoch: 4 step: 365, loss is 5.1794596\n",
      "epoch: 4 step: 366, loss is 2.2838864\n",
      "epoch: 4 step: 367, loss is 7.332088\n",
      "epoch: 4 step: 368, loss is 8.311957\n",
      "epoch: 4 step: 369, loss is 1.9376576\n",
      "epoch: 4 step: 370, loss is 14.94079\n",
      "epoch: 4 step: 371, loss is 9.807289\n",
      "epoch: 4 step: 372, loss is 8.627849\n",
      "epoch: 4 step: 373, loss is 12.0908575\n",
      "epoch: 4 step: 374, loss is 11.856814\n",
      "epoch: 4 step: 375, loss is 10.413968\n",
      "epoch: 4 step: 376, loss is 8.947225\n",
      "epoch: 4 step: 377, loss is 16.10538\n",
      "epoch: 4 step: 378, loss is 7.4808197\n",
      "epoch: 4 step: 379, loss is 14.064771\n",
      "epoch: 4 step: 380, loss is 2.9715505\n",
      "epoch: 4 step: 381, loss is 5.700367\n",
      "epoch: 4 step: 382, loss is 11.354943\n",
      "epoch: 4 step: 383, loss is 12.209341\n",
      "epoch: 4 step: 384, loss is 8.629803\n",
      "epoch: 4 step: 385, loss is 7.464757\n",
      "epoch: 4 step: 386, loss is 4.3745494\n",
      "epoch: 4 step: 387, loss is 7.487274\n",
      "epoch: 4 step: 388, loss is 7.3928223\n",
      "epoch: 4 step: 389, loss is 4.392405\n",
      "epoch: 4 step: 390, loss is 10.340281\n",
      "epoch: 4 step: 391, loss is 15.338669\n",
      "epoch: 4 step: 392, loss is 6.4617286\n",
      "epoch: 4 step: 393, loss is 4.133138\n",
      "epoch: 4 step: 394, loss is 6.8880706\n",
      "epoch: 4 step: 395, loss is 13.530011\n",
      "epoch: 4 step: 396, loss is 11.236566\n",
      "epoch: 4 step: 397, loss is 6.316319\n",
      "epoch: 4 step: 398, loss is 7.879731\n",
      "epoch: 4 step: 399, loss is 9.270348\n",
      "epoch: 4 step: 400, loss is 10.59611\n",
      "Train epoch time: 1687615.214 ms, per step time: 4219.038 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:56:38,214 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 10:56:38,216 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:56:41,586 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.4119070738020246 T+60 min: 0.16328413060990918 T+120 min: 0.10628156308461514\n",
      "2024-01-31 10:56:41,656 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1, loss is 10.631495\n",
      "epoch: 5 step: 2, loss is 8.387822\n",
      "epoch: 5 step: 3, loss is 13.710869\n",
      "epoch: 5 step: 4, loss is 5.4953156\n",
      "epoch: 5 step: 5, loss is 9.979673\n",
      "epoch: 5 step: 6, loss is 6.714036\n",
      "epoch: 5 step: 7, loss is 6.685842\n",
      "epoch: 5 step: 8, loss is 4.2601423\n",
      "epoch: 5 step: 9, loss is 2.9999993\n",
      "epoch: 5 step: 10, loss is 2.5337834\n",
      "epoch: 5 step: 11, loss is 8.508463\n",
      "epoch: 5 step: 12, loss is 8.42295\n",
      "epoch: 5 step: 13, loss is 8.569485\n",
      "epoch: 5 step: 14, loss is 5.3934393\n",
      "epoch: 5 step: 15, loss is 7.9034486\n",
      "epoch: 5 step: 16, loss is 12.259567\n",
      "epoch: 5 step: 17, loss is 8.008107\n",
      "epoch: 5 step: 18, loss is 7.291337\n",
      "epoch: 5 step: 19, loss is 4.7586455\n",
      "epoch: 5 step: 20, loss is 14.302854\n",
      "epoch: 5 step: 21, loss is 3.7846584\n",
      "epoch: 5 step: 22, loss is 12.408534\n",
      "epoch: 5 step: 23, loss is 14.33615\n",
      "epoch: 5 step: 24, loss is 5.025287\n",
      "epoch: 5 step: 25, loss is 8.458199\n",
      "epoch: 5 step: 26, loss is 15.693871\n",
      "epoch: 5 step: 27, loss is 22.327187\n",
      "epoch: 5 step: 28, loss is 17.936943\n",
      "epoch: 5 step: 29, loss is 7.3304977\n",
      "epoch: 5 step: 30, loss is 13.158412\n",
      "epoch: 5 step: 31, loss is 11.710132\n",
      "epoch: 5 step: 32, loss is 11.138893\n",
      "epoch: 5 step: 33, loss is 4.9665747\n",
      "epoch: 5 step: 34, loss is 12.0865965\n",
      "epoch: 5 step: 35, loss is 9.506385\n",
      "epoch: 5 step: 36, loss is 8.220237\n",
      "epoch: 5 step: 37, loss is 5.487331\n",
      "epoch: 5 step: 38, loss is 7.659286\n",
      "epoch: 5 step: 39, loss is 9.066897\n",
      "epoch: 5 step: 40, loss is 9.229425\n",
      "epoch: 5 step: 41, loss is 11.532029\n",
      "epoch: 5 step: 42, loss is 11.420379\n",
      "epoch: 5 step: 43, loss is 14.307367\n",
      "epoch: 5 step: 44, loss is 9.982462\n",
      "epoch: 5 step: 45, loss is 15.219409\n",
      "epoch: 5 step: 46, loss is 7.312978\n",
      "epoch: 5 step: 47, loss is 3.001394\n",
      "epoch: 5 step: 48, loss is 9.987114\n",
      "epoch: 5 step: 49, loss is 13.986376\n",
      "epoch: 5 step: 50, loss is 6.7663727\n",
      "epoch: 5 step: 51, loss is 7.3535867\n",
      "epoch: 5 step: 52, loss is 10.835659\n",
      "epoch: 5 step: 53, loss is 4.03575\n",
      "epoch: 5 step: 54, loss is 17.235962\n",
      "epoch: 5 step: 55, loss is 4.8890815\n",
      "epoch: 5 step: 56, loss is 6.193456\n",
      "epoch: 5 step: 57, loss is 12.351563\n",
      "epoch: 5 step: 58, loss is 12.991935\n",
      "epoch: 5 step: 59, loss is 11.512714\n",
      "epoch: 5 step: 60, loss is 3.1844296\n",
      "epoch: 5 step: 61, loss is 12.697228\n",
      "epoch: 5 step: 62, loss is 11.229603\n",
      "epoch: 5 step: 63, loss is 13.884003\n",
      "epoch: 5 step: 64, loss is 9.7715225\n",
      "epoch: 5 step: 65, loss is 3.5666463\n",
      "epoch: 5 step: 66, loss is 15.524452\n",
      "epoch: 5 step: 67, loss is 6.4682574\n",
      "epoch: 5 step: 68, loss is 10.731905\n",
      "epoch: 5 step: 69, loss is 11.709724\n",
      "epoch: 5 step: 70, loss is 11.286643\n",
      "epoch: 5 step: 71, loss is 3.969979\n",
      "epoch: 5 step: 72, loss is 13.019687\n",
      "epoch: 5 step: 73, loss is 13.722501\n",
      "epoch: 5 step: 74, loss is 16.456974\n",
      "epoch: 5 step: 75, loss is 10.625042\n",
      "epoch: 5 step: 76, loss is 7.1048675\n",
      "epoch: 5 step: 77, loss is 11.497929\n",
      "epoch: 5 step: 78, loss is 13.572883\n",
      "epoch: 5 step: 79, loss is 9.635073\n",
      "epoch: 5 step: 80, loss is 7.234012\n",
      "epoch: 5 step: 81, loss is 7.0485215\n",
      "epoch: 5 step: 82, loss is 11.622435\n",
      "epoch: 5 step: 83, loss is 12.5248995\n",
      "epoch: 5 step: 84, loss is 11.543509\n",
      "epoch: 5 step: 85, loss is 6.9962783\n",
      "epoch: 5 step: 86, loss is 13.758985\n",
      "epoch: 5 step: 87, loss is 7.901777\n",
      "epoch: 5 step: 88, loss is 5.801796\n",
      "epoch: 5 step: 89, loss is 12.534296\n",
      "epoch: 5 step: 90, loss is 5.2921734\n",
      "epoch: 5 step: 91, loss is 5.905163\n",
      "epoch: 5 step: 92, loss is 6.497083\n",
      "epoch: 5 step: 93, loss is 11.769897\n",
      "epoch: 5 step: 94, loss is 13.156825\n",
      "epoch: 5 step: 95, loss is 14.175391\n",
      "epoch: 5 step: 96, loss is 20.794384\n",
      "epoch: 5 step: 97, loss is 6.0201335\n",
      "epoch: 5 step: 98, loss is 9.175666\n",
      "epoch: 5 step: 99, loss is 7.9389544\n",
      "epoch: 5 step: 100, loss is 6.3970675\n",
      "epoch: 5 step: 101, loss is 5.013559\n",
      "epoch: 5 step: 102, loss is 6.2980266\n",
      "epoch: 5 step: 103, loss is 5.525966\n",
      "epoch: 5 step: 104, loss is 8.414882\n",
      "epoch: 5 step: 105, loss is 14.657737\n",
      "epoch: 5 step: 106, loss is 8.811191\n",
      "epoch: 5 step: 107, loss is 3.8203213\n",
      "epoch: 5 step: 108, loss is 8.20427\n",
      "epoch: 5 step: 109, loss is 6.8678017\n",
      "epoch: 5 step: 110, loss is 7.650745\n",
      "epoch: 5 step: 111, loss is 7.6307144\n",
      "epoch: 5 step: 112, loss is 7.781446\n",
      "epoch: 5 step: 113, loss is 8.235534\n",
      "epoch: 5 step: 114, loss is 5.4686313\n",
      "epoch: 5 step: 115, loss is 10.608706\n",
      "epoch: 5 step: 116, loss is 10.145556\n",
      "epoch: 5 step: 117, loss is 9.863107\n",
      "epoch: 5 step: 118, loss is 9.765075\n",
      "epoch: 5 step: 119, loss is 10.292937\n",
      "epoch: 5 step: 120, loss is 7.5957537\n",
      "epoch: 5 step: 121, loss is 8.942965\n",
      "epoch: 5 step: 122, loss is 4.448814\n",
      "epoch: 5 step: 123, loss is 12.249301\n",
      "epoch: 5 step: 124, loss is 6.5036263\n",
      "epoch: 5 step: 125, loss is 5.7959614\n",
      "epoch: 5 step: 126, loss is 5.2631245\n",
      "epoch: 5 step: 127, loss is 5.7066426\n",
      "epoch: 5 step: 128, loss is 9.65103\n",
      "epoch: 5 step: 129, loss is 8.33817\n",
      "epoch: 5 step: 130, loss is 4.682997\n",
      "epoch: 5 step: 131, loss is 12.688251\n",
      "epoch: 5 step: 132, loss is 8.972763\n",
      "epoch: 5 step: 133, loss is 5.926785\n",
      "epoch: 5 step: 134, loss is 14.200495\n",
      "epoch: 5 step: 135, loss is 7.9501543\n",
      "epoch: 5 step: 136, loss is 4.117658\n",
      "epoch: 5 step: 137, loss is 10.878026\n",
      "epoch: 5 step: 138, loss is 9.260337\n",
      "epoch: 5 step: 139, loss is 5.1848884\n",
      "epoch: 5 step: 140, loss is 8.278662\n",
      "epoch: 5 step: 141, loss is 6.7406807\n",
      "epoch: 5 step: 142, loss is 11.55156\n",
      "epoch: 5 step: 143, loss is 6.268988\n",
      "epoch: 5 step: 144, loss is 8.5409775\n",
      "epoch: 5 step: 145, loss is 9.443991\n",
      "epoch: 5 step: 146, loss is 5.869701\n",
      "epoch: 5 step: 147, loss is 6.10673\n",
      "epoch: 5 step: 148, loss is 10.007139\n",
      "epoch: 5 step: 149, loss is 20.440926\n",
      "epoch: 5 step: 150, loss is 11.340872\n",
      "epoch: 5 step: 151, loss is 7.81508\n",
      "epoch: 5 step: 152, loss is 21.721022\n",
      "epoch: 5 step: 153, loss is 5.7613144\n",
      "epoch: 5 step: 154, loss is 7.1448092\n",
      "epoch: 5 step: 155, loss is 10.04864\n",
      "epoch: 5 step: 156, loss is 12.34471\n",
      "epoch: 5 step: 157, loss is 11.677033\n",
      "epoch: 5 step: 158, loss is 7.871145\n",
      "epoch: 5 step: 159, loss is 6.426829\n",
      "epoch: 5 step: 160, loss is 23.551405\n",
      "epoch: 5 step: 161, loss is 9.514769\n",
      "epoch: 5 step: 162, loss is 9.29256\n",
      "epoch: 5 step: 163, loss is 8.428229\n",
      "epoch: 5 step: 164, loss is 12.387996\n",
      "epoch: 5 step: 165, loss is 19.549873\n",
      "epoch: 5 step: 166, loss is 3.0377066\n",
      "epoch: 5 step: 167, loss is 7.989761\n",
      "epoch: 5 step: 168, loss is 8.3322\n",
      "epoch: 5 step: 169, loss is 10.079988\n",
      "epoch: 5 step: 170, loss is 4.6191297\n",
      "epoch: 5 step: 171, loss is 3.8486416\n",
      "epoch: 5 step: 172, loss is 8.640483\n",
      "epoch: 5 step: 173, loss is 5.1511884\n",
      "epoch: 5 step: 174, loss is 4.039965\n",
      "epoch: 5 step: 175, loss is 2.8865755\n",
      "epoch: 5 step: 176, loss is 5.206315\n",
      "epoch: 5 step: 177, loss is 11.176275\n",
      "epoch: 5 step: 178, loss is 8.387357\n",
      "epoch: 5 step: 179, loss is 7.976318\n",
      "epoch: 5 step: 180, loss is 1.8052963\n",
      "epoch: 5 step: 181, loss is 5.5723796\n",
      "epoch: 5 step: 182, loss is 6.2282424\n",
      "epoch: 5 step: 183, loss is 6.1277995\n",
      "epoch: 5 step: 184, loss is 12.066929\n",
      "epoch: 5 step: 185, loss is 2.7362423\n",
      "epoch: 5 step: 186, loss is 5.7135406\n",
      "epoch: 5 step: 187, loss is 10.313344\n",
      "epoch: 5 step: 188, loss is 7.4719386\n",
      "epoch: 5 step: 189, loss is 13.5311985\n",
      "epoch: 5 step: 190, loss is 21.601717\n",
      "epoch: 5 step: 191, loss is 7.2960863\n",
      "epoch: 5 step: 192, loss is 12.421396\n",
      "epoch: 5 step: 193, loss is 8.647869\n",
      "epoch: 5 step: 194, loss is 10.662854\n",
      "epoch: 5 step: 195, loss is 11.814657\n",
      "epoch: 5 step: 196, loss is 16.368193\n",
      "epoch: 5 step: 197, loss is 12.368675\n",
      "epoch: 5 step: 198, loss is 3.7948174\n",
      "epoch: 5 step: 199, loss is 8.508166\n",
      "epoch: 5 step: 200, loss is 15.087338\n",
      "epoch: 5 step: 201, loss is 4.3888545\n",
      "epoch: 5 step: 202, loss is 7.3951087\n",
      "epoch: 5 step: 203, loss is 1.6048508\n",
      "epoch: 5 step: 204, loss is 10.2099\n",
      "epoch: 5 step: 205, loss is 9.446616\n",
      "epoch: 5 step: 206, loss is 9.398039\n",
      "epoch: 5 step: 207, loss is 14.820376\n",
      "epoch: 5 step: 208, loss is 10.117989\n",
      "epoch: 5 step: 209, loss is 18.408413\n",
      "epoch: 5 step: 210, loss is 11.205449\n",
      "epoch: 5 step: 211, loss is 7.9792185\n",
      "epoch: 5 step: 212, loss is 15.146637\n",
      "epoch: 5 step: 213, loss is 17.380625\n",
      "epoch: 5 step: 214, loss is 10.440936\n",
      "epoch: 5 step: 215, loss is 8.430682\n",
      "epoch: 5 step: 216, loss is 7.0475345\n",
      "epoch: 5 step: 217, loss is 8.43027\n",
      "epoch: 5 step: 218, loss is 8.34959\n",
      "epoch: 5 step: 219, loss is 3.492035\n",
      "epoch: 5 step: 220, loss is 7.284372\n",
      "epoch: 5 step: 221, loss is 11.793396\n",
      "epoch: 5 step: 222, loss is 12.567748\n",
      "epoch: 5 step: 223, loss is 7.5711007\n",
      "epoch: 5 step: 224, loss is 9.16282\n",
      "epoch: 5 step: 225, loss is 11.162758\n",
      "epoch: 5 step: 226, loss is 12.743927\n",
      "epoch: 5 step: 227, loss is 5.62576\n",
      "epoch: 5 step: 228, loss is 9.719904\n",
      "epoch: 5 step: 229, loss is 10.256751\n",
      "epoch: 5 step: 230, loss is 3.016227\n",
      "epoch: 5 step: 231, loss is 14.895472\n",
      "epoch: 5 step: 232, loss is 13.203323\n",
      "epoch: 5 step: 233, loss is 17.456888\n",
      "epoch: 5 step: 234, loss is 6.3501587\n",
      "epoch: 5 step: 235, loss is 5.698399\n",
      "epoch: 5 step: 236, loss is 7.669922\n",
      "epoch: 5 step: 237, loss is 15.038241\n",
      "epoch: 5 step: 238, loss is 1.2542189\n",
      "epoch: 5 step: 239, loss is 13.250785\n",
      "epoch: 5 step: 240, loss is 7.499948\n",
      "epoch: 5 step: 241, loss is 12.799797\n",
      "epoch: 5 step: 242, loss is 13.96305\n",
      "epoch: 5 step: 243, loss is 6.2045703\n",
      "epoch: 5 step: 244, loss is 9.261703\n",
      "epoch: 5 step: 245, loss is 13.137906\n",
      "epoch: 5 step: 246, loss is 5.6268735\n",
      "epoch: 5 step: 247, loss is 1.7798923\n",
      "epoch: 5 step: 248, loss is 4.302215\n",
      "epoch: 5 step: 249, loss is 17.192045\n",
      "epoch: 5 step: 250, loss is 5.874618\n",
      "epoch: 5 step: 251, loss is 14.248351\n",
      "epoch: 5 step: 252, loss is 8.042169\n",
      "epoch: 5 step: 253, loss is 2.707917\n",
      "epoch: 5 step: 254, loss is 8.272249\n",
      "epoch: 5 step: 255, loss is 6.518483\n",
      "epoch: 5 step: 256, loss is 3.7200456\n",
      "epoch: 5 step: 257, loss is 4.8931518\n",
      "epoch: 5 step: 258, loss is 9.775307\n",
      "epoch: 5 step: 259, loss is 5.4442167\n",
      "epoch: 5 step: 260, loss is 3.6159\n",
      "epoch: 5 step: 261, loss is 7.79292\n",
      "epoch: 5 step: 262, loss is 5.1962895\n",
      "epoch: 5 step: 263, loss is 10.529631\n",
      "epoch: 5 step: 264, loss is 2.2757719\n",
      "epoch: 5 step: 265, loss is 3.3210568\n",
      "epoch: 5 step: 266, loss is 7.5334296\n",
      "epoch: 5 step: 267, loss is 12.313452\n",
      "epoch: 5 step: 268, loss is 3.119498\n",
      "epoch: 5 step: 269, loss is 12.617778\n",
      "epoch: 5 step: 270, loss is 3.5836098\n",
      "epoch: 5 step: 271, loss is 10.1419935\n",
      "epoch: 5 step: 272, loss is 5.3244247\n",
      "epoch: 5 step: 273, loss is 14.506012\n",
      "epoch: 5 step: 274, loss is 9.065284\n",
      "epoch: 5 step: 275, loss is 7.1014833\n",
      "epoch: 5 step: 276, loss is 4.549492\n",
      "epoch: 5 step: 277, loss is 8.913678\n",
      "epoch: 5 step: 278, loss is 9.7163\n",
      "epoch: 5 step: 279, loss is 13.618973\n",
      "epoch: 5 step: 280, loss is 11.507527\n",
      "epoch: 5 step: 281, loss is 9.818935\n",
      "epoch: 5 step: 282, loss is 12.376059\n",
      "epoch: 5 step: 283, loss is 10.621506\n",
      "epoch: 5 step: 284, loss is 8.115376\n",
      "epoch: 5 step: 285, loss is 12.524125\n",
      "epoch: 5 step: 286, loss is 11.934016\n",
      "epoch: 5 step: 287, loss is 18.978323\n",
      "epoch: 5 step: 288, loss is 5.2660456\n",
      "epoch: 5 step: 289, loss is 5.11286\n",
      "epoch: 5 step: 290, loss is 6.446734\n",
      "epoch: 5 step: 291, loss is 4.856027\n",
      "epoch: 5 step: 292, loss is 9.004395\n",
      "epoch: 5 step: 293, loss is 9.165318\n",
      "epoch: 5 step: 294, loss is 8.424228\n",
      "epoch: 5 step: 295, loss is 6.32342\n",
      "epoch: 5 step: 296, loss is 5.8498797\n",
      "epoch: 5 step: 297, loss is 9.703807\n",
      "epoch: 5 step: 298, loss is 8.799947\n",
      "epoch: 5 step: 299, loss is 13.354802\n",
      "epoch: 5 step: 300, loss is 3.7787483\n",
      "epoch: 5 step: 301, loss is 8.219623\n",
      "epoch: 5 step: 302, loss is 8.6753435\n",
      "epoch: 5 step: 303, loss is 4.068034\n",
      "epoch: 5 step: 304, loss is 9.44405\n",
      "epoch: 5 step: 305, loss is 7.0157714\n",
      "epoch: 5 step: 306, loss is 9.052187\n",
      "epoch: 5 step: 307, loss is 7.4884334\n",
      "epoch: 5 step: 308, loss is 4.1641817\n",
      "epoch: 5 step: 309, loss is 5.55895\n",
      "epoch: 5 step: 310, loss is 5.693998\n",
      "epoch: 5 step: 311, loss is 6.2011943\n",
      "epoch: 5 step: 312, loss is 15.261699\n",
      "epoch: 5 step: 313, loss is 7.934396\n",
      "epoch: 5 step: 314, loss is 7.193046\n",
      "epoch: 5 step: 315, loss is 8.417132\n",
      "epoch: 5 step: 316, loss is 10.485958\n",
      "epoch: 5 step: 317, loss is 10.631312\n",
      "epoch: 5 step: 318, loss is 5.3854804\n",
      "epoch: 5 step: 319, loss is 4.3416204\n",
      "epoch: 5 step: 320, loss is 6.133428\n",
      "epoch: 5 step: 321, loss is 11.038399\n",
      "epoch: 5 step: 322, loss is 10.795598\n",
      "epoch: 5 step: 323, loss is 7.526134\n",
      "epoch: 5 step: 324, loss is 11.69377\n",
      "epoch: 5 step: 325, loss is 15.343103\n",
      "epoch: 5 step: 326, loss is 4.180414\n",
      "epoch: 5 step: 327, loss is 1.9247597\n",
      "epoch: 5 step: 328, loss is 2.562195\n",
      "epoch: 5 step: 329, loss is 9.181924\n",
      "epoch: 5 step: 330, loss is 3.468705\n",
      "epoch: 5 step: 331, loss is 7.6786075\n",
      "epoch: 5 step: 332, loss is 5.6610374\n",
      "epoch: 5 step: 333, loss is 1.8532251\n",
      "epoch: 5 step: 334, loss is 8.089282\n",
      "epoch: 5 step: 335, loss is 6.310372\n",
      "epoch: 5 step: 336, loss is 18.303768\n",
      "epoch: 5 step: 337, loss is 9.46337\n",
      "epoch: 5 step: 338, loss is 7.6183686\n",
      "epoch: 5 step: 339, loss is 6.296453\n",
      "epoch: 5 step: 340, loss is 12.350784\n",
      "epoch: 5 step: 341, loss is 11.734832\n",
      "epoch: 5 step: 342, loss is 7.058208\n",
      "epoch: 5 step: 343, loss is 14.124316\n",
      "epoch: 5 step: 344, loss is 14.062975\n",
      "epoch: 5 step: 345, loss is 11.118648\n",
      "epoch: 5 step: 346, loss is 14.661054\n",
      "epoch: 5 step: 347, loss is 18.050169\n",
      "epoch: 5 step: 348, loss is 10.386849\n",
      "epoch: 5 step: 349, loss is 17.819105\n",
      "epoch: 5 step: 350, loss is 9.1744585\n",
      "epoch: 5 step: 351, loss is 5.092346\n",
      "epoch: 5 step: 352, loss is 7.669666\n",
      "epoch: 5 step: 353, loss is 5.966626\n",
      "epoch: 5 step: 354, loss is 4.989822\n",
      "epoch: 5 step: 355, loss is 19.305593\n",
      "epoch: 5 step: 356, loss is 6.2722297\n",
      "epoch: 5 step: 357, loss is 17.060827\n",
      "epoch: 5 step: 358, loss is 12.174474\n",
      "epoch: 5 step: 359, loss is 15.584104\n",
      "epoch: 5 step: 360, loss is 2.7462678\n",
      "epoch: 5 step: 361, loss is 12.883452\n",
      "epoch: 5 step: 362, loss is 7.7744904\n",
      "epoch: 5 step: 363, loss is 4.8834033\n",
      "epoch: 5 step: 364, loss is 7.3042274\n",
      "epoch: 5 step: 365, loss is 8.934322\n",
      "epoch: 5 step: 366, loss is 1.8163586\n",
      "epoch: 5 step: 367, loss is 14.792688\n",
      "epoch: 5 step: 368, loss is 6.5286202\n",
      "epoch: 5 step: 369, loss is 10.896334\n",
      "epoch: 5 step: 370, loss is 5.369243\n",
      "epoch: 5 step: 371, loss is 6.807532\n",
      "epoch: 5 step: 372, loss is 13.986018\n",
      "epoch: 5 step: 373, loss is 6.5641456\n",
      "epoch: 5 step: 374, loss is 3.7626512\n",
      "epoch: 5 step: 375, loss is 5.4657474\n",
      "epoch: 5 step: 376, loss is 10.283322\n",
      "epoch: 5 step: 377, loss is 7.860248\n",
      "epoch: 5 step: 378, loss is 4.517271\n",
      "epoch: 5 step: 379, loss is 6.7254114\n",
      "epoch: 5 step: 380, loss is 12.755939\n",
      "epoch: 5 step: 381, loss is 9.718998\n",
      "epoch: 5 step: 382, loss is 6.1242285\n",
      "epoch: 5 step: 383, loss is 13.625025\n",
      "epoch: 5 step: 384, loss is 7.9344134\n",
      "epoch: 5 step: 385, loss is 8.680602\n",
      "epoch: 5 step: 386, loss is 7.1456604\n",
      "epoch: 5 step: 387, loss is 11.936925\n",
      "epoch: 5 step: 388, loss is 9.427384\n",
      "epoch: 5 step: 389, loss is 5.386045\n",
      "epoch: 5 step: 390, loss is 7.9937325\n",
      "epoch: 5 step: 391, loss is 4.4265428\n",
      "epoch: 5 step: 392, loss is 18.11367\n",
      "epoch: 5 step: 393, loss is 11.8551655\n",
      "epoch: 5 step: 394, loss is 3.7888184\n",
      "epoch: 5 step: 395, loss is 9.754228\n",
      "epoch: 5 step: 396, loss is 7.669852\n",
      "epoch: 5 step: 397, loss is 0.9869246\n",
      "epoch: 5 step: 398, loss is 14.705731\n",
      "epoch: 5 step: 399, loss is 10.468576\n",
      "epoch: 5 step: 400, loss is 6.882686\n",
      "Train epoch time: 1691109.624 ms, per step time: 4227.774 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 11:24:52,789 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 11:24:52,790 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 11:24:56,256 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.4118216017414204 T+60 min: 0.15679251293172677 T+120 min: 0.10144497020636714\n",
      "2024-01-31 11:24:56,322 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    }
   ],
   "source": [
    "# loss_scale = ms.amp.DynamicLossScaleManager(init_loss_scale=2 ** 18, scale_factor=2, scale_window=1000)\n",
    "loss_scale = ms.train.loss_scale_manager.FixedLossScaleManager(loss_scale=2048)\n",
    "evo_loss_fn = EvolutionLoss(evo_model, config)\n",
    "trainer = EvolutionTrainer(config, evo_model, evo_loss_fn, logger, loss_scale)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### evolution评估和可视化\n",
    "\n",
    "完成训练后，我们使用ckpt进行推理，下述展示了推理的可视化图片\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T03:27:47.291549200Z",
     "start_time": "2024-01-31T03:27:46.401222Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config[\"data\"][\"batch_size\"] = 1\n",
    "config[\"summary\"][\"visual\"] = True\n",
    "params = load_checkpoint('./summary/ckpt/evolution-3_200.ckpt')\n",
    "evo_model.set_train(False)\n",
    "load_param_into_net(evo_model, params)\n",
    "evo_inference = EvolutionPredictor(config, evo_model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T06:11:02.019387Z",
     "start_time": "2024-01-31T06:11:00.391020800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_params = config.get(\"data\")\n",
    "test_dataset_generator = RadarData(data_params, run_mode='test', module_name=\"evolution\")\n",
    "test_dataset = NowcastDataset(test_dataset_generator,\n",
    "                              module_name=\"evolution\",\n",
    "                              distribute=train_params.get('distribute', False),\n",
    "                              num_workers=data_params.get('num_workers', 1),\n",
    "                              shuffle=False)\n",
    "test_dataset = test_dataset.create_dataset(data_params.get('batch_size', 1))\n",
    "# data = next(test_dataset.create_dict_iterator())\n",
    "steps = 1\n",
    "for d in test_dataset.create_dict_iterator():\n",
    "    if steps == 6:\n",
    "        data = d\n",
    "        break\n",
    "    steps += 1\n",
    "inputs = data['inputs']\n",
    "pred = evo_inference.forecast(inputs)\n",
    "labels = inputs[:, data_params.get(\"t_in\"):]\n",
    "plt_idx = [x // data_params.get(\"time_interval\") - 1 for x in data_params.get(\"key_info_timestep\", [10, 60, 120])]\n",
    "plt_img(field=pred[0].asnumpy(), label=labels[0].asnumpy(), idx=plt_idx, fig_name=\"./evolution_example.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config[\"model\"][\"module_name\"] = 'generation'\n",
    "config[\"data\"][\"batch_size\"] = 1\n",
    "config[\"summary\"][\"visual\"] = False\n",
    "config[\"summary\"][\"save_checkpoint_epochs\"] = 1\n",
    "train_params = config.get(\"train\")\n",
    "summary_params = config.get(\"summary\")\n",
    "g_model = GenerationNet(config)\n",
    "d_model = TemporalDiscriminator(data_params.get(\"t_in\", 9) + data_params.get(\"t_out\", 20))\n",
    "g_model.set_train()\n",
    "d_model.set_train()\n",
    "g_model = amp.auto_mixed_precision(g_model, amp_level=train_params.get(\"amp_level\", 'O2'))\n",
    "d_model = amp.auto_mixed_precision(d_model, amp_level=train_params.get(\"amp_level\", 'O2'))\n",
    "loss_scale = nn.DynamicLossScaleUpdateCell(loss_scale_value=2 ** 12, scale_factor=2, scale_window=1000)\n",
    "g_loss_fn = GenerateLoss(g_model, d_model)\n",
    "d_loss_fn = DiscriminatorLoss(g_model, d_model)\n",
    "trainer = GenerationTrainer(config, g_model, d_model, g_loss_fn, d_loss_fn, logger, loss_scale)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### generation评估和可视化\n",
    "\n",
    "完成训练后，我们使用ckpt进行推理，下述展示了推理的可视化图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config[\"summary\"][\"visual\"] = True\n",
    "config[\"train\"][\"load_ckpt\"] = True\n",
    "gen_inference = GenerationPredictor(config, g_model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_params = config.get(\"data\")\n",
    "model_params = config.get(\"model\")\n",
    "test_dataset_generator = RadarData(data_params, run_mode='test', module_name=\"generation\")\n",
    "test_dataset = NowcastDataset(test_dataset_generator,\n",
    "                              module_name=\"generation\",\n",
    "                              distribute=train_params.get('distribute', False),\n",
    "                              num_workers=data_params.get('num_workers', 1),\n",
    "                              shuffle=False)\n",
    "test_dataset = test_dataset.create_dataset(data_params.get('batch_size', 1))\n",
    "data = next(test_dataset.create_dict_iterator())\n",
    "inp, evo_result, labels = data.get(\"inputs\"), data.get(\"evo\"), data.get(\"labels\")\n",
    "noise_scale = data_params.get(\"noise_scale\", 32)\n",
    "threshold = summary_params.get(\"csin_threshold\", 16)\n",
    "batch_size = data_params.get(\"batch_size\", 1)\n",
    "w_size = data_params.get(\"w_size\", 512)\n",
    "h_size = data_params.get(\"h_size\", 512)\n",
    "ngf = model_params.get(\"ngf\", 32)\n",
    "noise = ms.tensor(ms.numpy.randn((batch_size, ngf, h_size // noise_scale, w_size // noise_scale)), inp.dtype)\n",
    "pred = gen_inference.generator(inp, evo_result, noise)\n",
    "plt_img(field=pred[0].asnumpy(), label=labels[0].asnumpy(), idx=plt_idx, fig_name=\"./generation_example.png\", evo=evo_result[0].asnumpy() * 128, plot_evo=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
