{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# NowcastNet: Physics-based generative model for extreme precipitation nowcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Overview\n",
    "\n",
    "NowcastNet is proposed by Long Mingsheng. It is a nonlinear nowcasting model for\n",
    "extreme precipitation with lead times of up to 3h. It includes a stochastic generative network and a deterministic\n",
    "evolution network. The evolution network yields physically plausible predictions for advective features at a scale of\n",
    "20km. The generative network generates convective details present in the radar observations.More information can be found in [paper](https://www.nature.com/articles/s41586-023-06184-4). The architecture of the Nowcastnet is shown below.\n",
    "\n",
    "![nowcastnet](images/nowcastnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## NowcastNet\n",
    "\n",
    "1. Evolution network：a motion decoder for learning motion fields $v_{1:T}$ and an intensity decoder for learning intensity residuals $s_{1:T}$. Then, evolution operator uses $v_{1:T}$ and $s_{1:T}$ to predict $x_{1:T}^{''}$. The formalization is shown below.\n",
    "\n",
    "$$\n",
    "x_{1:T}^{''} = Evolution(x_{-T:0})\n",
    "$$\n",
    "\n",
    "2. Nowcast encoder & decoder：It uses [Semantic Image Synthesis with Spatially-Adaptive Normalization](https://openaccess.thecvf.com/content_CVPR_2019/papers/Park_Semantic_Image_Synthesis_With_Spatially-Adaptive_Normalization_CVPR_2019_paper.pdf) to model the relation between physics-conditioning$x_{1:T}^{''}$and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Technology path\n",
    "\n",
    "MindSpore Earth solves the problem as follows:\n",
    "\n",
    "1. Data Construction.\n",
    "2. Model Construction.\n",
    "3. Loss function.\n",
    "4. Model Training.\n",
    "5. Model Evaluation and Visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Download the training and test dataset: [Nowcastnet/dataset]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T02:45:33.718460400Z",
     "start_time": "2024-02-01T02:45:27.178254400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(693605:281472989458464,MainProcess):2024-02-01-10:45:55.954.650 [mindspore/run_check/_check_version.py:348] Using custom Ascend AI software package (Ascend Data Center Solution) path, package version checking is skipped. Please make sure Ascend AI software package (Ascend Data Center Solution) version is supported. For details, refer to the installation guidelines https://www.mindspore.cn/install\n",
      "[WARNING] ME(693605:281472989458464,MainProcess):2024-02-01-10:45:55.957.409 [mindspore/run_check/_check_version.py:461] Can not find the tbe operator implementation(need by mindspore-ascend). Please check whether the Environment Variable PYTHONPATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(693605:281472989458464,MainProcess):2024-02-01-10:45:55.958.132 [mindspore/run_check/_check_version.py:468] Can not find driver so(need by mindspore-ascend). Please check whether the Environment Variable LD_LIBRARY_PATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import mindspore as ms\n",
    "import numpy as np\n",
    "from mindspore import context, nn, set_seed\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T02:45:42.550037400Z",
     "start_time": "2024-02-01T02:45:42.475237700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src import get_logger\n",
    "from src import EvolutionTrainer, GenerationTrainer, GenerateLoss, DiscriminatorLoss, EvolutionLoss\n",
    "from src import EvolutionPredictor, GenerationPredictor\n",
    "from src import RadarData, NowcastDataset\n",
    "from src import init_generation_model\n",
    "from src.evolution import EvolutionNet\n",
    "from src.visual import plt_img\n",
    "from mindearth.utils import make_dir\n",
    "from mindearth.utils.tools import load_yaml_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-30T12:21:12.488547200Z",
     "start_time": "2024-01-30T12:21:12.479570700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "set_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T02:46:31.312719300Z",
     "start_time": "2024-02-01T02:46:31.298942800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = load_yaml_config(\"./configs/Nowcastnet.yaml\")\n",
    "make_dir(os.path.join(config['summary'][\"summary_dir\"], \"img\"))\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"Ascend\", device_id=1)\n",
    "logger = get_logger(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Construction\n",
    "\n",
    "Download the statistic, training and validation dataset from [dataset]() to `./dataset`. Modify the parameter of `root_dir` in the `./configs/Nowcastnet.yaml`, which set the directory for dataset.\n",
    "\n",
    "The `./dataset` is hosted with the following directory structure:\n",
    "\n",
    "```markdown\n",
    "├── train\n",
    "├── valid\n",
    "├── test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T02:47:08.523769Z",
     "start_time": "2024-02-01T02:46:59.933399300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 10:47:26,275 - utils.py[line:55] - INFO: {'name': 'NowcastNet', 'ngf': 32, 'pool_ensemble_num': 4, 'module_name': 'evolution'}\n",
      "2024-02-01 10:47:26,276 - utils.py[line:55] - INFO: {'name': 'us', 'root_dir': '/data/zmmVol1/cszhou/usa_datasets', 't_in': 9, 't_out': 20, 'h_size': 512, 'w_size': 512, 'time_interval': 10, 'num_workers': 1, 'data_sink': False, 'batch_size': 1, 'noise_scale': 32}\n",
      "2024-02-01 10:47:26,277 - utils.py[line:55] - INFO: {'name': 'adam', 'beta1': 0.01, 'beta2': 0.9, 'g_lr': 1.5e-05, 'd_lr': '6e-5', 'epochs': 10}\n",
      "2024-02-01 10:47:26,278 - utils.py[line:55] - INFO: {'name': 'adam', 'lr': 0.001, 'weight_decay': 0.1, 'gamma': 0.5, 'epochs': 50}\n",
      "2024-02-01 10:47:26,279 - utils.py[line:55] - INFO: {'summary_dir': './summary/', 'eval_interval': 2, 'save_checkpoint_epochs': 1, 'keep_checkpoint_max': 4, 'key_info_timestep': [10, 60, 120], 'generate_ckpt_path': '/data/zmmVol1/cszhou/nowcastnet_final/applications/nowcasting/Nowcastnet/ckpt/generator-device13.ckpt', 'evolution_ckpt_path': '/data/zmmVol1/cszhou/nowcastnet_final/applications/nowcasting/Nowcastnet/scripts/single_device5/summary/ckpt/evolution-38_400.ckpt', 'visual': True, 'csin_threshold': 16}\n",
      "2024-02-01 10:47:26,279 - utils.py[line:55] - INFO: {'distribute': False, 'mixed_precision': True, 'amp_level': 'O2', 'load_ckpt': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvolutionNet<\n",
       "  (evo_net): EvolutionNetwork<\n",
       "    (inc): DoubleConv<\n",
       "      (single_conv): SequentialCell<\n",
       "        (0): BatchNorm2d<num_features=9, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.inc.single_conv.0.gamma, shape=(9,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.inc.single_conv.0.beta, shape=(9,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.inc.single_conv.0.moving_mean, shape=(9,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.inc.single_conv.0.moving_variance, shape=(9,), dtype=Float32, requires_grad=False)>\n",
       "        (1): SpectralNormal<\n",
       "          (parametrizations): Conv2d<input_channels=9, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc994520>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc994700>, format=NCHW>\n",
       "          >\n",
       "        >\n",
       "      (double_conv): SequentialCell<\n",
       "        (0): BatchNorm2d<num_features=9, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.inc.double_conv.0.gamma, shape=(9,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.inc.double_conv.0.beta, shape=(9,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.inc.double_conv.0.moving_mean, shape=(9,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.inc.double_conv.0.moving_variance, shape=(9,), dtype=Float32, requires_grad=False)>\n",
       "        (1): ReLU<>\n",
       "        (2): SpectralNormal<\n",
       "          (parametrizations): Conv2d<input_channels=9, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc7003a0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc7004c0>, format=NCHW>\n",
       "          >\n",
       "        (3): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.inc.double_conv.3.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.inc.double_conv.3.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.inc.double_conv.3.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.inc.double_conv.3.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "        (4): ReLU<>\n",
       "        (5): SpectralNormal<\n",
       "          (parametrizations): Conv2d<input_channels=32, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc700a90>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc700c10>, format=NCHW>\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (down1): Down<\n",
       "      (maxpool_conv): SequentialCell<\n",
       "        (0): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n",
       "        (1): DoubleConv<\n",
       "          (single_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down1.maxpool_conv.1.single_conv.0.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down1.maxpool_conv.1.single_conv.0.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down1.maxpool_conv.1.single_conv.0.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down1.maxpool_conv.1.single_conv.0.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "            (1): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=32, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc700e50>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc700e80>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          (double_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.0.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.0.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.0.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.0.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "            (1): ReLU<>\n",
       "            (2): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=32, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc700ca0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc700490>, format=NCHW>\n",
       "              >\n",
       "            (3): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.3.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.3.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.3.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down1.maxpool_conv.1.double_conv.3.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "            (4): ReLU<>\n",
       "            (5): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc532310>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc5323d0>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (down2): Down<\n",
       "      (maxpool_conv): SequentialCell<\n",
       "        (0): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n",
       "        (1): DoubleConv<\n",
       "          (single_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down2.maxpool_conv.1.single_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down2.maxpool_conv.1.single_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down2.maxpool_conv.1.single_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down2.maxpool_conv.1.single_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "            (1): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=64, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc532580>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc532550>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          (double_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "            (1): ReLU<>\n",
       "            (2): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=64, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc532880>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc532760>, format=NCHW>\n",
       "              >\n",
       "            (3): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.3.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.3.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.3.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down2.maxpool_conv.1.double_conv.3.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "            (4): ReLU<>\n",
       "            (5): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=128, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc5329a0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc532a90>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (down3): Down<\n",
       "      (maxpool_conv): SequentialCell<\n",
       "        (0): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n",
       "        (1): DoubleConv<\n",
       "          (single_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down3.maxpool_conv.1.single_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down3.maxpool_conv.1.single_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down3.maxpool_conv.1.single_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down3.maxpool_conv.1.single_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "            (1): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=128, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc5326d0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc532280>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          (double_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "            (1): ReLU<>\n",
       "            (2): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=128, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc532f10>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc532fd0>, format=NCHW>\n",
       "              >\n",
       "            (3): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.3.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.3.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.3.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down3.maxpool_conv.1.double_conv.3.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "            (4): ReLU<>\n",
       "            (5): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffedc532d90>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffedc532d30>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (down4): Down<\n",
       "      (maxpool_conv): SequentialCell<\n",
       "        (0): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n",
       "        (1): DoubleConv<\n",
       "          (single_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down4.maxpool_conv.1.single_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down4.maxpool_conv.1.single_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down4.maxpool_conv.1.single_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down4.maxpool_conv.1.single_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "            (1): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f2b520>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f2b550>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          (double_conv): SequentialCell<\n",
       "            (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "            (1): ReLU<>\n",
       "            (2): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f2b580>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f2b670>, format=NCHW>\n",
       "              >\n",
       "            (3): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.3.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.3.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.3.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.down4.maxpool_conv.1.double_conv.3.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "            (4): ReLU<>\n",
       "            (5): SpectralNormal<\n",
       "              (parametrizations): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f2b730>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f2b640>, format=NCHW>\n",
       "              >\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up1): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1.conv.single_conv.0.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1.conv.single_conv.0.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1.conv.single_conv.0.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1.conv.single_conv.0.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=512, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f2bd00>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f2bd30>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1.conv.double_conv.0.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1.conv.double_conv.0.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1.conv.double_conv.0.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1.conv.double_conv.0.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=512, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f2bb80>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f2b700>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1.conv.double_conv.3.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1.conv.double_conv.3.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1.conv.double_conv.3.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1.conv.double_conv.3.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f12070>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f12190>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up2): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2.conv.single_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2.conv.single_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2.conv.single_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2.conv.single_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f122e0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f12250>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2.conv.double_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2.conv.double_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2.conv.double_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2.conv.double_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f125b0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f2bbb0>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2.conv.double_conv.3.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2.conv.double_conv.3.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2.conv.double_conv.3.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2.conv.double_conv.3.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f126d0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f12790>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up3): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3.conv.single_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3.conv.single_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3.conv.single_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3.conv.single_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f129d0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f129a0>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3.conv.double_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3.conv.double_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3.conv.double_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3.conv.double_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f12bb0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f12c70>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3.conv.double_conv.3.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3.conv.double_conv.3.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3.conv.double_conv.3.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3.conv.double_conv.3.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9f12c40>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9f12760>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up4): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4.conv.single_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4.conv.single_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4.conv.single_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4.conv.single_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9e85070>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9e85190>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4.conv.double_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4.conv.double_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4.conv.double_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4.conv.double_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9e852e0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9e85280>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4.conv.double_conv.3.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4.conv.double_conv.3.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4.conv.double_conv.3.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4.conv.double_conv.3.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=32, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9e85550>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9e85610>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (outc): OutConv<\n",
       "      (conv): Conv2d<input_channels=32, output_channels=20, kernel_size=(1, 1), stride=(1, 1), pad_mode=pad, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9e85640>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9e85340>, format=NCHW>\n",
       "      >\n",
       "    (up1_v): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1_v.conv.single_conv.0.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1_v.conv.single_conv.0.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1_v.conv.single_conv.0.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1_v.conv.single_conv.0.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=512, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9e85910>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9e85940>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=512, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1_v.conv.double_conv.0.gamma, shape=(512,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1_v.conv.double_conv.0.beta, shape=(512,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1_v.conv.double_conv.0.moving_mean, shape=(512,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1_v.conv.double_conv.0.moving_variance, shape=(512,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=512, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9e851c0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9e854c0>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up1_v.conv.double_conv.3.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up1_v.conv.double_conv.3.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up1_v.conv.double_conv.3.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up1_v.conv.double_conv.3.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9e85d30>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9e85df0>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up2_v): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2_v.conv.single_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2_v.conv.single_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2_v.conv.single_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2_v.conv.single_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9e85ee0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9e85fd0>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=256, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2_v.conv.double_conv.0.gamma, shape=(256,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2_v.conv.double_conv.0.beta, shape=(256,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2_v.conv.double_conv.0.moving_mean, shape=(256,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2_v.conv.double_conv.0.moving_variance, shape=(256,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=256, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9e85a00>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9e85790>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up2_v.conv.double_conv.3.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up2_v.conv.double_conv.3.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up2_v.conv.double_conv.3.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up2_v.conv.double_conv.3.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9df63a0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9df6460>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up3_v): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3_v.conv.single_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3_v.conv.single_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3_v.conv.single_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3_v.conv.single_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9df6670>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9df6520>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=128, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3_v.conv.double_conv.0.gamma, shape=(128,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3_v.conv.double_conv.0.beta, shape=(128,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3_v.conv.double_conv.0.moving_mean, shape=(128,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3_v.conv.double_conv.0.moving_variance, shape=(128,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=128, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9df6880>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9df6940>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up3_v.conv.double_conv.3.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up3_v.conv.double_conv.3.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up3_v.conv.double_conv.3.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up3_v.conv.double_conv.3.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9df65b0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9df6610>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (up4_v): Up<\n",
       "      (up): Upsample<>\n",
       "      (conv): DoubleConv<\n",
       "        (single_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4_v.conv.single_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4_v.conv.single_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4_v.conv.single_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4_v.conv.single_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (1): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9df6df0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9df6e20>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        (double_conv): SequentialCell<\n",
       "          (0): BatchNorm2d<num_features=64, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4_v.conv.double_conv.0.gamma, shape=(64,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4_v.conv.double_conv.0.beta, shape=(64,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4_v.conv.double_conv.0.moving_mean, shape=(64,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4_v.conv.double_conv.0.moving_variance, shape=(64,), dtype=Float32, requires_grad=False)>\n",
       "          (1): ReLU<>\n",
       "          (2): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=64, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9df6b20>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9df6f40>, format=NCHW>\n",
       "            >\n",
       "          (3): BatchNorm2d<num_features=32, eps=1e-05, momentum=0.9, gamma=Parameter (name=evo_net.up4_v.conv.double_conv.3.gamma, shape=(32,), dtype=Float32, requires_grad=True), beta=Parameter (name=evo_net.up4_v.conv.double_conv.3.beta, shape=(32,), dtype=Float32, requires_grad=True), moving_mean=Parameter (name=evo_net.up4_v.conv.double_conv.3.moving_mean, shape=(32,), dtype=Float32, requires_grad=False), moving_variance=Parameter (name=evo_net.up4_v.conv.double_conv.3.moving_variance, shape=(32,), dtype=Float32, requires_grad=False)>\n",
       "          (4): ReLU<>\n",
       "          (5): SpectralNormal<\n",
       "            (parametrizations): Conv2d<input_channels=32, output_channels=32, kernel_size=(3, 3), stride=(1, 1), pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9d670a0>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9d67250>, format=NCHW>\n",
       "            >\n",
       "          >\n",
       "        >\n",
       "      >\n",
       "    (outc_v): OutConv<\n",
       "      (conv): Conv2d<input_channels=32, output_channels=40, kernel_size=(1, 1), stride=(1, 1), pad_mode=pad, padding=0, dilation=(1, 1), group=1, has_bias=True, weight_init=<mindspore.common.initializer.HeUniform object at 0xfffed9df6c10>, bias_init=<mindspore.common.initializer.Uniform object at 0xfffed9d67070>, format=NCHW>\n",
       "      >\n",
       "    >\n",
       "  >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"model\"][\"module_name\"] = 'evolution'\n",
    "config[\"data\"][\"batch_size\"] = 4\n",
    "config[\"summary\"][\"eval_interval\"] = 1\n",
    "config[\"summary\"][\"visual\"] = False\n",
    "train_params = config.get(\"train\")\n",
    "summary_params = config.get(\"summary\")\n",
    "evo_model = EvolutionNet(config.get('data').get(\"t_in\", 9),\n",
    "                         config.get('data').get(\"t_out\", 20),\n",
    "                         config.get('data').get(\"h_size\", 512),\n",
    "                         config.get('data').get(\"w_size\", 512))\n",
    "evo_model.set_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T03:24:30.164901700Z",
     "start_time": "2024-01-31T01:01:39.614516800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] MD(4138269,fffcfb65b120,python):2024-01-31-09:02:51.669.590 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:231] operator()] Bad performance attention, it takes more than 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 16.964931\n",
      "epoch: 1 step: 2, loss is 14.502213\n",
      "epoch: 1 step: 3, loss is 10.780349\n",
      "epoch: 1 step: 4, loss is 11.027175\n",
      "epoch: 1 step: 5, loss is 3.8108711\n",
      "epoch: 1 step: 6, loss is 13.924669\n",
      "epoch: 1 step: 7, loss is 12.181091\n",
      "epoch: 1 step: 8, loss is 4.613654\n",
      "epoch: 1 step: 9, loss is 4.306578\n",
      "epoch: 1 step: 10, loss is 4.932178\n",
      "epoch: 1 step: 11, loss is 6.628277\n",
      "epoch: 1 step: 12, loss is 3.5065076\n",
      "epoch: 1 step: 13, loss is 20.65365\n",
      "epoch: 1 step: 14, loss is 17.443842\n",
      "epoch: 1 step: 15, loss is 7.5954895\n",
      "epoch: 1 step: 16, loss is 7.138162\n",
      "epoch: 1 step: 17, loss is 6.9041977\n",
      "epoch: 1 step: 18, loss is 19.990036\n",
      "epoch: 1 step: 19, loss is 9.513996\n",
      "epoch: 1 step: 20, loss is 7.3165126\n",
      "epoch: 1 step: 21, loss is 6.1689415\n",
      "epoch: 1 step: 22, loss is 6.158663\n",
      "epoch: 1 step: 23, loss is 9.237205\n",
      "epoch: 1 step: 24, loss is 7.669189\n",
      "epoch: 1 step: 25, loss is 5.0312796\n",
      "epoch: 1 step: 26, loss is 6.590024\n",
      "epoch: 1 step: 27, loss is 15.463813\n",
      "epoch: 1 step: 28, loss is 7.9854445\n",
      "epoch: 1 step: 29, loss is 4.398997\n",
      "epoch: 1 step: 30, loss is 4.5272164\n",
      "epoch: 1 step: 31, loss is 11.291908\n",
      "epoch: 1 step: 32, loss is 4.758201\n",
      "epoch: 1 step: 33, loss is 12.15818\n",
      "epoch: 1 step: 34, loss is 9.617511\n",
      "epoch: 1 step: 35, loss is 10.697494\n",
      "epoch: 1 step: 36, loss is 9.898358\n",
      "epoch: 1 step: 37, loss is 9.26039\n",
      "epoch: 1 step: 38, loss is 6.876935\n",
      "epoch: 1 step: 39, loss is 19.414267\n",
      "epoch: 1 step: 40, loss is 6.9686904\n",
      "epoch: 1 step: 41, loss is 8.792517\n",
      "epoch: 1 step: 42, loss is 5.86637\n",
      "epoch: 1 step: 43, loss is 13.445674\n",
      "epoch: 1 step: 44, loss is 15.180026\n",
      "epoch: 1 step: 45, loss is 11.377322\n",
      "epoch: 1 step: 46, loss is 8.324775\n",
      "epoch: 1 step: 47, loss is 10.875625\n",
      "epoch: 1 step: 48, loss is 6.671407\n",
      "epoch: 1 step: 49, loss is 7.2738595\n",
      "epoch: 1 step: 50, loss is 2.5302095\n",
      "epoch: 1 step: 51, loss is 12.482405\n",
      "epoch: 1 step: 52, loss is 10.49932\n",
      "epoch: 1 step: 53, loss is 8.723933\n",
      "epoch: 1 step: 54, loss is 5.7406073\n",
      "epoch: 1 step: 55, loss is 8.1165085\n",
      "epoch: 1 step: 56, loss is 5.586655\n",
      "epoch: 1 step: 57, loss is 10.743989\n",
      "epoch: 1 step: 58, loss is 2.4052536\n",
      "epoch: 1 step: 59, loss is 7.8741846\n",
      "epoch: 1 step: 60, loss is 15.538988\n",
      "epoch: 1 step: 61, loss is 9.297923\n",
      "epoch: 1 step: 62, loss is 5.390023\n",
      "epoch: 1 step: 63, loss is 5.696861\n",
      "epoch: 1 step: 64, loss is 8.24357\n",
      "epoch: 1 step: 65, loss is 4.29499\n",
      "epoch: 1 step: 66, loss is 4.2717934\n",
      "epoch: 1 step: 67, loss is 10.973701\n",
      "epoch: 1 step: 68, loss is 14.457351\n",
      "epoch: 1 step: 69, loss is 6.1116934\n",
      "epoch: 1 step: 70, loss is 10.326851\n",
      "epoch: 1 step: 71, loss is 7.462485\n",
      "epoch: 1 step: 72, loss is 12.940358\n",
      "epoch: 1 step: 73, loss is 4.1140833\n",
      "epoch: 1 step: 74, loss is 10.428161\n",
      "epoch: 1 step: 75, loss is 3.6108303\n",
      "epoch: 1 step: 76, loss is 16.931557\n",
      "epoch: 1 step: 77, loss is 13.471918\n",
      "epoch: 1 step: 78, loss is 14.105043\n",
      "epoch: 1 step: 79, loss is 20.49185\n",
      "epoch: 1 step: 80, loss is 7.827617\n",
      "epoch: 1 step: 81, loss is 15.288184\n",
      "epoch: 1 step: 82, loss is 21.24135\n",
      "epoch: 1 step: 83, loss is 7.5578628\n",
      "epoch: 1 step: 84, loss is 3.9976785\n",
      "epoch: 1 step: 85, loss is 11.95989\n",
      "epoch: 1 step: 86, loss is 4.5543447\n",
      "epoch: 1 step: 87, loss is 6.509666\n",
      "epoch: 1 step: 88, loss is 8.042537\n",
      "epoch: 1 step: 89, loss is 7.300719\n",
      "epoch: 1 step: 90, loss is 3.464943\n",
      "epoch: 1 step: 91, loss is 9.632981\n",
      "epoch: 1 step: 92, loss is 7.315619\n",
      "epoch: 1 step: 93, loss is 7.2241855\n",
      "epoch: 1 step: 94, loss is 8.3599\n",
      "epoch: 1 step: 95, loss is 2.32561\n",
      "epoch: 1 step: 96, loss is 9.266434\n",
      "epoch: 1 step: 97, loss is 10.457726\n",
      "epoch: 1 step: 98, loss is 4.792747\n",
      "epoch: 1 step: 99, loss is 4.498106\n",
      "epoch: 1 step: 100, loss is 7.439522\n",
      "epoch: 1 step: 101, loss is 10.878738\n",
      "epoch: 1 step: 102, loss is 5.3957043\n",
      "epoch: 1 step: 103, loss is 6.0373197\n",
      "epoch: 1 step: 104, loss is 6.7042694\n",
      "epoch: 1 step: 105, loss is 6.3693085\n",
      "epoch: 1 step: 106, loss is 7.909204\n",
      "epoch: 1 step: 107, loss is 13.680556\n",
      "epoch: 1 step: 108, loss is 6.0075154\n",
      "epoch: 1 step: 109, loss is 9.484731\n",
      "epoch: 1 step: 110, loss is 11.522829\n",
      "epoch: 1 step: 111, loss is 10.184873\n",
      "epoch: 1 step: 112, loss is 5.731665\n",
      "epoch: 1 step: 113, loss is 3.8105686\n",
      "epoch: 1 step: 114, loss is 9.551883\n",
      "epoch: 1 step: 115, loss is 14.625876\n",
      "epoch: 1 step: 116, loss is 14.840924\n",
      "epoch: 1 step: 117, loss is 5.2914557\n",
      "epoch: 1 step: 118, loss is 5.4606357\n",
      "epoch: 1 step: 119, loss is 4.2632265\n",
      "epoch: 1 step: 120, loss is 14.183838\n",
      "epoch: 1 step: 121, loss is 13.063286\n",
      "epoch: 1 step: 122, loss is 18.90632\n",
      "epoch: 1 step: 123, loss is 14.5564575\n",
      "epoch: 1 step: 124, loss is 4.44399\n",
      "epoch: 1 step: 125, loss is 7.264557\n",
      "epoch: 1 step: 126, loss is 12.214412\n",
      "epoch: 1 step: 127, loss is 11.335418\n",
      "epoch: 1 step: 128, loss is 12.424735\n",
      "epoch: 1 step: 129, loss is 11.148064\n",
      "epoch: 1 step: 130, loss is 3.0634212\n",
      "epoch: 1 step: 131, loss is 9.569626\n",
      "epoch: 1 step: 132, loss is 13.128596\n",
      "epoch: 1 step: 133, loss is 12.354448\n",
      "epoch: 1 step: 134, loss is 9.601986\n",
      "epoch: 1 step: 135, loss is 2.7166932\n",
      "epoch: 1 step: 136, loss is 4.251752\n",
      "epoch: 1 step: 137, loss is 23.482744\n",
      "epoch: 1 step: 138, loss is 5.436116\n",
      "epoch: 1 step: 139, loss is 4.289401\n",
      "epoch: 1 step: 140, loss is 7.24936\n",
      "epoch: 1 step: 141, loss is 8.673624\n",
      "epoch: 1 step: 142, loss is 9.799458\n",
      "epoch: 1 step: 143, loss is 7.263776\n",
      "epoch: 1 step: 144, loss is 8.3800125\n",
      "epoch: 1 step: 145, loss is 9.532288\n",
      "epoch: 1 step: 146, loss is 17.03655\n",
      "epoch: 1 step: 147, loss is 7.8191466\n",
      "epoch: 1 step: 148, loss is 11.993373\n",
      "epoch: 1 step: 149, loss is 12.577567\n",
      "epoch: 1 step: 150, loss is 8.181959\n",
      "epoch: 1 step: 151, loss is 6.631215\n",
      "epoch: 1 step: 152, loss is 13.766024\n",
      "epoch: 1 step: 153, loss is 9.468322\n",
      "epoch: 1 step: 154, loss is 9.816963\n",
      "epoch: 1 step: 155, loss is 8.041017\n",
      "epoch: 1 step: 156, loss is 4.829606\n",
      "epoch: 1 step: 157, loss is 6.762423\n",
      "epoch: 1 step: 158, loss is 12.020473\n",
      "epoch: 1 step: 159, loss is 7.8607407\n",
      "epoch: 1 step: 160, loss is 4.0203385\n",
      "epoch: 1 step: 161, loss is 6.353967\n",
      "epoch: 1 step: 162, loss is 4.0598826\n",
      "epoch: 1 step: 163, loss is 3.6132944\n",
      "epoch: 1 step: 164, loss is 11.348147\n",
      "epoch: 1 step: 165, loss is 11.713739\n",
      "epoch: 1 step: 166, loss is 18.555906\n",
      "epoch: 1 step: 167, loss is 7.0928855\n",
      "epoch: 1 step: 168, loss is 8.019599\n",
      "epoch: 1 step: 169, loss is 6.473865\n",
      "epoch: 1 step: 170, loss is 8.242885\n",
      "epoch: 1 step: 171, loss is 4.784219\n",
      "epoch: 1 step: 172, loss is 13.512122\n",
      "epoch: 1 step: 173, loss is 9.940894\n",
      "epoch: 1 step: 174, loss is 7.437154\n",
      "epoch: 1 step: 175, loss is 4.4937067\n",
      "epoch: 1 step: 176, loss is 14.391604\n",
      "epoch: 1 step: 177, loss is 2.2355168\n",
      "epoch: 1 step: 178, loss is 7.665934\n",
      "epoch: 1 step: 179, loss is 10.328207\n",
      "epoch: 1 step: 180, loss is 14.156844\n",
      "epoch: 1 step: 181, loss is 6.245267\n",
      "epoch: 1 step: 182, loss is 15.584538\n",
      "epoch: 1 step: 183, loss is 2.1077874\n",
      "epoch: 1 step: 184, loss is 3.5419939\n",
      "epoch: 1 step: 185, loss is 5.6080604\n",
      "epoch: 1 step: 186, loss is 10.985804\n",
      "epoch: 1 step: 187, loss is 8.52919\n",
      "epoch: 1 step: 188, loss is 7.9665284\n",
      "epoch: 1 step: 189, loss is 7.1876893\n",
      "epoch: 1 step: 190, loss is 13.44533\n",
      "epoch: 1 step: 191, loss is 13.128505\n",
      "epoch: 1 step: 192, loss is 8.743109\n",
      "epoch: 1 step: 193, loss is 6.9234285\n",
      "epoch: 1 step: 194, loss is 8.952152\n",
      "epoch: 1 step: 195, loss is 13.811938\n",
      "epoch: 1 step: 196, loss is 11.274354\n",
      "epoch: 1 step: 197, loss is 10.706752\n",
      "epoch: 1 step: 198, loss is 6.335921\n",
      "epoch: 1 step: 199, loss is 19.018145\n",
      "epoch: 1 step: 200, loss is 5.913008\n",
      "epoch: 1 step: 201, loss is 5.8782706\n",
      "epoch: 1 step: 202, loss is 12.370498\n",
      "epoch: 1 step: 203, loss is 6.653756\n",
      "epoch: 1 step: 204, loss is 6.2753673\n",
      "epoch: 1 step: 205, loss is 8.764506\n",
      "epoch: 1 step: 206, loss is 13.218335\n",
      "epoch: 1 step: 207, loss is 10.977753\n",
      "epoch: 1 step: 208, loss is 6.318348\n",
      "epoch: 1 step: 209, loss is 6.7571025\n",
      "epoch: 1 step: 210, loss is 8.462529\n",
      "epoch: 1 step: 211, loss is 10.625142\n",
      "epoch: 1 step: 212, loss is 12.006033\n",
      "epoch: 1 step: 213, loss is 18.857683\n",
      "epoch: 1 step: 214, loss is 6.3117485\n",
      "epoch: 1 step: 215, loss is 7.57649\n",
      "epoch: 1 step: 216, loss is 7.947931\n",
      "epoch: 1 step: 217, loss is 6.690007\n",
      "epoch: 1 step: 218, loss is 7.4355044\n",
      "epoch: 1 step: 219, loss is 5.8383784\n",
      "epoch: 1 step: 220, loss is 7.9469423\n",
      "epoch: 1 step: 221, loss is 9.972283\n",
      "epoch: 1 step: 222, loss is 7.680134\n",
      "epoch: 1 step: 223, loss is 9.293043\n",
      "epoch: 1 step: 224, loss is 7.799268\n",
      "epoch: 1 step: 225, loss is 9.68341\n",
      "epoch: 1 step: 226, loss is 14.760447\n",
      "epoch: 1 step: 227, loss is 8.728953\n",
      "epoch: 1 step: 228, loss is 12.804427\n",
      "epoch: 1 step: 229, loss is 9.576239\n",
      "epoch: 1 step: 230, loss is 8.50848\n",
      "epoch: 1 step: 231, loss is 11.705716\n",
      "epoch: 1 step: 232, loss is 3.6493626\n",
      "epoch: 1 step: 233, loss is 8.572134\n",
      "epoch: 1 step: 234, loss is 13.613303\n",
      "epoch: 1 step: 235, loss is 9.064838\n",
      "epoch: 1 step: 236, loss is 16.527098\n",
      "epoch: 1 step: 237, loss is 14.337552\n",
      "epoch: 1 step: 238, loss is 11.650723\n",
      "epoch: 1 step: 239, loss is 9.424839\n",
      "epoch: 1 step: 240, loss is 11.140727\n",
      "epoch: 1 step: 241, loss is 6.140134\n",
      "epoch: 1 step: 242, loss is 6.678531\n",
      "epoch: 1 step: 243, loss is 5.3360233\n",
      "epoch: 1 step: 244, loss is 13.993085\n",
      "epoch: 1 step: 245, loss is 11.521411\n",
      "epoch: 1 step: 246, loss is 20.689844\n",
      "epoch: 1 step: 247, loss is 7.0184073\n",
      "epoch: 1 step: 248, loss is 4.3469954\n",
      "epoch: 1 step: 249, loss is 13.18764\n",
      "epoch: 1 step: 250, loss is 11.985401\n",
      "epoch: 1 step: 251, loss is 15.475783\n",
      "epoch: 1 step: 252, loss is 5.469285\n",
      "epoch: 1 step: 253, loss is 13.345296\n",
      "epoch: 1 step: 254, loss is 6.699672\n",
      "epoch: 1 step: 255, loss is 8.804835\n",
      "epoch: 1 step: 256, loss is 10.055738\n",
      "epoch: 1 step: 257, loss is 17.492495\n",
      "epoch: 1 step: 258, loss is 7.796107\n",
      "epoch: 1 step: 259, loss is 12.960048\n",
      "epoch: 1 step: 260, loss is 8.516406\n",
      "epoch: 1 step: 261, loss is 7.0510254\n",
      "epoch: 1 step: 262, loss is 6.873712\n",
      "epoch: 1 step: 263, loss is 3.8377035\n",
      "epoch: 1 step: 264, loss is 8.718678\n",
      "epoch: 1 step: 265, loss is 7.1279716\n",
      "epoch: 1 step: 266, loss is 7.9922028\n",
      "epoch: 1 step: 267, loss is 4.747283\n",
      "epoch: 1 step: 268, loss is 8.433405\n",
      "epoch: 1 step: 269, loss is 4.706301\n",
      "epoch: 1 step: 270, loss is 14.584383\n",
      "epoch: 1 step: 271, loss is 6.509504\n",
      "epoch: 1 step: 272, loss is 8.290088\n",
      "epoch: 1 step: 273, loss is 4.737615\n",
      "epoch: 1 step: 274, loss is 10.970706\n",
      "epoch: 1 step: 275, loss is 8.109492\n",
      "epoch: 1 step: 276, loss is 6.9756775\n",
      "epoch: 1 step: 277, loss is 10.41698\n",
      "epoch: 1 step: 278, loss is 13.584566\n",
      "epoch: 1 step: 279, loss is 7.0505614\n",
      "epoch: 1 step: 280, loss is 8.139429\n",
      "epoch: 1 step: 281, loss is 7.9716525\n",
      "epoch: 1 step: 282, loss is 10.396158\n",
      "epoch: 1 step: 283, loss is 15.148501\n",
      "epoch: 1 step: 284, loss is 4.380001\n",
      "epoch: 1 step: 285, loss is 4.0754213\n",
      "epoch: 1 step: 286, loss is 15.811124\n",
      "epoch: 1 step: 287, loss is 12.500298\n",
      "epoch: 1 step: 288, loss is 10.110407\n",
      "epoch: 1 step: 289, loss is 10.692337\n",
      "epoch: 1 step: 290, loss is 12.567976\n",
      "epoch: 1 step: 291, loss is 10.914864\n",
      "epoch: 1 step: 292, loss is 5.941654\n",
      "epoch: 1 step: 293, loss is 5.6451206\n",
      "epoch: 1 step: 294, loss is 2.7260299\n",
      "epoch: 1 step: 295, loss is 7.996601\n",
      "epoch: 1 step: 296, loss is 7.4386406\n",
      "epoch: 1 step: 297, loss is 8.1776495\n",
      "epoch: 1 step: 298, loss is 7.7091117\n",
      "epoch: 1 step: 299, loss is 8.312502\n",
      "epoch: 1 step: 300, loss is 8.100204\n",
      "epoch: 1 step: 301, loss is 6.3468375\n",
      "epoch: 1 step: 302, loss is 7.523632\n",
      "epoch: 1 step: 303, loss is 4.7613688\n",
      "epoch: 1 step: 304, loss is 19.382504\n",
      "epoch: 1 step: 305, loss is 2.661499\n",
      "epoch: 1 step: 306, loss is 6.581848\n",
      "epoch: 1 step: 307, loss is 17.015114\n",
      "epoch: 1 step: 308, loss is 5.368159\n",
      "epoch: 1 step: 309, loss is 6.088465\n",
      "epoch: 1 step: 310, loss is 11.750272\n",
      "epoch: 1 step: 311, loss is 11.693415\n",
      "epoch: 1 step: 312, loss is 13.704157\n",
      "epoch: 1 step: 313, loss is 11.232135\n",
      "epoch: 1 step: 314, loss is 3.6701562\n",
      "epoch: 1 step: 315, loss is 10.623233\n",
      "epoch: 1 step: 316, loss is 4.281273\n",
      "epoch: 1 step: 317, loss is 8.660683\n",
      "epoch: 1 step: 318, loss is 14.607958\n",
      "epoch: 1 step: 319, loss is 6.1075015\n",
      "epoch: 1 step: 320, loss is 6.1718245\n",
      "epoch: 1 step: 321, loss is 7.783943\n",
      "epoch: 1 step: 322, loss is 7.4864097\n",
      "epoch: 1 step: 323, loss is 12.649513\n",
      "epoch: 1 step: 324, loss is 10.401742\n",
      "epoch: 1 step: 325, loss is 8.134112\n",
      "epoch: 1 step: 326, loss is 4.4953103\n",
      "epoch: 1 step: 327, loss is 1.972975\n",
      "epoch: 1 step: 328, loss is 15.003345\n",
      "epoch: 1 step: 329, loss is 8.12178\n",
      "epoch: 1 step: 330, loss is 5.370235\n",
      "epoch: 1 step: 331, loss is 4.20061\n",
      "epoch: 1 step: 332, loss is 12.827085\n",
      "epoch: 1 step: 333, loss is 11.595283\n",
      "epoch: 1 step: 334, loss is 8.555338\n",
      "epoch: 1 step: 335, loss is 17.14596\n",
      "epoch: 1 step: 336, loss is 4.805692\n",
      "epoch: 1 step: 337, loss is 5.3607078\n",
      "epoch: 1 step: 338, loss is 18.441927\n",
      "epoch: 1 step: 339, loss is 11.609587\n",
      "epoch: 1 step: 340, loss is 6.3581595\n",
      "epoch: 1 step: 341, loss is 4.8234067\n",
      "epoch: 1 step: 342, loss is 9.863045\n",
      "epoch: 1 step: 343, loss is 10.113366\n",
      "epoch: 1 step: 344, loss is 11.9911995\n",
      "epoch: 1 step: 345, loss is 14.107406\n",
      "epoch: 1 step: 346, loss is 10.610396\n",
      "epoch: 1 step: 347, loss is 11.898156\n",
      "epoch: 1 step: 348, loss is 8.802024\n",
      "epoch: 1 step: 349, loss is 18.567091\n",
      "epoch: 1 step: 350, loss is 5.8980117\n",
      "epoch: 1 step: 351, loss is 16.104399\n",
      "epoch: 1 step: 352, loss is 7.775352\n",
      "epoch: 1 step: 353, loss is 5.3579774\n",
      "epoch: 1 step: 354, loss is 4.0566053\n",
      "epoch: 1 step: 355, loss is 6.556756\n",
      "epoch: 1 step: 356, loss is 1.8250645\n",
      "epoch: 1 step: 357, loss is 5.080116\n",
      "epoch: 1 step: 358, loss is 4.5969048\n",
      "epoch: 1 step: 359, loss is 4.02367\n",
      "epoch: 1 step: 360, loss is 18.282087\n",
      "epoch: 1 step: 361, loss is 12.694061\n",
      "epoch: 1 step: 362, loss is 12.354276\n",
      "epoch: 1 step: 363, loss is 7.8570275\n",
      "epoch: 1 step: 364, loss is 2.7255073\n",
      "epoch: 1 step: 365, loss is 13.490703\n",
      "epoch: 1 step: 366, loss is 7.2164245\n",
      "epoch: 1 step: 367, loss is 13.530998\n",
      "epoch: 1 step: 368, loss is 11.5138035\n",
      "epoch: 1 step: 369, loss is 13.798487\n",
      "epoch: 1 step: 370, loss is 4.251083\n",
      "epoch: 1 step: 371, loss is 5.4539146\n",
      "epoch: 1 step: 372, loss is 5.3844047\n",
      "epoch: 1 step: 373, loss is 4.1161246\n",
      "epoch: 1 step: 374, loss is 10.430495\n",
      "epoch: 1 step: 375, loss is 7.321725\n",
      "epoch: 1 step: 376, loss is 7.896744\n",
      "epoch: 1 step: 377, loss is 5.5631166\n",
      "epoch: 1 step: 378, loss is 12.331556\n",
      "epoch: 1 step: 379, loss is 1.9966191\n",
      "epoch: 1 step: 380, loss is 4.4902163\n",
      "epoch: 1 step: 381, loss is 4.982368\n",
      "epoch: 1 step: 382, loss is 11.313365\n",
      "epoch: 1 step: 383, loss is 12.783118\n",
      "epoch: 1 step: 384, loss is 4.868557\n",
      "epoch: 1 step: 385, loss is 7.2009416\n",
      "epoch: 1 step: 386, loss is 4.927545\n",
      "epoch: 1 step: 387, loss is 7.1093187\n",
      "epoch: 1 step: 388, loss is 5.77129\n",
      "epoch: 1 step: 389, loss is 8.019076\n",
      "epoch: 1 step: 390, loss is 9.89576\n",
      "epoch: 1 step: 391, loss is 11.473057\n",
      "epoch: 1 step: 392, loss is 3.8957233\n",
      "epoch: 1 step: 393, loss is 1.7264107\n",
      "epoch: 1 step: 394, loss is 9.8388815\n",
      "epoch: 1 step: 395, loss is 6.835823\n",
      "epoch: 1 step: 396, loss is 5.9300346\n",
      "epoch: 1 step: 397, loss is 13.365226\n",
      "epoch: 1 step: 398, loss is 6.6358147\n",
      "epoch: 1 step: 399, loss is 11.47153\n",
      "epoch: 1 step: 400, loss is 7.2303286\n",
      "Train epoch time: 1794325.439 ms, per step time: 4485.814 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 09:32:00,659 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 09:32:00,661 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 09:32:04,107 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.4054458796087876 T+60 min: 0.16474475307855177 T+120 min: 0.09442198339292594\n",
      "2024-01-31 09:32:04,181 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 step: 1, loss is 3.5902307\n",
      "epoch: 2 step: 2, loss is 6.164537\n",
      "epoch: 2 step: 3, loss is 11.180219\n",
      "epoch: 2 step: 4, loss is 11.332051\n",
      "epoch: 2 step: 5, loss is 4.4809947\n",
      "epoch: 2 step: 6, loss is 6.9257097\n",
      "epoch: 2 step: 7, loss is 7.415494\n",
      "epoch: 2 step: 8, loss is 11.204009\n",
      "epoch: 2 step: 9, loss is 8.37794\n",
      "epoch: 2 step: 10, loss is 9.490828\n",
      "epoch: 2 step: 11, loss is 2.3988461\n",
      "epoch: 2 step: 12, loss is 6.1954045\n",
      "epoch: 2 step: 13, loss is 12.88989\n",
      "epoch: 2 step: 14, loss is 14.573158\n",
      "epoch: 2 step: 15, loss is 6.751909\n",
      "epoch: 2 step: 16, loss is 6.6825066\n",
      "epoch: 2 step: 17, loss is 8.922988\n",
      "epoch: 2 step: 18, loss is 10.171614\n",
      "epoch: 2 step: 19, loss is 21.820257\n",
      "epoch: 2 step: 20, loss is 8.730773\n",
      "epoch: 2 step: 21, loss is 11.956616\n",
      "epoch: 2 step: 22, loss is 12.381399\n",
      "epoch: 2 step: 23, loss is 6.375179\n",
      "epoch: 2 step: 24, loss is 6.8310676\n",
      "epoch: 2 step: 25, loss is 9.096922\n",
      "epoch: 2 step: 26, loss is 8.052887\n",
      "epoch: 2 step: 27, loss is 10.0189085\n",
      "epoch: 2 step: 28, loss is 6.9568367\n",
      "epoch: 2 step: 29, loss is 8.110953\n",
      "epoch: 2 step: 30, loss is 7.743202\n",
      "epoch: 2 step: 31, loss is 9.142183\n",
      "epoch: 2 step: 32, loss is 3.963022\n",
      "epoch: 2 step: 33, loss is 10.550201\n",
      "epoch: 2 step: 34, loss is 12.281748\n",
      "epoch: 2 step: 35, loss is 13.465476\n",
      "epoch: 2 step: 36, loss is 12.146997\n",
      "epoch: 2 step: 37, loss is 5.2931256\n",
      "epoch: 2 step: 38, loss is 12.128537\n",
      "epoch: 2 step: 39, loss is 4.236503\n",
      "epoch: 2 step: 40, loss is 12.060542\n",
      "epoch: 2 step: 41, loss is 3.402657\n",
      "epoch: 2 step: 42, loss is 15.347463\n",
      "epoch: 2 step: 43, loss is 8.246298\n",
      "epoch: 2 step: 44, loss is 10.587758\n",
      "epoch: 2 step: 45, loss is 12.190825\n",
      "epoch: 2 step: 46, loss is 12.451841\n",
      "epoch: 2 step: 47, loss is 7.1361947\n",
      "epoch: 2 step: 48, loss is 11.336909\n",
      "epoch: 2 step: 49, loss is 7.309054\n",
      "epoch: 2 step: 50, loss is 4.2109222\n",
      "epoch: 2 step: 51, loss is 13.240636\n",
      "epoch: 2 step: 52, loss is 9.888194\n",
      "epoch: 2 step: 53, loss is 13.570625\n",
      "epoch: 2 step: 54, loss is 13.212143\n",
      "epoch: 2 step: 55, loss is 8.365734\n",
      "epoch: 2 step: 56, loss is 7.16347\n",
      "epoch: 2 step: 57, loss is 5.101911\n",
      "epoch: 2 step: 58, loss is 4.6784286\n",
      "epoch: 2 step: 59, loss is 6.5032053\n",
      "epoch: 2 step: 60, loss is 6.365212\n",
      "epoch: 2 step: 61, loss is 9.545447\n",
      "epoch: 2 step: 62, loss is 5.310281\n",
      "epoch: 2 step: 63, loss is 5.344236\n",
      "epoch: 2 step: 64, loss is 4.1562037\n",
      "epoch: 2 step: 65, loss is 5.8225923\n",
      "epoch: 2 step: 66, loss is 4.090275\n",
      "epoch: 2 step: 67, loss is 11.484424\n",
      "epoch: 2 step: 68, loss is 7.546144\n",
      "epoch: 2 step: 69, loss is 8.047069\n",
      "epoch: 2 step: 70, loss is 11.787371\n",
      "epoch: 2 step: 71, loss is 7.0848565\n",
      "epoch: 2 step: 72, loss is 6.30876\n",
      "epoch: 2 step: 73, loss is 12.056404\n",
      "epoch: 2 step: 74, loss is 12.668941\n",
      "epoch: 2 step: 75, loss is 8.926393\n",
      "epoch: 2 step: 76, loss is 2.7328854\n",
      "epoch: 2 step: 77, loss is 9.116481\n",
      "epoch: 2 step: 78, loss is 3.9502122\n",
      "epoch: 2 step: 79, loss is 14.535497\n",
      "epoch: 2 step: 80, loss is 13.295636\n",
      "epoch: 2 step: 81, loss is 10.152904\n",
      "epoch: 2 step: 82, loss is 9.260558\n",
      "epoch: 2 step: 83, loss is 16.8603\n",
      "epoch: 2 step: 84, loss is 11.238963\n",
      "epoch: 2 step: 85, loss is 6.2139883\n",
      "epoch: 2 step: 86, loss is 2.766853\n",
      "epoch: 2 step: 87, loss is 16.447927\n",
      "epoch: 2 step: 88, loss is 10.797151\n",
      "epoch: 2 step: 89, loss is 8.251236\n",
      "epoch: 2 step: 90, loss is 5.7845345\n",
      "epoch: 2 step: 91, loss is 5.6928062\n",
      "epoch: 2 step: 92, loss is 11.224189\n",
      "epoch: 2 step: 93, loss is 15.644973\n",
      "epoch: 2 step: 94, loss is 7.944646\n",
      "epoch: 2 step: 95, loss is 11.027203\n",
      "epoch: 2 step: 96, loss is 16.354975\n",
      "epoch: 2 step: 97, loss is 12.1733\n",
      "epoch: 2 step: 98, loss is 8.86968\n",
      "epoch: 2 step: 99, loss is 5.985891\n",
      "epoch: 2 step: 100, loss is 13.9713745\n",
      "epoch: 2 step: 101, loss is 9.478367\n",
      "epoch: 2 step: 102, loss is 13.662224\n",
      "epoch: 2 step: 103, loss is 11.494834\n",
      "epoch: 2 step: 104, loss is 11.579443\n",
      "epoch: 2 step: 105, loss is 12.76338\n",
      "epoch: 2 step: 106, loss is 6.647256\n",
      "epoch: 2 step: 107, loss is 6.5973277\n",
      "epoch: 2 step: 108, loss is 23.077032\n",
      "epoch: 2 step: 109, loss is 8.376225\n",
      "epoch: 2 step: 110, loss is 8.016612\n",
      "epoch: 2 step: 111, loss is 4.042365\n",
      "epoch: 2 step: 112, loss is 11.550816\n",
      "epoch: 2 step: 113, loss is 9.601252\n",
      "epoch: 2 step: 114, loss is 7.6853943\n",
      "epoch: 2 step: 115, loss is 7.0721946\n",
      "epoch: 2 step: 116, loss is 3.6418023\n",
      "epoch: 2 step: 117, loss is 2.6425476\n",
      "epoch: 2 step: 118, loss is 3.4654794\n",
      "epoch: 2 step: 119, loss is 7.8887343\n",
      "epoch: 2 step: 120, loss is 7.913855\n",
      "epoch: 2 step: 121, loss is 8.613564\n",
      "epoch: 2 step: 122, loss is 8.014841\n",
      "epoch: 2 step: 123, loss is 11.698581\n",
      "epoch: 2 step: 124, loss is 7.009118\n",
      "epoch: 2 step: 125, loss is 3.2938175\n",
      "epoch: 2 step: 126, loss is 11.201624\n",
      "epoch: 2 step: 127, loss is 10.113303\n",
      "epoch: 2 step: 128, loss is 5.4597983\n",
      "epoch: 2 step: 129, loss is 6.9519067\n",
      "epoch: 2 step: 130, loss is 3.3263035\n",
      "epoch: 2 step: 131, loss is 13.771629\n",
      "epoch: 2 step: 132, loss is 8.181102\n",
      "epoch: 2 step: 133, loss is 4.8423343\n",
      "epoch: 2 step: 134, loss is 6.2169724\n",
      "epoch: 2 step: 135, loss is 6.5294876\n",
      "epoch: 2 step: 136, loss is 4.0749464\n",
      "epoch: 2 step: 137, loss is 4.970653\n",
      "epoch: 2 step: 138, loss is 2.545008\n",
      "epoch: 2 step: 139, loss is 6.7413993\n",
      "epoch: 2 step: 140, loss is 5.195244\n",
      "epoch: 2 step: 141, loss is 11.366359\n",
      "epoch: 2 step: 142, loss is 12.9999695\n",
      "epoch: 2 step: 143, loss is 9.889552\n",
      "epoch: 2 step: 144, loss is 11.725775\n",
      "epoch: 2 step: 145, loss is 8.922037\n",
      "epoch: 2 step: 146, loss is 9.956292\n",
      "epoch: 2 step: 147, loss is 3.9910653\n",
      "epoch: 2 step: 148, loss is 4.125259\n",
      "epoch: 2 step: 149, loss is 5.675421\n",
      "epoch: 2 step: 150, loss is 10.2696295\n",
      "epoch: 2 step: 151, loss is 14.99657\n",
      "epoch: 2 step: 152, loss is 12.620851\n",
      "epoch: 2 step: 153, loss is 10.539119\n",
      "epoch: 2 step: 154, loss is 7.774999\n",
      "epoch: 2 step: 155, loss is 14.334155\n",
      "epoch: 2 step: 156, loss is 3.2186348\n",
      "epoch: 2 step: 157, loss is 10.7718115\n",
      "epoch: 2 step: 158, loss is 15.400685\n",
      "epoch: 2 step: 159, loss is 7.9398394\n",
      "epoch: 2 step: 160, loss is 4.3938217\n",
      "epoch: 2 step: 161, loss is 12.714574\n",
      "epoch: 2 step: 162, loss is 3.2595139\n",
      "epoch: 2 step: 163, loss is 12.930966\n",
      "epoch: 2 step: 164, loss is 6.246062\n",
      "epoch: 2 step: 165, loss is 16.100668\n",
      "epoch: 2 step: 166, loss is 12.145316\n",
      "epoch: 2 step: 167, loss is 7.848287\n",
      "epoch: 2 step: 168, loss is 7.352586\n",
      "epoch: 2 step: 169, loss is 7.0305924\n",
      "epoch: 2 step: 170, loss is 2.8503387\n",
      "epoch: 2 step: 171, loss is 4.4784603\n",
      "epoch: 2 step: 172, loss is 8.702354\n",
      "epoch: 2 step: 173, loss is 4.5586495\n",
      "epoch: 2 step: 174, loss is 10.117444\n",
      "epoch: 2 step: 175, loss is 9.310026\n",
      "epoch: 2 step: 176, loss is 4.739387\n",
      "epoch: 2 step: 177, loss is 17.377935\n",
      "epoch: 2 step: 178, loss is 17.068823\n",
      "epoch: 2 step: 179, loss is 13.092015\n",
      "epoch: 2 step: 180, loss is 15.346863\n",
      "epoch: 2 step: 181, loss is 3.5874317\n",
      "epoch: 2 step: 182, loss is 12.904947\n",
      "epoch: 2 step: 183, loss is 16.304346\n",
      "epoch: 2 step: 184, loss is 7.8395343\n",
      "epoch: 2 step: 185, loss is 5.1330028\n",
      "epoch: 2 step: 186, loss is 10.590071\n",
      "epoch: 2 step: 187, loss is 3.4636362\n",
      "epoch: 2 step: 188, loss is 11.427713\n",
      "epoch: 2 step: 189, loss is 5.3968816\n",
      "epoch: 2 step: 190, loss is 10.040416\n",
      "epoch: 2 step: 191, loss is 9.07088\n",
      "epoch: 2 step: 192, loss is 5.1004047\n",
      "epoch: 2 step: 193, loss is 12.069837\n",
      "epoch: 2 step: 194, loss is 13.48926\n",
      "epoch: 2 step: 195, loss is 9.757981\n",
      "epoch: 2 step: 196, loss is 16.034136\n",
      "epoch: 2 step: 197, loss is 13.260974\n",
      "epoch: 2 step: 198, loss is 6.974724\n",
      "epoch: 2 step: 199, loss is 6.953617\n",
      "epoch: 2 step: 200, loss is 4.634584\n",
      "epoch: 2 step: 201, loss is 7.028338\n",
      "epoch: 2 step: 202, loss is 11.323602\n",
      "epoch: 2 step: 203, loss is 5.562336\n",
      "epoch: 2 step: 204, loss is 8.291891\n",
      "epoch: 2 step: 205, loss is 2.1244857\n",
      "epoch: 2 step: 206, loss is 3.8604717\n",
      "epoch: 2 step: 207, loss is 12.692039\n",
      "epoch: 2 step: 208, loss is 6.9932733\n",
      "epoch: 2 step: 209, loss is 9.076287\n",
      "epoch: 2 step: 210, loss is 9.723704\n",
      "epoch: 2 step: 211, loss is 5.2368865\n",
      "epoch: 2 step: 212, loss is 5.199726\n",
      "epoch: 2 step: 213, loss is 7.7142577\n",
      "epoch: 2 step: 214, loss is 12.54171\n",
      "epoch: 2 step: 215, loss is 9.585287\n",
      "epoch: 2 step: 216, loss is 5.419639\n",
      "epoch: 2 step: 217, loss is 9.889884\n",
      "epoch: 2 step: 218, loss is 10.124169\n",
      "epoch: 2 step: 219, loss is 6.3251414\n",
      "epoch: 2 step: 220, loss is 4.730331\n",
      "epoch: 2 step: 221, loss is 4.8017716\n",
      "epoch: 2 step: 222, loss is 6.314808\n",
      "epoch: 2 step: 223, loss is 11.345702\n",
      "epoch: 2 step: 224, loss is 12.907297\n",
      "epoch: 2 step: 225, loss is 8.3995285\n",
      "epoch: 2 step: 226, loss is 13.3998995\n",
      "epoch: 2 step: 227, loss is 11.626922\n",
      "epoch: 2 step: 228, loss is 16.938524\n",
      "epoch: 2 step: 229, loss is 7.875486\n",
      "epoch: 2 step: 230, loss is 1.01351\n",
      "epoch: 2 step: 231, loss is 9.103618\n",
      "epoch: 2 step: 232, loss is 6.10383\n",
      "epoch: 2 step: 233, loss is 4.0472193\n",
      "epoch: 2 step: 234, loss is 4.7144976\n",
      "epoch: 2 step: 235, loss is 5.9155507\n",
      "epoch: 2 step: 236, loss is 16.520493\n",
      "epoch: 2 step: 237, loss is 4.443886\n",
      "epoch: 2 step: 238, loss is 10.625236\n",
      "epoch: 2 step: 239, loss is 6.502607\n",
      "epoch: 2 step: 240, loss is 7.6038527\n",
      "epoch: 2 step: 241, loss is 7.593755\n",
      "epoch: 2 step: 242, loss is 12.446227\n",
      "epoch: 2 step: 243, loss is 6.950078\n",
      "epoch: 2 step: 244, loss is 10.6412\n",
      "epoch: 2 step: 245, loss is 16.961386\n",
      "epoch: 2 step: 246, loss is 12.671943\n",
      "epoch: 2 step: 247, loss is 10.83973\n",
      "epoch: 2 step: 248, loss is 4.867165\n",
      "epoch: 2 step: 249, loss is 4.085074\n",
      "epoch: 2 step: 250, loss is 15.363601\n",
      "epoch: 2 step: 251, loss is 13.196632\n",
      "epoch: 2 step: 252, loss is 8.090506\n",
      "epoch: 2 step: 253, loss is 4.4392686\n",
      "epoch: 2 step: 254, loss is 6.09036\n",
      "epoch: 2 step: 255, loss is 8.64077\n",
      "epoch: 2 step: 256, loss is 9.250715\n",
      "epoch: 2 step: 257, loss is 8.768018\n",
      "epoch: 2 step: 258, loss is 16.663458\n",
      "epoch: 2 step: 259, loss is 8.535916\n",
      "epoch: 2 step: 260, loss is 6.805487\n",
      "epoch: 2 step: 261, loss is 2.2531843\n",
      "epoch: 2 step: 262, loss is 7.893066\n",
      "epoch: 2 step: 263, loss is 19.049095\n",
      "epoch: 2 step: 264, loss is 7.469293\n",
      "epoch: 2 step: 265, loss is 5.9620824\n",
      "epoch: 2 step: 266, loss is 18.863585\n",
      "epoch: 2 step: 267, loss is 9.773634\n",
      "epoch: 2 step: 268, loss is 14.89872\n",
      "epoch: 2 step: 269, loss is 5.6893783\n",
      "epoch: 2 step: 270, loss is 5.9205475\n",
      "epoch: 2 step: 271, loss is 12.429119\n",
      "epoch: 2 step: 272, loss is 5.094901\n",
      "epoch: 2 step: 273, loss is 11.725877\n",
      "epoch: 2 step: 274, loss is 4.596536\n",
      "epoch: 2 step: 275, loss is 7.5479484\n",
      "epoch: 2 step: 276, loss is 9.535804\n",
      "epoch: 2 step: 277, loss is 13.170703\n",
      "epoch: 2 step: 278, loss is 2.9478254\n",
      "epoch: 2 step: 279, loss is 5.497151\n",
      "epoch: 2 step: 280, loss is 7.469646\n",
      "epoch: 2 step: 281, loss is 2.7707424\n",
      "epoch: 2 step: 282, loss is 6.3240294\n",
      "epoch: 2 step: 283, loss is 10.455788\n",
      "epoch: 2 step: 284, loss is 3.974795\n",
      "epoch: 2 step: 285, loss is 10.164766\n",
      "epoch: 2 step: 286, loss is 8.665133\n",
      "epoch: 2 step: 287, loss is 15.268677\n",
      "epoch: 2 step: 288, loss is 12.318749\n",
      "epoch: 2 step: 289, loss is 10.5265\n",
      "epoch: 2 step: 290, loss is 8.4838295\n",
      "epoch: 2 step: 291, loss is 11.364627\n",
      "epoch: 2 step: 292, loss is 16.513672\n",
      "epoch: 2 step: 293, loss is 16.86052\n",
      "epoch: 2 step: 294, loss is 13.195221\n",
      "epoch: 2 step: 295, loss is 13.271289\n",
      "epoch: 2 step: 296, loss is 4.1092906\n",
      "epoch: 2 step: 297, loss is 11.367045\n",
      "epoch: 2 step: 298, loss is 10.060623\n",
      "epoch: 2 step: 299, loss is 6.2831507\n",
      "epoch: 2 step: 300, loss is 5.819244\n",
      "epoch: 2 step: 301, loss is 4.459101\n",
      "epoch: 2 step: 302, loss is 13.922836\n",
      "epoch: 2 step: 303, loss is 4.2946906\n",
      "epoch: 2 step: 304, loss is 4.33151\n",
      "epoch: 2 step: 305, loss is 14.268569\n",
      "epoch: 2 step: 306, loss is 4.8524013\n",
      "epoch: 2 step: 307, loss is 15.420482\n",
      "epoch: 2 step: 308, loss is 5.64585\n",
      "epoch: 2 step: 309, loss is 16.402136\n",
      "epoch: 2 step: 310, loss is 10.513843\n",
      "epoch: 2 step: 311, loss is 12.488105\n",
      "epoch: 2 step: 312, loss is 6.0826755\n",
      "epoch: 2 step: 313, loss is 3.4336698\n",
      "epoch: 2 step: 314, loss is 7.6654787\n",
      "epoch: 2 step: 315, loss is 12.411796\n",
      "epoch: 2 step: 316, loss is 7.0432773\n",
      "epoch: 2 step: 317, loss is 12.285403\n",
      "epoch: 2 step: 318, loss is 2.9164684\n",
      "epoch: 2 step: 319, loss is 6.997214\n",
      "epoch: 2 step: 320, loss is 6.231052\n",
      "epoch: 2 step: 321, loss is 6.1908035\n",
      "epoch: 2 step: 322, loss is 3.4095154\n",
      "epoch: 2 step: 323, loss is 8.235909\n",
      "epoch: 2 step: 324, loss is 3.839009\n",
      "epoch: 2 step: 325, loss is 7.9122095\n",
      "epoch: 2 step: 326, loss is 10.4650755\n",
      "epoch: 2 step: 327, loss is 6.0926514\n",
      "epoch: 2 step: 328, loss is 10.687957\n",
      "epoch: 2 step: 329, loss is 7.848503\n",
      "epoch: 2 step: 330, loss is 12.805781\n",
      "epoch: 2 step: 331, loss is 6.375276\n",
      "epoch: 2 step: 332, loss is 8.033614\n",
      "epoch: 2 step: 333, loss is 12.198896\n",
      "epoch: 2 step: 334, loss is 6.2554355\n",
      "epoch: 2 step: 335, loss is 7.6766396\n",
      "epoch: 2 step: 336, loss is 8.579577\n",
      "epoch: 2 step: 337, loss is 10.6671095\n",
      "epoch: 2 step: 338, loss is 8.020312\n",
      "epoch: 2 step: 339, loss is 9.489757\n",
      "epoch: 2 step: 340, loss is 12.269236\n",
      "epoch: 2 step: 341, loss is 27.296696\n",
      "epoch: 2 step: 342, loss is 5.171322\n",
      "epoch: 2 step: 343, loss is 11.728749\n",
      "epoch: 2 step: 344, loss is 11.169777\n",
      "epoch: 2 step: 345, loss is 5.458398\n",
      "epoch: 2 step: 346, loss is 5.78911\n",
      "epoch: 2 step: 347, loss is 2.9274514\n",
      "epoch: 2 step: 348, loss is 7.4018693\n",
      "epoch: 2 step: 349, loss is 9.33463\n",
      "epoch: 2 step: 350, loss is 9.200088\n",
      "epoch: 2 step: 351, loss is 6.134559\n",
      "epoch: 2 step: 352, loss is 5.7578588\n",
      "epoch: 2 step: 353, loss is 8.868519\n",
      "epoch: 2 step: 354, loss is 2.8058476\n",
      "epoch: 2 step: 355, loss is 8.246224\n",
      "epoch: 2 step: 356, loss is 6.90008\n",
      "epoch: 2 step: 357, loss is 11.968184\n",
      "epoch: 2 step: 358, loss is 12.93239\n",
      "epoch: 2 step: 359, loss is 5.4736686\n",
      "epoch: 2 step: 360, loss is 13.29988\n",
      "epoch: 2 step: 361, loss is 8.791315\n",
      "epoch: 2 step: 362, loss is 11.016503\n",
      "epoch: 2 step: 363, loss is 16.835129\n",
      "epoch: 2 step: 364, loss is 11.18768\n",
      "epoch: 2 step: 365, loss is 17.12584\n",
      "epoch: 2 step: 366, loss is 5.4613247\n",
      "epoch: 2 step: 367, loss is 9.642198\n",
      "epoch: 2 step: 368, loss is 6.4991746\n",
      "epoch: 2 step: 369, loss is 10.14177\n",
      "epoch: 2 step: 370, loss is 6.7438393\n",
      "epoch: 2 step: 371, loss is 10.260614\n",
      "epoch: 2 step: 372, loss is 2.3388724\n",
      "epoch: 2 step: 373, loss is 10.906717\n",
      "epoch: 2 step: 374, loss is 4.3277445\n",
      "epoch: 2 step: 375, loss is 9.924989\n",
      "epoch: 2 step: 376, loss is 10.085904\n",
      "epoch: 2 step: 377, loss is 8.016669\n",
      "epoch: 2 step: 378, loss is 9.791915\n",
      "epoch: 2 step: 379, loss is 13.639999\n",
      "epoch: 2 step: 380, loss is 12.051585\n",
      "epoch: 2 step: 381, loss is 9.764248\n",
      "epoch: 2 step: 382, loss is 10.555309\n",
      "epoch: 2 step: 383, loss is 13.815684\n",
      "epoch: 2 step: 384, loss is 4.407768\n",
      "epoch: 2 step: 385, loss is 14.262488\n",
      "epoch: 2 step: 386, loss is 10.830002\n",
      "epoch: 2 step: 387, loss is 10.928685\n",
      "epoch: 2 step: 388, loss is 7.9791884\n",
      "epoch: 2 step: 389, loss is 15.709459\n",
      "epoch: 2 step: 390, loss is 15.412381\n",
      "epoch: 2 step: 391, loss is 9.153276\n",
      "epoch: 2 step: 392, loss is 9.770236\n",
      "epoch: 2 step: 393, loss is 13.901111\n",
      "epoch: 2 step: 394, loss is 8.2784195\n",
      "epoch: 2 step: 395, loss is 5.905315\n",
      "epoch: 2 step: 396, loss is 13.185033\n",
      "epoch: 2 step: 397, loss is 12.38396\n",
      "epoch: 2 step: 398, loss is 7.7851076\n",
      "epoch: 2 step: 399, loss is 6.364196\n",
      "epoch: 2 step: 400, loss is 11.064963\n",
      "Train epoch time: 1688639.108 ms, per step time: 4221.598 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:00:12,836 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 10:00:12,838 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:00:16,213 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.41709989523909563 T+60 min: 0.16894114336218546 T+120 min: 0.10467792846088278\n",
      "2024-01-31 10:00:16,291 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 step: 1, loss is 7.1252494\n",
      "epoch: 3 step: 2, loss is 11.036712\n",
      "epoch: 3 step: 3, loss is 5.4519153\n",
      "epoch: 3 step: 4, loss is 5.8808107\n",
      "epoch: 3 step: 5, loss is 4.4894466\n",
      "epoch: 3 step: 6, loss is 4.2037396\n",
      "epoch: 3 step: 7, loss is 7.131599\n",
      "epoch: 3 step: 8, loss is 7.6371865\n",
      "epoch: 3 step: 9, loss is 10.900062\n",
      "epoch: 3 step: 10, loss is 6.7450824\n",
      "epoch: 3 step: 11, loss is 8.569858\n",
      "epoch: 3 step: 12, loss is 12.626097\n",
      "epoch: 3 step: 13, loss is 16.801985\n",
      "epoch: 3 step: 14, loss is 12.869039\n",
      "epoch: 3 step: 15, loss is 12.314567\n",
      "epoch: 3 step: 16, loss is 10.593638\n",
      "epoch: 3 step: 17, loss is 7.0162005\n",
      "epoch: 3 step: 18, loss is 14.256413\n",
      "epoch: 3 step: 19, loss is 6.391328\n",
      "epoch: 3 step: 20, loss is 6.419895\n",
      "epoch: 3 step: 21, loss is 12.473334\n",
      "epoch: 3 step: 22, loss is 10.50286\n",
      "epoch: 3 step: 23, loss is 6.199636\n",
      "epoch: 3 step: 24, loss is 12.170155\n",
      "epoch: 3 step: 25, loss is 10.767848\n",
      "epoch: 3 step: 26, loss is 3.7217011\n",
      "epoch: 3 step: 27, loss is 7.41636\n",
      "epoch: 3 step: 28, loss is 8.754957\n",
      "epoch: 3 step: 29, loss is 10.721056\n",
      "epoch: 3 step: 30, loss is 13.41573\n",
      "epoch: 3 step: 31, loss is 12.369431\n",
      "epoch: 3 step: 32, loss is 12.527661\n",
      "epoch: 3 step: 33, loss is 8.318936\n",
      "epoch: 3 step: 34, loss is 6.968779\n",
      "epoch: 3 step: 35, loss is 10.02579\n",
      "epoch: 3 step: 36, loss is 10.751868\n",
      "epoch: 3 step: 37, loss is 7.629959\n",
      "epoch: 3 step: 38, loss is 5.0034227\n",
      "epoch: 3 step: 39, loss is 4.653483\n",
      "epoch: 3 step: 40, loss is 8.515567\n",
      "epoch: 3 step: 41, loss is 8.258481\n",
      "epoch: 3 step: 42, loss is 12.310803\n",
      "epoch: 3 step: 43, loss is 8.894664\n",
      "epoch: 3 step: 44, loss is 8.478974\n",
      "epoch: 3 step: 45, loss is 11.548934\n",
      "epoch: 3 step: 46, loss is 11.114578\n",
      "epoch: 3 step: 47, loss is 11.374794\n",
      "epoch: 3 step: 48, loss is 12.539844\n",
      "epoch: 3 step: 49, loss is 8.426234\n",
      "epoch: 3 step: 50, loss is 13.767882\n",
      "epoch: 3 step: 51, loss is 16.16264\n",
      "epoch: 3 step: 52, loss is 11.728778\n",
      "epoch: 3 step: 53, loss is 13.91986\n",
      "epoch: 3 step: 54, loss is 8.307953\n",
      "epoch: 3 step: 55, loss is 11.460391\n",
      "epoch: 3 step: 56, loss is 4.677033\n",
      "epoch: 3 step: 57, loss is 10.287713\n",
      "epoch: 3 step: 58, loss is 4.0899553\n",
      "epoch: 3 step: 59, loss is 13.14405\n",
      "epoch: 3 step: 60, loss is 9.926351\n",
      "epoch: 3 step: 61, loss is 3.4921708\n",
      "epoch: 3 step: 62, loss is 9.957998\n",
      "epoch: 3 step: 63, loss is 9.321293\n",
      "epoch: 3 step: 64, loss is 11.367603\n",
      "epoch: 3 step: 65, loss is 3.9579086\n",
      "epoch: 3 step: 66, loss is 13.182986\n",
      "epoch: 3 step: 67, loss is 10.440848\n",
      "epoch: 3 step: 68, loss is 7.2526407\n",
      "epoch: 3 step: 69, loss is 11.419489\n",
      "epoch: 3 step: 70, loss is 11.404378\n",
      "epoch: 3 step: 71, loss is 12.730815\n",
      "epoch: 3 step: 72, loss is 8.048335\n",
      "epoch: 3 step: 73, loss is 3.4358842\n",
      "epoch: 3 step: 74, loss is 5.516293\n",
      "epoch: 3 step: 75, loss is 4.7600703\n",
      "epoch: 3 step: 76, loss is 10.421222\n",
      "epoch: 3 step: 77, loss is 10.347287\n",
      "epoch: 3 step: 78, loss is 6.4398055\n",
      "epoch: 3 step: 79, loss is 9.895462\n",
      "epoch: 3 step: 80, loss is 3.4589546\n",
      "epoch: 3 step: 81, loss is 5.2512436\n",
      "epoch: 3 step: 82, loss is 12.645004\n",
      "epoch: 3 step: 83, loss is 2.219214\n",
      "epoch: 3 step: 84, loss is 9.147678\n",
      "epoch: 3 step: 85, loss is 5.455143\n",
      "epoch: 3 step: 86, loss is 3.0193756\n",
      "epoch: 3 step: 87, loss is 11.154009\n",
      "epoch: 3 step: 88, loss is 17.096634\n",
      "epoch: 3 step: 89, loss is 9.082738\n",
      "epoch: 3 step: 90, loss is 13.794395\n",
      "epoch: 3 step: 91, loss is 13.460361\n",
      "epoch: 3 step: 92, loss is 6.4926515\n",
      "epoch: 3 step: 93, loss is 17.863716\n",
      "epoch: 3 step: 94, loss is 5.6714053\n",
      "epoch: 3 step: 95, loss is 10.452785\n",
      "epoch: 3 step: 96, loss is 5.5571895\n",
      "epoch: 3 step: 97, loss is 9.122199\n",
      "epoch: 3 step: 98, loss is 13.007586\n",
      "epoch: 3 step: 99, loss is 12.274165\n",
      "epoch: 3 step: 100, loss is 12.593251\n",
      "epoch: 3 step: 101, loss is 19.453524\n",
      "epoch: 3 step: 102, loss is 12.323127\n",
      "epoch: 3 step: 103, loss is 15.943438\n",
      "epoch: 3 step: 104, loss is 7.048824\n",
      "epoch: 3 step: 105, loss is 5.1395874\n",
      "epoch: 3 step: 106, loss is 13.605034\n",
      "epoch: 3 step: 107, loss is 7.143197\n",
      "epoch: 3 step: 108, loss is 16.594166\n",
      "epoch: 3 step: 109, loss is 8.751489\n",
      "epoch: 3 step: 110, loss is 8.513526\n",
      "epoch: 3 step: 111, loss is 15.462524\n",
      "epoch: 3 step: 112, loss is 11.62522\n",
      "epoch: 3 step: 113, loss is 5.876299\n",
      "epoch: 3 step: 114, loss is 9.593172\n",
      "epoch: 3 step: 115, loss is 13.139612\n",
      "epoch: 3 step: 116, loss is 2.3185706\n",
      "epoch: 3 step: 117, loss is 5.492456\n",
      "epoch: 3 step: 118, loss is 21.601189\n",
      "epoch: 3 step: 119, loss is 4.4091845\n",
      "epoch: 3 step: 120, loss is 4.1444793\n",
      "epoch: 3 step: 121, loss is 4.400072\n",
      "epoch: 3 step: 122, loss is 3.8407102\n",
      "epoch: 3 step: 123, loss is 11.795681\n",
      "epoch: 3 step: 124, loss is 14.003606\n",
      "epoch: 3 step: 125, loss is 12.342367\n",
      "epoch: 3 step: 126, loss is 17.124807\n",
      "epoch: 3 step: 127, loss is 5.140582\n",
      "epoch: 3 step: 128, loss is 8.453563\n",
      "epoch: 3 step: 129, loss is 6.9804244\n",
      "epoch: 3 step: 130, loss is 13.676351\n",
      "epoch: 3 step: 131, loss is 5.977342\n",
      "epoch: 3 step: 132, loss is 9.535567\n",
      "epoch: 3 step: 133, loss is 4.9637423\n",
      "epoch: 3 step: 134, loss is 7.6738977\n",
      "epoch: 3 step: 135, loss is 8.824555\n",
      "epoch: 3 step: 136, loss is 4.2818284\n",
      "epoch: 3 step: 137, loss is 7.8294916\n",
      "epoch: 3 step: 138, loss is 9.811589\n",
      "epoch: 3 step: 139, loss is 8.319696\n",
      "epoch: 3 step: 140, loss is 11.833242\n",
      "epoch: 3 step: 141, loss is 9.337647\n",
      "epoch: 3 step: 142, loss is 7.990991\n",
      "epoch: 3 step: 143, loss is 10.311142\n",
      "epoch: 3 step: 144, loss is 8.755572\n",
      "epoch: 3 step: 145, loss is 13.015883\n",
      "epoch: 3 step: 146, loss is 8.193568\n",
      "epoch: 3 step: 147, loss is 7.7664948\n",
      "epoch: 3 step: 148, loss is 6.6714754\n",
      "epoch: 3 step: 149, loss is 12.959691\n",
      "epoch: 3 step: 150, loss is 3.9051225\n",
      "epoch: 3 step: 151, loss is 14.532422\n",
      "epoch: 3 step: 152, loss is 8.112529\n",
      "epoch: 3 step: 153, loss is 3.8627934\n",
      "epoch: 3 step: 154, loss is 6.464882\n",
      "epoch: 3 step: 155, loss is 10.866905\n",
      "epoch: 3 step: 156, loss is 5.3408937\n",
      "epoch: 3 step: 157, loss is 4.6901617\n",
      "epoch: 3 step: 158, loss is 3.9422233\n",
      "epoch: 3 step: 159, loss is 6.9413466\n",
      "epoch: 3 step: 160, loss is 8.41715\n",
      "epoch: 3 step: 161, loss is 18.038269\n",
      "epoch: 3 step: 162, loss is 10.890504\n",
      "epoch: 3 step: 163, loss is 10.213196\n",
      "epoch: 3 step: 164, loss is 5.8512273\n",
      "epoch: 3 step: 165, loss is 19.224508\n",
      "epoch: 3 step: 166, loss is 1.6743206\n",
      "epoch: 3 step: 167, loss is 4.0736403\n",
      "epoch: 3 step: 168, loss is 6.568725\n",
      "epoch: 3 step: 169, loss is 6.5036163\n",
      "epoch: 3 step: 170, loss is 3.2806041\n",
      "epoch: 3 step: 171, loss is 17.350594\n",
      "epoch: 3 step: 172, loss is 10.720379\n",
      "epoch: 3 step: 173, loss is 14.819077\n",
      "epoch: 3 step: 174, loss is 9.348502\n",
      "epoch: 3 step: 175, loss is 8.403157\n",
      "epoch: 3 step: 176, loss is 15.955768\n",
      "epoch: 3 step: 177, loss is 9.932305\n",
      "epoch: 3 step: 178, loss is 8.917662\n",
      "epoch: 3 step: 179, loss is 11.369731\n",
      "epoch: 3 step: 180, loss is 8.441173\n",
      "epoch: 3 step: 181, loss is 3.2800446\n",
      "epoch: 3 step: 182, loss is 18.221891\n",
      "epoch: 3 step: 183, loss is 12.966662\n",
      "epoch: 3 step: 184, loss is 8.09284\n",
      "epoch: 3 step: 185, loss is 12.851425\n",
      "epoch: 3 step: 186, loss is 7.9701095\n",
      "epoch: 3 step: 187, loss is 9.386691\n",
      "epoch: 3 step: 188, loss is 5.9600296\n",
      "epoch: 3 step: 189, loss is 6.260385\n",
      "epoch: 3 step: 190, loss is 6.286342\n",
      "epoch: 3 step: 191, loss is 5.661381\n",
      "epoch: 3 step: 192, loss is 5.211166\n",
      "epoch: 3 step: 193, loss is 4.9982123\n",
      "epoch: 3 step: 194, loss is 12.869987\n",
      "epoch: 3 step: 195, loss is 9.14388\n",
      "epoch: 3 step: 196, loss is 17.957191\n",
      "epoch: 3 step: 197, loss is 4.8586283\n",
      "epoch: 3 step: 198, loss is 15.078257\n",
      "epoch: 3 step: 199, loss is 3.8004525\n",
      "epoch: 3 step: 200, loss is 8.943662\n",
      "epoch: 3 step: 201, loss is 12.095364\n",
      "epoch: 3 step: 202, loss is 7.0641365\n",
      "epoch: 3 step: 203, loss is 14.842824\n",
      "epoch: 3 step: 204, loss is 7.708806\n",
      "epoch: 3 step: 205, loss is 8.222194\n",
      "epoch: 3 step: 206, loss is 10.447627\n",
      "epoch: 3 step: 207, loss is 13.507117\n",
      "epoch: 3 step: 208, loss is 15.489845\n",
      "epoch: 3 step: 209, loss is 8.031699\n",
      "epoch: 3 step: 210, loss is 8.591907\n",
      "epoch: 3 step: 211, loss is 11.864071\n",
      "epoch: 3 step: 212, loss is 12.0543585\n",
      "epoch: 3 step: 213, loss is 19.549475\n",
      "epoch: 3 step: 214, loss is 6.766399\n",
      "epoch: 3 step: 215, loss is 8.157355\n",
      "epoch: 3 step: 216, loss is 16.210495\n",
      "epoch: 3 step: 217, loss is 12.308489\n",
      "epoch: 3 step: 218, loss is 4.317367\n",
      "epoch: 3 step: 219, loss is 15.444658\n",
      "epoch: 3 step: 220, loss is 14.04983\n",
      "epoch: 3 step: 221, loss is 7.7229385\n",
      "epoch: 3 step: 222, loss is 6.3145714\n",
      "epoch: 3 step: 223, loss is 12.22589\n",
      "epoch: 3 step: 224, loss is 14.212875\n",
      "epoch: 3 step: 225, loss is 5.5329223\n",
      "epoch: 3 step: 226, loss is 4.68029\n",
      "epoch: 3 step: 227, loss is 8.454091\n",
      "epoch: 3 step: 228, loss is 17.012182\n",
      "epoch: 3 step: 229, loss is 12.586389\n",
      "epoch: 3 step: 230, loss is 11.180295\n",
      "epoch: 3 step: 231, loss is 9.299583\n",
      "epoch: 3 step: 232, loss is 11.515103\n",
      "epoch: 3 step: 233, loss is 7.7277017\n",
      "epoch: 3 step: 234, loss is 4.2447343\n",
      "epoch: 3 step: 235, loss is 9.053782\n",
      "epoch: 3 step: 236, loss is 5.730511\n",
      "epoch: 3 step: 237, loss is 14.744601\n",
      "epoch: 3 step: 238, loss is 5.662766\n",
      "epoch: 3 step: 239, loss is 5.059889\n",
      "epoch: 3 step: 240, loss is 6.8456607\n",
      "epoch: 3 step: 241, loss is 9.886804\n",
      "epoch: 3 step: 242, loss is 4.11713\n",
      "epoch: 3 step: 243, loss is 5.5154166\n",
      "epoch: 3 step: 244, loss is 3.542528\n",
      "epoch: 3 step: 245, loss is 7.7595096\n",
      "epoch: 3 step: 246, loss is 6.097282\n",
      "epoch: 3 step: 247, loss is 5.7261677\n",
      "epoch: 3 step: 248, loss is 2.6028702\n",
      "epoch: 3 step: 249, loss is 6.0603204\n",
      "epoch: 3 step: 250, loss is 7.755925\n",
      "epoch: 3 step: 251, loss is 7.668538\n",
      "epoch: 3 step: 252, loss is 6.292173\n",
      "epoch: 3 step: 253, loss is 10.9022255\n",
      "epoch: 3 step: 254, loss is 4.363937\n",
      "epoch: 3 step: 255, loss is 6.8618746\n",
      "epoch: 3 step: 256, loss is 6.3894386\n",
      "epoch: 3 step: 257, loss is 12.534091\n",
      "epoch: 3 step: 258, loss is 6.53219\n",
      "epoch: 3 step: 259, loss is 7.040326\n",
      "epoch: 3 step: 260, loss is 17.305487\n",
      "epoch: 3 step: 261, loss is 8.674139\n",
      "epoch: 3 step: 262, loss is 9.027857\n",
      "epoch: 3 step: 263, loss is 8.337772\n",
      "epoch: 3 step: 264, loss is 2.7621582\n",
      "epoch: 3 step: 265, loss is 14.380831\n",
      "epoch: 3 step: 266, loss is 10.283586\n",
      "epoch: 3 step: 267, loss is 13.8352585\n",
      "epoch: 3 step: 268, loss is 4.777553\n",
      "epoch: 3 step: 269, loss is 8.521775\n",
      "epoch: 3 step: 270, loss is 2.294319\n",
      "epoch: 3 step: 271, loss is 8.853145\n",
      "epoch: 3 step: 272, loss is 9.4030695\n",
      "epoch: 3 step: 273, loss is 9.127052\n",
      "epoch: 3 step: 274, loss is 12.889727\n",
      "epoch: 3 step: 275, loss is 2.5375266\n",
      "epoch: 3 step: 276, loss is 8.43682\n",
      "epoch: 3 step: 277, loss is 9.189303\n",
      "epoch: 3 step: 278, loss is 9.4796\n",
      "epoch: 3 step: 279, loss is 5.526674\n",
      "epoch: 3 step: 280, loss is 5.4248643\n",
      "epoch: 3 step: 281, loss is 11.679728\n",
      "epoch: 3 step: 282, loss is 9.076962\n",
      "epoch: 3 step: 283, loss is 7.0416245\n",
      "epoch: 3 step: 284, loss is 13.959948\n",
      "epoch: 3 step: 285, loss is 16.823256\n",
      "epoch: 3 step: 286, loss is 8.523455\n",
      "epoch: 3 step: 287, loss is 9.888581\n",
      "epoch: 3 step: 288, loss is 5.2833495\n",
      "epoch: 3 step: 289, loss is 6.734751\n",
      "epoch: 3 step: 290, loss is 12.886375\n",
      "epoch: 3 step: 291, loss is 8.421905\n",
      "epoch: 3 step: 292, loss is 11.43323\n",
      "epoch: 3 step: 293, loss is 4.6211596\n",
      "epoch: 3 step: 294, loss is 7.200006\n",
      "epoch: 3 step: 295, loss is 6.660711\n",
      "epoch: 3 step: 296, loss is 8.5496855\n",
      "epoch: 3 step: 297, loss is 6.457355\n",
      "epoch: 3 step: 298, loss is 6.649246\n",
      "epoch: 3 step: 299, loss is 7.6583915\n",
      "epoch: 3 step: 300, loss is 12.627669\n",
      "epoch: 3 step: 301, loss is 12.514285\n",
      "epoch: 3 step: 302, loss is 10.519188\n",
      "epoch: 3 step: 303, loss is 10.342556\n",
      "epoch: 3 step: 304, loss is 12.685178\n",
      "epoch: 3 step: 305, loss is 8.385439\n",
      "epoch: 3 step: 306, loss is 5.5591493\n",
      "epoch: 3 step: 307, loss is 7.975984\n",
      "epoch: 3 step: 308, loss is 5.823359\n",
      "epoch: 3 step: 309, loss is 9.8139105\n",
      "epoch: 3 step: 310, loss is 6.145803\n",
      "epoch: 3 step: 311, loss is 6.2630115\n",
      "epoch: 3 step: 312, loss is 11.048338\n",
      "epoch: 3 step: 313, loss is 7.979239\n",
      "epoch: 3 step: 314, loss is 11.66101\n",
      "epoch: 3 step: 315, loss is 14.647682\n",
      "epoch: 3 step: 316, loss is 7.6165605\n",
      "epoch: 3 step: 317, loss is 5.5190253\n",
      "epoch: 3 step: 318, loss is 2.8864295\n",
      "epoch: 3 step: 319, loss is 4.916617\n",
      "epoch: 3 step: 320, loss is 6.548047\n",
      "epoch: 3 step: 321, loss is 9.262445\n",
      "epoch: 3 step: 322, loss is 11.501224\n",
      "epoch: 3 step: 323, loss is 12.685979\n",
      "epoch: 3 step: 324, loss is 8.252933\n",
      "epoch: 3 step: 325, loss is 14.539726\n",
      "epoch: 3 step: 326, loss is 5.4665966\n",
      "epoch: 3 step: 327, loss is 5.227836\n",
      "epoch: 3 step: 328, loss is 7.1446824\n",
      "epoch: 3 step: 329, loss is 1.7398499\n",
      "epoch: 3 step: 330, loss is 10.756945\n",
      "epoch: 3 step: 331, loss is 9.303668\n",
      "epoch: 3 step: 332, loss is 7.2474976\n",
      "epoch: 3 step: 333, loss is 11.460282\n",
      "epoch: 3 step: 334, loss is 8.950673\n",
      "epoch: 3 step: 335, loss is 5.9494348\n",
      "epoch: 3 step: 336, loss is 7.9552536\n",
      "epoch: 3 step: 337, loss is 9.6694355\n",
      "epoch: 3 step: 338, loss is 3.2072227\n",
      "epoch: 3 step: 339, loss is 8.702727\n",
      "epoch: 3 step: 340, loss is 11.835588\n",
      "epoch: 3 step: 341, loss is 9.234789\n",
      "epoch: 3 step: 342, loss is 1.7095547\n",
      "epoch: 3 step: 343, loss is 4.4285936\n",
      "epoch: 3 step: 344, loss is 4.8690267\n",
      "epoch: 3 step: 345, loss is 6.0651603\n",
      "epoch: 3 step: 346, loss is 11.606653\n",
      "epoch: 3 step: 347, loss is 14.800946\n",
      "epoch: 3 step: 348, loss is 4.9116244\n",
      "epoch: 3 step: 349, loss is 14.010162\n",
      "epoch: 3 step: 350, loss is 8.38638\n",
      "epoch: 3 step: 351, loss is 5.9482946\n",
      "epoch: 3 step: 352, loss is 8.202174\n",
      "epoch: 3 step: 353, loss is 5.358973\n",
      "epoch: 3 step: 354, loss is 6.0181065\n",
      "epoch: 3 step: 355, loss is 15.355827\n",
      "epoch: 3 step: 356, loss is 8.254792\n",
      "epoch: 3 step: 357, loss is 9.294754\n",
      "epoch: 3 step: 358, loss is 1.4971765\n",
      "epoch: 3 step: 359, loss is 19.25026\n",
      "epoch: 3 step: 360, loss is 10.0901375\n",
      "epoch: 3 step: 361, loss is 14.025174\n",
      "epoch: 3 step: 362, loss is 7.563031\n",
      "epoch: 3 step: 363, loss is 8.445477\n",
      "epoch: 3 step: 364, loss is 7.2591414\n",
      "epoch: 3 step: 365, loss is 3.5900161\n",
      "epoch: 3 step: 366, loss is 12.366282\n",
      "epoch: 3 step: 367, loss is 15.282715\n",
      "epoch: 3 step: 368, loss is 9.450681\n",
      "epoch: 3 step: 369, loss is 7.346142\n",
      "epoch: 3 step: 370, loss is 12.328713\n",
      "epoch: 3 step: 371, loss is 9.652606\n",
      "epoch: 3 step: 372, loss is 18.507063\n",
      "epoch: 3 step: 373, loss is 17.365095\n",
      "epoch: 3 step: 374, loss is 10.517929\n",
      "epoch: 3 step: 375, loss is 6.246998\n",
      "epoch: 3 step: 376, loss is 4.0740523\n",
      "epoch: 3 step: 377, loss is 5.074087\n",
      "epoch: 3 step: 378, loss is 10.842862\n",
      "epoch: 3 step: 379, loss is 12.703062\n",
      "epoch: 3 step: 380, loss is 8.071118\n",
      "epoch: 3 step: 381, loss is 11.336051\n",
      "epoch: 3 step: 382, loss is 10.191779\n",
      "epoch: 3 step: 383, loss is 13.273868\n",
      "epoch: 3 step: 384, loss is 7.1373506\n",
      "epoch: 3 step: 385, loss is 9.659966\n",
      "epoch: 3 step: 386, loss is 7.5409546\n",
      "epoch: 3 step: 387, loss is 7.9206767\n",
      "epoch: 3 step: 388, loss is 7.165996\n",
      "epoch: 3 step: 389, loss is 4.672729\n",
      "epoch: 3 step: 390, loss is 3.9680245\n",
      "epoch: 3 step: 391, loss is 8.9942875\n",
      "epoch: 3 step: 392, loss is 5.0241065\n",
      "epoch: 3 step: 393, loss is 6.1589537\n",
      "epoch: 3 step: 394, loss is 3.548375\n",
      "epoch: 3 step: 395, loss is 6.6165423\n",
      "epoch: 3 step: 396, loss is 4.777743\n",
      "epoch: 3 step: 397, loss is 3.6817207\n",
      "epoch: 3 step: 398, loss is 5.818244\n",
      "epoch: 3 step: 399, loss is 6.7248154\n",
      "epoch: 3 step: 400, loss is 10.864609\n",
      "Train epoch time: 1690693.724 ms, per step time: 4226.734 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:28:27,000 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 10:28:27,002 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:28:30,512 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.3993438740760541 T+60 min: 0.16725303802177002 T+120 min: 0.0959103616970071\n",
      "2024-01-31 10:28:30,583 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 step: 1, loss is 3.676213\n",
      "epoch: 4 step: 2, loss is 6.1458254\n",
      "epoch: 4 step: 3, loss is 3.8185475\n",
      "epoch: 4 step: 4, loss is 6.627117\n",
      "epoch: 4 step: 5, loss is 6.9782486\n",
      "epoch: 4 step: 6, loss is 6.811868\n",
      "epoch: 4 step: 7, loss is 6.6884317\n",
      "epoch: 4 step: 8, loss is 7.3477755\n",
      "epoch: 4 step: 9, loss is 5.200476\n",
      "epoch: 4 step: 10, loss is 12.155771\n",
      "epoch: 4 step: 11, loss is 11.58068\n",
      "epoch: 4 step: 12, loss is 5.4448733\n",
      "epoch: 4 step: 13, loss is 10.812689\n",
      "epoch: 4 step: 14, loss is 12.388344\n",
      "epoch: 4 step: 15, loss is 5.3166175\n",
      "epoch: 4 step: 16, loss is 7.333459\n",
      "epoch: 4 step: 17, loss is 9.206997\n",
      "epoch: 4 step: 18, loss is 3.0782144\n",
      "epoch: 4 step: 19, loss is 5.3736815\n",
      "epoch: 4 step: 20, loss is 12.703902\n",
      "epoch: 4 step: 21, loss is 11.112024\n",
      "epoch: 4 step: 22, loss is 9.309543\n",
      "epoch: 4 step: 23, loss is 16.022741\n",
      "epoch: 4 step: 24, loss is 14.004642\n",
      "epoch: 4 step: 25, loss is 7.8977027\n",
      "epoch: 4 step: 26, loss is 2.6011\n",
      "epoch: 4 step: 27, loss is 4.357134\n",
      "epoch: 4 step: 28, loss is 10.371706\n",
      "epoch: 4 step: 29, loss is 7.375095\n",
      "epoch: 4 step: 30, loss is 7.5128417\n",
      "epoch: 4 step: 31, loss is 7.1043024\n",
      "epoch: 4 step: 32, loss is 6.3426604\n",
      "epoch: 4 step: 33, loss is 4.9876103\n",
      "epoch: 4 step: 34, loss is 5.7143807\n",
      "epoch: 4 step: 35, loss is 23.054178\n",
      "epoch: 4 step: 36, loss is 8.410891\n",
      "epoch: 4 step: 37, loss is 2.590817\n",
      "epoch: 4 step: 38, loss is 13.101186\n",
      "epoch: 4 step: 39, loss is 10.384282\n",
      "epoch: 4 step: 40, loss is 15.3681135\n",
      "epoch: 4 step: 41, loss is 3.6147048\n",
      "epoch: 4 step: 42, loss is 5.2593803\n",
      "epoch: 4 step: 43, loss is 6.159233\n",
      "epoch: 4 step: 44, loss is 14.822476\n",
      "epoch: 4 step: 45, loss is 9.855629\n",
      "epoch: 4 step: 46, loss is 2.013343\n",
      "epoch: 4 step: 47, loss is 5.9026637\n",
      "epoch: 4 step: 48, loss is 6.8767333\n",
      "epoch: 4 step: 49, loss is 11.081061\n",
      "epoch: 4 step: 50, loss is 8.160582\n",
      "epoch: 4 step: 51, loss is 7.699431\n",
      "epoch: 4 step: 52, loss is 9.594963\n",
      "epoch: 4 step: 53, loss is 5.246492\n",
      "epoch: 4 step: 54, loss is 9.238589\n",
      "epoch: 4 step: 55, loss is 12.828422\n",
      "epoch: 4 step: 56, loss is 3.5254242\n",
      "epoch: 4 step: 57, loss is 6.440239\n",
      "epoch: 4 step: 58, loss is 24.6152\n",
      "epoch: 4 step: 59, loss is 19.360817\n",
      "epoch: 4 step: 60, loss is 17.859755\n",
      "epoch: 4 step: 61, loss is 2.831498\n",
      "epoch: 4 step: 62, loss is 7.422414\n",
      "epoch: 4 step: 63, loss is 2.1120486\n",
      "epoch: 4 step: 64, loss is 14.740466\n",
      "epoch: 4 step: 65, loss is 17.857216\n",
      "epoch: 4 step: 66, loss is 10.600756\n",
      "epoch: 4 step: 67, loss is 4.2868834\n",
      "epoch: 4 step: 68, loss is 4.944597\n",
      "epoch: 4 step: 69, loss is 17.163239\n",
      "epoch: 4 step: 70, loss is 4.2221103\n",
      "epoch: 4 step: 71, loss is 10.387584\n",
      "epoch: 4 step: 72, loss is 9.282251\n",
      "epoch: 4 step: 73, loss is 9.199167\n",
      "epoch: 4 step: 74, loss is 6.785553\n",
      "epoch: 4 step: 75, loss is 14.524498\n",
      "epoch: 4 step: 76, loss is 11.74334\n",
      "epoch: 4 step: 77, loss is 6.27148\n",
      "epoch: 4 step: 78, loss is 10.0393305\n",
      "epoch: 4 step: 79, loss is 6.0050945\n",
      "epoch: 4 step: 80, loss is 10.229861\n",
      "epoch: 4 step: 81, loss is 11.787543\n",
      "epoch: 4 step: 82, loss is 4.7233157\n",
      "epoch: 4 step: 83, loss is 6.637301\n",
      "epoch: 4 step: 84, loss is 7.719641\n",
      "epoch: 4 step: 85, loss is 4.12404\n",
      "epoch: 4 step: 86, loss is 17.521246\n",
      "epoch: 4 step: 87, loss is 17.507727\n",
      "epoch: 4 step: 88, loss is 7.7966228\n",
      "epoch: 4 step: 89, loss is 11.815755\n",
      "epoch: 4 step: 90, loss is 9.160973\n",
      "epoch: 4 step: 91, loss is 7.896972\n",
      "epoch: 4 step: 92, loss is 15.70753\n",
      "epoch: 4 step: 93, loss is 6.5210557\n",
      "epoch: 4 step: 94, loss is 6.6325717\n",
      "epoch: 4 step: 95, loss is 11.314981\n",
      "epoch: 4 step: 96, loss is 5.9632664\n",
      "epoch: 4 step: 97, loss is 8.22915\n",
      "epoch: 4 step: 98, loss is 12.918307\n",
      "epoch: 4 step: 99, loss is 4.414189\n",
      "epoch: 4 step: 100, loss is 11.192988\n",
      "epoch: 4 step: 101, loss is 4.5086946\n",
      "epoch: 4 step: 102, loss is 7.328501\n",
      "epoch: 4 step: 103, loss is 4.1611032\n",
      "epoch: 4 step: 104, loss is 14.200145\n",
      "epoch: 4 step: 105, loss is 9.492152\n",
      "epoch: 4 step: 106, loss is 4.991545\n",
      "epoch: 4 step: 107, loss is 5.7460485\n",
      "epoch: 4 step: 108, loss is 6.549302\n",
      "epoch: 4 step: 109, loss is 7.381531\n",
      "epoch: 4 step: 110, loss is 14.290914\n",
      "epoch: 4 step: 111, loss is 6.1140246\n",
      "epoch: 4 step: 112, loss is 6.148664\n",
      "epoch: 4 step: 113, loss is 7.8371353\n",
      "epoch: 4 step: 114, loss is 11.339846\n",
      "epoch: 4 step: 115, loss is 7.606468\n",
      "epoch: 4 step: 116, loss is 7.9452233\n",
      "epoch: 4 step: 117, loss is 6.0036664\n",
      "epoch: 4 step: 118, loss is 10.471092\n",
      "epoch: 4 step: 119, loss is 8.270972\n",
      "epoch: 4 step: 120, loss is 10.283503\n",
      "epoch: 4 step: 121, loss is 12.491603\n",
      "epoch: 4 step: 122, loss is 8.554973\n",
      "epoch: 4 step: 123, loss is 13.23322\n",
      "epoch: 4 step: 124, loss is 13.755976\n",
      "epoch: 4 step: 125, loss is 5.5793405\n",
      "epoch: 4 step: 126, loss is 4.885715\n",
      "epoch: 4 step: 127, loss is 5.8129454\n",
      "epoch: 4 step: 128, loss is 4.6696568\n",
      "epoch: 4 step: 129, loss is 10.603922\n",
      "epoch: 4 step: 130, loss is 13.363962\n",
      "epoch: 4 step: 131, loss is 10.523055\n",
      "epoch: 4 step: 132, loss is 5.512915\n",
      "epoch: 4 step: 133, loss is 13.945411\n",
      "epoch: 4 step: 134, loss is 10.778062\n",
      "epoch: 4 step: 135, loss is 8.135046\n",
      "epoch: 4 step: 136, loss is 13.848558\n",
      "epoch: 4 step: 137, loss is 4.459125\n",
      "epoch: 4 step: 138, loss is 17.83843\n",
      "epoch: 4 step: 139, loss is 10.091002\n",
      "epoch: 4 step: 140, loss is 8.051492\n",
      "epoch: 4 step: 141, loss is 9.495379\n",
      "epoch: 4 step: 142, loss is 13.894305\n",
      "epoch: 4 step: 143, loss is 18.18354\n",
      "epoch: 4 step: 144, loss is 9.4925\n",
      "epoch: 4 step: 145, loss is 2.1044579\n",
      "epoch: 4 step: 146, loss is 9.420735\n",
      "epoch: 4 step: 147, loss is 10.54213\n",
      "epoch: 4 step: 148, loss is 14.165033\n",
      "epoch: 4 step: 149, loss is 5.624727\n",
      "epoch: 4 step: 150, loss is 5.493815\n",
      "epoch: 4 step: 151, loss is 10.743982\n",
      "epoch: 4 step: 152, loss is 3.0974233\n",
      "epoch: 4 step: 153, loss is 13.217432\n",
      "epoch: 4 step: 154, loss is 18.763859\n",
      "epoch: 4 step: 155, loss is 6.541345\n",
      "epoch: 4 step: 156, loss is 13.719568\n",
      "epoch: 4 step: 157, loss is 10.15655\n",
      "epoch: 4 step: 158, loss is 9.503666\n",
      "epoch: 4 step: 159, loss is 5.086662\n",
      "epoch: 4 step: 160, loss is 10.235117\n",
      "epoch: 4 step: 161, loss is 3.839955\n",
      "epoch: 4 step: 162, loss is 5.3130574\n",
      "epoch: 4 step: 163, loss is 6.0059114\n",
      "epoch: 4 step: 164, loss is 6.031484\n",
      "epoch: 4 step: 165, loss is 6.352182\n",
      "epoch: 4 step: 166, loss is 8.588338\n",
      "epoch: 4 step: 167, loss is 5.5310936\n",
      "epoch: 4 step: 168, loss is 10.252608\n",
      "epoch: 4 step: 169, loss is 2.4737244\n",
      "epoch: 4 step: 170, loss is 13.21802\n",
      "epoch: 4 step: 171, loss is 21.14692\n",
      "epoch: 4 step: 172, loss is 3.6985261\n",
      "epoch: 4 step: 173, loss is 6.6554766\n",
      "epoch: 4 step: 174, loss is 17.723349\n",
      "epoch: 4 step: 175, loss is 12.393163\n",
      "epoch: 4 step: 176, loss is 10.612553\n",
      "epoch: 4 step: 177, loss is 6.868173\n",
      "epoch: 4 step: 178, loss is 8.517087\n",
      "epoch: 4 step: 179, loss is 3.8414834\n",
      "epoch: 4 step: 180, loss is 11.700546\n",
      "epoch: 4 step: 181, loss is 3.4552376\n",
      "epoch: 4 step: 182, loss is 10.322907\n",
      "epoch: 4 step: 183, loss is 12.58256\n",
      "epoch: 4 step: 184, loss is 13.516565\n",
      "epoch: 4 step: 185, loss is 7.3142495\n",
      "epoch: 4 step: 186, loss is 8.524318\n",
      "epoch: 4 step: 187, loss is 15.444776\n",
      "epoch: 4 step: 188, loss is 10.324603\n",
      "epoch: 4 step: 189, loss is 2.3947856\n",
      "epoch: 4 step: 190, loss is 7.7508845\n",
      "epoch: 4 step: 191, loss is 6.8893623\n",
      "epoch: 4 step: 192, loss is 11.779426\n",
      "epoch: 4 step: 193, loss is 7.783684\n",
      "epoch: 4 step: 194, loss is 5.559186\n",
      "epoch: 4 step: 195, loss is 12.33841\n",
      "epoch: 4 step: 196, loss is 3.10277\n",
      "epoch: 4 step: 197, loss is 11.593186\n",
      "epoch: 4 step: 198, loss is 8.362334\n",
      "epoch: 4 step: 199, loss is 4.3570304\n",
      "epoch: 4 step: 200, loss is 9.075495\n",
      "epoch: 4 step: 201, loss is 3.0587902\n",
      "epoch: 4 step: 202, loss is 8.793173\n",
      "epoch: 4 step: 203, loss is 9.160072\n",
      "epoch: 4 step: 204, loss is 9.996168\n",
      "epoch: 4 step: 205, loss is 4.4661884\n",
      "epoch: 4 step: 206, loss is 12.07717\n",
      "epoch: 4 step: 207, loss is 9.499755\n",
      "epoch: 4 step: 208, loss is 7.9330635\n",
      "epoch: 4 step: 209, loss is 9.918828\n",
      "epoch: 4 step: 210, loss is 11.348759\n",
      "epoch: 4 step: 211, loss is 14.074396\n",
      "epoch: 4 step: 212, loss is 12.478229\n",
      "epoch: 4 step: 213, loss is 5.991877\n",
      "epoch: 4 step: 214, loss is 10.43513\n",
      "epoch: 4 step: 215, loss is 6.452308\n",
      "epoch: 4 step: 216, loss is 11.93827\n",
      "epoch: 4 step: 217, loss is 15.703278\n",
      "epoch: 4 step: 218, loss is 9.217426\n",
      "epoch: 4 step: 219, loss is 10.627667\n",
      "epoch: 4 step: 220, loss is 6.635383\n",
      "epoch: 4 step: 221, loss is 10.326945\n",
      "epoch: 4 step: 222, loss is 10.12241\n",
      "epoch: 4 step: 223, loss is 6.9434175\n",
      "epoch: 4 step: 224, loss is 17.091703\n",
      "epoch: 4 step: 225, loss is 11.446109\n",
      "epoch: 4 step: 226, loss is 9.434878\n",
      "epoch: 4 step: 227, loss is 10.74102\n",
      "epoch: 4 step: 228, loss is 8.835663\n",
      "epoch: 4 step: 229, loss is 15.326393\n",
      "epoch: 4 step: 230, loss is 10.077687\n",
      "epoch: 4 step: 231, loss is 11.318299\n",
      "epoch: 4 step: 232, loss is 5.291282\n",
      "epoch: 4 step: 233, loss is 10.002483\n",
      "epoch: 4 step: 234, loss is 2.5099685\n",
      "epoch: 4 step: 235, loss is 7.1666236\n",
      "epoch: 4 step: 236, loss is 13.010958\n",
      "epoch: 4 step: 237, loss is 8.899947\n",
      "epoch: 4 step: 238, loss is 8.618236\n",
      "epoch: 4 step: 239, loss is 8.771242\n",
      "epoch: 4 step: 240, loss is 14.431208\n",
      "epoch: 4 step: 241, loss is 10.483966\n",
      "epoch: 4 step: 242, loss is 5.6612062\n",
      "epoch: 4 step: 243, loss is 4.2863727\n",
      "epoch: 4 step: 244, loss is 3.0027046\n",
      "epoch: 4 step: 245, loss is 4.438354\n",
      "epoch: 4 step: 246, loss is 6.52958\n",
      "epoch: 4 step: 247, loss is 3.0307872\n",
      "epoch: 4 step: 248, loss is 9.385951\n",
      "epoch: 4 step: 249, loss is 8.068754\n",
      "epoch: 4 step: 250, loss is 11.730714\n",
      "epoch: 4 step: 251, loss is 2.195976\n",
      "epoch: 4 step: 252, loss is 9.411709\n",
      "epoch: 4 step: 253, loss is 19.269846\n",
      "epoch: 4 step: 254, loss is 8.46624\n",
      "epoch: 4 step: 255, loss is 11.38557\n",
      "epoch: 4 step: 256, loss is 11.96028\n",
      "epoch: 4 step: 257, loss is 4.257151\n",
      "epoch: 4 step: 258, loss is 7.614395\n",
      "epoch: 4 step: 259, loss is 3.947626\n",
      "epoch: 4 step: 260, loss is 17.896894\n",
      "epoch: 4 step: 261, loss is 7.5754213\n",
      "epoch: 4 step: 262, loss is 13.038469\n",
      "epoch: 4 step: 263, loss is 10.510594\n",
      "epoch: 4 step: 264, loss is 16.152983\n",
      "epoch: 4 step: 265, loss is 3.1057775\n",
      "epoch: 4 step: 266, loss is 11.86877\n",
      "epoch: 4 step: 267, loss is 14.262515\n",
      "epoch: 4 step: 268, loss is 18.942148\n",
      "epoch: 4 step: 269, loss is 13.272494\n",
      "epoch: 4 step: 270, loss is 2.750522\n",
      "epoch: 4 step: 271, loss is 9.770556\n",
      "epoch: 4 step: 272, loss is 14.897692\n",
      "epoch: 4 step: 273, loss is 5.36881\n",
      "epoch: 4 step: 274, loss is 5.537888\n",
      "epoch: 4 step: 275, loss is 3.613037\n",
      "epoch: 4 step: 276, loss is 4.3828106\n",
      "epoch: 4 step: 277, loss is 15.002818\n",
      "epoch: 4 step: 278, loss is 8.434581\n",
      "epoch: 4 step: 279, loss is 10.029888\n",
      "epoch: 4 step: 280, loss is 8.948175\n",
      "epoch: 4 step: 281, loss is 8.584951\n",
      "epoch: 4 step: 282, loss is 7.5333133\n",
      "epoch: 4 step: 283, loss is 6.416717\n",
      "epoch: 4 step: 284, loss is 8.40339\n",
      "epoch: 4 step: 285, loss is 9.977886\n",
      "epoch: 4 step: 286, loss is 7.452141\n",
      "epoch: 4 step: 287, loss is 15.941347\n",
      "epoch: 4 step: 288, loss is 17.368036\n",
      "epoch: 4 step: 289, loss is 5.150826\n",
      "epoch: 4 step: 290, loss is 9.903787\n",
      "epoch: 4 step: 291, loss is 11.5694475\n",
      "epoch: 4 step: 292, loss is 8.215062\n",
      "epoch: 4 step: 293, loss is 16.685926\n",
      "epoch: 4 step: 294, loss is 8.113766\n",
      "epoch: 4 step: 295, loss is 1.0069968\n",
      "epoch: 4 step: 296, loss is 5.023268\n",
      "epoch: 4 step: 297, loss is 6.1058106\n",
      "epoch: 4 step: 298, loss is 7.959131\n",
      "epoch: 4 step: 299, loss is 9.037157\n",
      "epoch: 4 step: 300, loss is 1.342965\n",
      "epoch: 4 step: 301, loss is 9.047324\n",
      "epoch: 4 step: 302, loss is 7.529364\n",
      "epoch: 4 step: 303, loss is 5.397156\n",
      "epoch: 4 step: 304, loss is 10.451912\n",
      "epoch: 4 step: 305, loss is 12.45346\n",
      "epoch: 4 step: 306, loss is 6.912183\n",
      "epoch: 4 step: 307, loss is 5.581401\n",
      "epoch: 4 step: 308, loss is 10.474632\n",
      "epoch: 4 step: 309, loss is 8.47137\n",
      "epoch: 4 step: 310, loss is 11.21259\n",
      "epoch: 4 step: 311, loss is 8.1547\n",
      "epoch: 4 step: 312, loss is 5.7790904\n",
      "epoch: 4 step: 313, loss is 9.919932\n",
      "epoch: 4 step: 314, loss is 5.7779565\n",
      "epoch: 4 step: 315, loss is 10.513469\n",
      "epoch: 4 step: 316, loss is 5.898944\n",
      "epoch: 4 step: 317, loss is 2.5560396\n",
      "epoch: 4 step: 318, loss is 2.6284294\n",
      "epoch: 4 step: 319, loss is 7.526073\n",
      "epoch: 4 step: 320, loss is 6.662506\n",
      "epoch: 4 step: 321, loss is 18.26149\n",
      "epoch: 4 step: 322, loss is 14.512451\n",
      "epoch: 4 step: 323, loss is 9.068983\n",
      "epoch: 4 step: 324, loss is 8.694118\n",
      "epoch: 4 step: 325, loss is 13.520667\n",
      "epoch: 4 step: 326, loss is 8.416137\n",
      "epoch: 4 step: 327, loss is 11.744475\n",
      "epoch: 4 step: 328, loss is 5.1127934\n",
      "epoch: 4 step: 329, loss is 8.381087\n",
      "epoch: 4 step: 330, loss is 19.403856\n",
      "epoch: 4 step: 331, loss is 8.697036\n",
      "epoch: 4 step: 332, loss is 5.1610827\n",
      "epoch: 4 step: 333, loss is 14.558612\n",
      "epoch: 4 step: 334, loss is 7.422728\n",
      "epoch: 4 step: 335, loss is 6.563929\n",
      "epoch: 4 step: 336, loss is 10.003052\n",
      "epoch: 4 step: 337, loss is 7.613647\n",
      "epoch: 4 step: 338, loss is 5.840883\n",
      "epoch: 4 step: 339, loss is 4.81624\n",
      "epoch: 4 step: 340, loss is 11.951698\n",
      "epoch: 4 step: 341, loss is 14.603927\n",
      "epoch: 4 step: 342, loss is 8.533343\n",
      "epoch: 4 step: 343, loss is 9.096772\n",
      "epoch: 4 step: 344, loss is 10.441264\n",
      "epoch: 4 step: 345, loss is 11.458043\n",
      "epoch: 4 step: 346, loss is 16.871424\n",
      "epoch: 4 step: 347, loss is 10.138394\n",
      "epoch: 4 step: 348, loss is 5.1306887\n",
      "epoch: 4 step: 349, loss is 5.430984\n",
      "epoch: 4 step: 350, loss is 7.727433\n",
      "epoch: 4 step: 351, loss is 10.3026495\n",
      "epoch: 4 step: 352, loss is 4.307813\n",
      "epoch: 4 step: 353, loss is 7.772714\n",
      "epoch: 4 step: 354, loss is 13.533885\n",
      "epoch: 4 step: 355, loss is 8.837291\n",
      "epoch: 4 step: 356, loss is 3.503616\n",
      "epoch: 4 step: 357, loss is 7.3944473\n",
      "epoch: 4 step: 358, loss is 5.5632763\n",
      "epoch: 4 step: 359, loss is 19.481575\n",
      "epoch: 4 step: 360, loss is 8.963536\n",
      "epoch: 4 step: 361, loss is 4.429003\n",
      "epoch: 4 step: 362, loss is 6.3598213\n",
      "epoch: 4 step: 363, loss is 3.8078454\n",
      "epoch: 4 step: 364, loss is 25.479204\n",
      "epoch: 4 step: 365, loss is 5.1794596\n",
      "epoch: 4 step: 366, loss is 2.2838864\n",
      "epoch: 4 step: 367, loss is 7.332088\n",
      "epoch: 4 step: 368, loss is 8.311957\n",
      "epoch: 4 step: 369, loss is 1.9376576\n",
      "epoch: 4 step: 370, loss is 14.94079\n",
      "epoch: 4 step: 371, loss is 9.807289\n",
      "epoch: 4 step: 372, loss is 8.627849\n",
      "epoch: 4 step: 373, loss is 12.0908575\n",
      "epoch: 4 step: 374, loss is 11.856814\n",
      "epoch: 4 step: 375, loss is 10.413968\n",
      "epoch: 4 step: 376, loss is 8.947225\n",
      "epoch: 4 step: 377, loss is 16.10538\n",
      "epoch: 4 step: 378, loss is 7.4808197\n",
      "epoch: 4 step: 379, loss is 14.064771\n",
      "epoch: 4 step: 380, loss is 2.9715505\n",
      "epoch: 4 step: 381, loss is 5.700367\n",
      "epoch: 4 step: 382, loss is 11.354943\n",
      "epoch: 4 step: 383, loss is 12.209341\n",
      "epoch: 4 step: 384, loss is 8.629803\n",
      "epoch: 4 step: 385, loss is 7.464757\n",
      "epoch: 4 step: 386, loss is 4.3745494\n",
      "epoch: 4 step: 387, loss is 7.487274\n",
      "epoch: 4 step: 388, loss is 7.3928223\n",
      "epoch: 4 step: 389, loss is 4.392405\n",
      "epoch: 4 step: 390, loss is 10.340281\n",
      "epoch: 4 step: 391, loss is 15.338669\n",
      "epoch: 4 step: 392, loss is 6.4617286\n",
      "epoch: 4 step: 393, loss is 4.133138\n",
      "epoch: 4 step: 394, loss is 6.8880706\n",
      "epoch: 4 step: 395, loss is 13.530011\n",
      "epoch: 4 step: 396, loss is 11.236566\n",
      "epoch: 4 step: 397, loss is 6.316319\n",
      "epoch: 4 step: 398, loss is 7.879731\n",
      "epoch: 4 step: 399, loss is 9.270348\n",
      "epoch: 4 step: 400, loss is 10.59611\n",
      "Train epoch time: 1687615.214 ms, per step time: 4219.038 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:56:38,214 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 10:56:38,216 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 10:56:41,586 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.4119070738020246 T+60 min: 0.16328413060990918 T+120 min: 0.10628156308461514\n",
      "2024-01-31 10:56:41,656 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 step: 1, loss is 10.631495\n",
      "epoch: 5 step: 2, loss is 8.387822\n",
      "epoch: 5 step: 3, loss is 13.710869\n",
      "epoch: 5 step: 4, loss is 5.4953156\n",
      "epoch: 5 step: 5, loss is 9.979673\n",
      "epoch: 5 step: 6, loss is 6.714036\n",
      "epoch: 5 step: 7, loss is 6.685842\n",
      "epoch: 5 step: 8, loss is 4.2601423\n",
      "epoch: 5 step: 9, loss is 2.9999993\n",
      "epoch: 5 step: 10, loss is 2.5337834\n",
      "epoch: 5 step: 11, loss is 8.508463\n",
      "epoch: 5 step: 12, loss is 8.42295\n",
      "epoch: 5 step: 13, loss is 8.569485\n",
      "epoch: 5 step: 14, loss is 5.3934393\n",
      "epoch: 5 step: 15, loss is 7.9034486\n",
      "epoch: 5 step: 16, loss is 12.259567\n",
      "epoch: 5 step: 17, loss is 8.008107\n",
      "epoch: 5 step: 18, loss is 7.291337\n",
      "epoch: 5 step: 19, loss is 4.7586455\n",
      "epoch: 5 step: 20, loss is 14.302854\n",
      "epoch: 5 step: 21, loss is 3.7846584\n",
      "epoch: 5 step: 22, loss is 12.408534\n",
      "epoch: 5 step: 23, loss is 14.33615\n",
      "epoch: 5 step: 24, loss is 5.025287\n",
      "epoch: 5 step: 25, loss is 8.458199\n",
      "epoch: 5 step: 26, loss is 15.693871\n",
      "epoch: 5 step: 27, loss is 22.327187\n",
      "epoch: 5 step: 28, loss is 17.936943\n",
      "epoch: 5 step: 29, loss is 7.3304977\n",
      "epoch: 5 step: 30, loss is 13.158412\n",
      "epoch: 5 step: 31, loss is 11.710132\n",
      "epoch: 5 step: 32, loss is 11.138893\n",
      "epoch: 5 step: 33, loss is 4.9665747\n",
      "epoch: 5 step: 34, loss is 12.0865965\n",
      "epoch: 5 step: 35, loss is 9.506385\n",
      "epoch: 5 step: 36, loss is 8.220237\n",
      "epoch: 5 step: 37, loss is 5.487331\n",
      "epoch: 5 step: 38, loss is 7.659286\n",
      "epoch: 5 step: 39, loss is 9.066897\n",
      "epoch: 5 step: 40, loss is 9.229425\n",
      "epoch: 5 step: 41, loss is 11.532029\n",
      "epoch: 5 step: 42, loss is 11.420379\n",
      "epoch: 5 step: 43, loss is 14.307367\n",
      "epoch: 5 step: 44, loss is 9.982462\n",
      "epoch: 5 step: 45, loss is 15.219409\n",
      "epoch: 5 step: 46, loss is 7.312978\n",
      "epoch: 5 step: 47, loss is 3.001394\n",
      "epoch: 5 step: 48, loss is 9.987114\n",
      "epoch: 5 step: 49, loss is 13.986376\n",
      "epoch: 5 step: 50, loss is 6.7663727\n",
      "epoch: 5 step: 51, loss is 7.3535867\n",
      "epoch: 5 step: 52, loss is 10.835659\n",
      "epoch: 5 step: 53, loss is 4.03575\n",
      "epoch: 5 step: 54, loss is 17.235962\n",
      "epoch: 5 step: 55, loss is 4.8890815\n",
      "epoch: 5 step: 56, loss is 6.193456\n",
      "epoch: 5 step: 57, loss is 12.351563\n",
      "epoch: 5 step: 58, loss is 12.991935\n",
      "epoch: 5 step: 59, loss is 11.512714\n",
      "epoch: 5 step: 60, loss is 3.1844296\n",
      "epoch: 5 step: 61, loss is 12.697228\n",
      "epoch: 5 step: 62, loss is 11.229603\n",
      "epoch: 5 step: 63, loss is 13.884003\n",
      "epoch: 5 step: 64, loss is 9.7715225\n",
      "epoch: 5 step: 65, loss is 3.5666463\n",
      "epoch: 5 step: 66, loss is 15.524452\n",
      "epoch: 5 step: 67, loss is 6.4682574\n",
      "epoch: 5 step: 68, loss is 10.731905\n",
      "epoch: 5 step: 69, loss is 11.709724\n",
      "epoch: 5 step: 70, loss is 11.286643\n",
      "epoch: 5 step: 71, loss is 3.969979\n",
      "epoch: 5 step: 72, loss is 13.019687\n",
      "epoch: 5 step: 73, loss is 13.722501\n",
      "epoch: 5 step: 74, loss is 16.456974\n",
      "epoch: 5 step: 75, loss is 10.625042\n",
      "epoch: 5 step: 76, loss is 7.1048675\n",
      "epoch: 5 step: 77, loss is 11.497929\n",
      "epoch: 5 step: 78, loss is 13.572883\n",
      "epoch: 5 step: 79, loss is 9.635073\n",
      "epoch: 5 step: 80, loss is 7.234012\n",
      "epoch: 5 step: 81, loss is 7.0485215\n",
      "epoch: 5 step: 82, loss is 11.622435\n",
      "epoch: 5 step: 83, loss is 12.5248995\n",
      "epoch: 5 step: 84, loss is 11.543509\n",
      "epoch: 5 step: 85, loss is 6.9962783\n",
      "epoch: 5 step: 86, loss is 13.758985\n",
      "epoch: 5 step: 87, loss is 7.901777\n",
      "epoch: 5 step: 88, loss is 5.801796\n",
      "epoch: 5 step: 89, loss is 12.534296\n",
      "epoch: 5 step: 90, loss is 5.2921734\n",
      "epoch: 5 step: 91, loss is 5.905163\n",
      "epoch: 5 step: 92, loss is 6.497083\n",
      "epoch: 5 step: 93, loss is 11.769897\n",
      "epoch: 5 step: 94, loss is 13.156825\n",
      "epoch: 5 step: 95, loss is 14.175391\n",
      "epoch: 5 step: 96, loss is 20.794384\n",
      "epoch: 5 step: 97, loss is 6.0201335\n",
      "epoch: 5 step: 98, loss is 9.175666\n",
      "epoch: 5 step: 99, loss is 7.9389544\n",
      "epoch: 5 step: 100, loss is 6.3970675\n",
      "epoch: 5 step: 101, loss is 5.013559\n",
      "epoch: 5 step: 102, loss is 6.2980266\n",
      "epoch: 5 step: 103, loss is 5.525966\n",
      "epoch: 5 step: 104, loss is 8.414882\n",
      "epoch: 5 step: 105, loss is 14.657737\n",
      "epoch: 5 step: 106, loss is 8.811191\n",
      "epoch: 5 step: 107, loss is 3.8203213\n",
      "epoch: 5 step: 108, loss is 8.20427\n",
      "epoch: 5 step: 109, loss is 6.8678017\n",
      "epoch: 5 step: 110, loss is 7.650745\n",
      "epoch: 5 step: 111, loss is 7.6307144\n",
      "epoch: 5 step: 112, loss is 7.781446\n",
      "epoch: 5 step: 113, loss is 8.235534\n",
      "epoch: 5 step: 114, loss is 5.4686313\n",
      "epoch: 5 step: 115, loss is 10.608706\n",
      "epoch: 5 step: 116, loss is 10.145556\n",
      "epoch: 5 step: 117, loss is 9.863107\n",
      "epoch: 5 step: 118, loss is 9.765075\n",
      "epoch: 5 step: 119, loss is 10.292937\n",
      "epoch: 5 step: 120, loss is 7.5957537\n",
      "epoch: 5 step: 121, loss is 8.942965\n",
      "epoch: 5 step: 122, loss is 4.448814\n",
      "epoch: 5 step: 123, loss is 12.249301\n",
      "epoch: 5 step: 124, loss is 6.5036263\n",
      "epoch: 5 step: 125, loss is 5.7959614\n",
      "epoch: 5 step: 126, loss is 5.2631245\n",
      "epoch: 5 step: 127, loss is 5.7066426\n",
      "epoch: 5 step: 128, loss is 9.65103\n",
      "epoch: 5 step: 129, loss is 8.33817\n",
      "epoch: 5 step: 130, loss is 4.682997\n",
      "epoch: 5 step: 131, loss is 12.688251\n",
      "epoch: 5 step: 132, loss is 8.972763\n",
      "epoch: 5 step: 133, loss is 5.926785\n",
      "epoch: 5 step: 134, loss is 14.200495\n",
      "epoch: 5 step: 135, loss is 7.9501543\n",
      "epoch: 5 step: 136, loss is 4.117658\n",
      "epoch: 5 step: 137, loss is 10.878026\n",
      "epoch: 5 step: 138, loss is 9.260337\n",
      "epoch: 5 step: 139, loss is 5.1848884\n",
      "epoch: 5 step: 140, loss is 8.278662\n",
      "epoch: 5 step: 141, loss is 6.7406807\n",
      "epoch: 5 step: 142, loss is 11.55156\n",
      "epoch: 5 step: 143, loss is 6.268988\n",
      "epoch: 5 step: 144, loss is 8.5409775\n",
      "epoch: 5 step: 145, loss is 9.443991\n",
      "epoch: 5 step: 146, loss is 5.869701\n",
      "epoch: 5 step: 147, loss is 6.10673\n",
      "epoch: 5 step: 148, loss is 10.007139\n",
      "epoch: 5 step: 149, loss is 20.440926\n",
      "epoch: 5 step: 150, loss is 11.340872\n",
      "epoch: 5 step: 151, loss is 7.81508\n",
      "epoch: 5 step: 152, loss is 21.721022\n",
      "epoch: 5 step: 153, loss is 5.7613144\n",
      "epoch: 5 step: 154, loss is 7.1448092\n",
      "epoch: 5 step: 155, loss is 10.04864\n",
      "epoch: 5 step: 156, loss is 12.34471\n",
      "epoch: 5 step: 157, loss is 11.677033\n",
      "epoch: 5 step: 158, loss is 7.871145\n",
      "epoch: 5 step: 159, loss is 6.426829\n",
      "epoch: 5 step: 160, loss is 23.551405\n",
      "epoch: 5 step: 161, loss is 9.514769\n",
      "epoch: 5 step: 162, loss is 9.29256\n",
      "epoch: 5 step: 163, loss is 8.428229\n",
      "epoch: 5 step: 164, loss is 12.387996\n",
      "epoch: 5 step: 165, loss is 19.549873\n",
      "epoch: 5 step: 166, loss is 3.0377066\n",
      "epoch: 5 step: 167, loss is 7.989761\n",
      "epoch: 5 step: 168, loss is 8.3322\n",
      "epoch: 5 step: 169, loss is 10.079988\n",
      "epoch: 5 step: 170, loss is 4.6191297\n",
      "epoch: 5 step: 171, loss is 3.8486416\n",
      "epoch: 5 step: 172, loss is 8.640483\n",
      "epoch: 5 step: 173, loss is 5.1511884\n",
      "epoch: 5 step: 174, loss is 4.039965\n",
      "epoch: 5 step: 175, loss is 2.8865755\n",
      "epoch: 5 step: 176, loss is 5.206315\n",
      "epoch: 5 step: 177, loss is 11.176275\n",
      "epoch: 5 step: 178, loss is 8.387357\n",
      "epoch: 5 step: 179, loss is 7.976318\n",
      "epoch: 5 step: 180, loss is 1.8052963\n",
      "epoch: 5 step: 181, loss is 5.5723796\n",
      "epoch: 5 step: 182, loss is 6.2282424\n",
      "epoch: 5 step: 183, loss is 6.1277995\n",
      "epoch: 5 step: 184, loss is 12.066929\n",
      "epoch: 5 step: 185, loss is 2.7362423\n",
      "epoch: 5 step: 186, loss is 5.7135406\n",
      "epoch: 5 step: 187, loss is 10.313344\n",
      "epoch: 5 step: 188, loss is 7.4719386\n",
      "epoch: 5 step: 189, loss is 13.5311985\n",
      "epoch: 5 step: 190, loss is 21.601717\n",
      "epoch: 5 step: 191, loss is 7.2960863\n",
      "epoch: 5 step: 192, loss is 12.421396\n",
      "epoch: 5 step: 193, loss is 8.647869\n",
      "epoch: 5 step: 194, loss is 10.662854\n",
      "epoch: 5 step: 195, loss is 11.814657\n",
      "epoch: 5 step: 196, loss is 16.368193\n",
      "epoch: 5 step: 197, loss is 12.368675\n",
      "epoch: 5 step: 198, loss is 3.7948174\n",
      "epoch: 5 step: 199, loss is 8.508166\n",
      "epoch: 5 step: 200, loss is 15.087338\n",
      "epoch: 5 step: 201, loss is 4.3888545\n",
      "epoch: 5 step: 202, loss is 7.3951087\n",
      "epoch: 5 step: 203, loss is 1.6048508\n",
      "epoch: 5 step: 204, loss is 10.2099\n",
      "epoch: 5 step: 205, loss is 9.446616\n",
      "epoch: 5 step: 206, loss is 9.398039\n",
      "epoch: 5 step: 207, loss is 14.820376\n",
      "epoch: 5 step: 208, loss is 10.117989\n",
      "epoch: 5 step: 209, loss is 18.408413\n",
      "epoch: 5 step: 210, loss is 11.205449\n",
      "epoch: 5 step: 211, loss is 7.9792185\n",
      "epoch: 5 step: 212, loss is 15.146637\n",
      "epoch: 5 step: 213, loss is 17.380625\n",
      "epoch: 5 step: 214, loss is 10.440936\n",
      "epoch: 5 step: 215, loss is 8.430682\n",
      "epoch: 5 step: 216, loss is 7.0475345\n",
      "epoch: 5 step: 217, loss is 8.43027\n",
      "epoch: 5 step: 218, loss is 8.34959\n",
      "epoch: 5 step: 219, loss is 3.492035\n",
      "epoch: 5 step: 220, loss is 7.284372\n",
      "epoch: 5 step: 221, loss is 11.793396\n",
      "epoch: 5 step: 222, loss is 12.567748\n",
      "epoch: 5 step: 223, loss is 7.5711007\n",
      "epoch: 5 step: 224, loss is 9.16282\n",
      "epoch: 5 step: 225, loss is 11.162758\n",
      "epoch: 5 step: 226, loss is 12.743927\n",
      "epoch: 5 step: 227, loss is 5.62576\n",
      "epoch: 5 step: 228, loss is 9.719904\n",
      "epoch: 5 step: 229, loss is 10.256751\n",
      "epoch: 5 step: 230, loss is 3.016227\n",
      "epoch: 5 step: 231, loss is 14.895472\n",
      "epoch: 5 step: 232, loss is 13.203323\n",
      "epoch: 5 step: 233, loss is 17.456888\n",
      "epoch: 5 step: 234, loss is 6.3501587\n",
      "epoch: 5 step: 235, loss is 5.698399\n",
      "epoch: 5 step: 236, loss is 7.669922\n",
      "epoch: 5 step: 237, loss is 15.038241\n",
      "epoch: 5 step: 238, loss is 1.2542189\n",
      "epoch: 5 step: 239, loss is 13.250785\n",
      "epoch: 5 step: 240, loss is 7.499948\n",
      "epoch: 5 step: 241, loss is 12.799797\n",
      "epoch: 5 step: 242, loss is 13.96305\n",
      "epoch: 5 step: 243, loss is 6.2045703\n",
      "epoch: 5 step: 244, loss is 9.261703\n",
      "epoch: 5 step: 245, loss is 13.137906\n",
      "epoch: 5 step: 246, loss is 5.6268735\n",
      "epoch: 5 step: 247, loss is 1.7798923\n",
      "epoch: 5 step: 248, loss is 4.302215\n",
      "epoch: 5 step: 249, loss is 17.192045\n",
      "epoch: 5 step: 250, loss is 5.874618\n",
      "epoch: 5 step: 251, loss is 14.248351\n",
      "epoch: 5 step: 252, loss is 8.042169\n",
      "epoch: 5 step: 253, loss is 2.707917\n",
      "epoch: 5 step: 254, loss is 8.272249\n",
      "epoch: 5 step: 255, loss is 6.518483\n",
      "epoch: 5 step: 256, loss is 3.7200456\n",
      "epoch: 5 step: 257, loss is 4.8931518\n",
      "epoch: 5 step: 258, loss is 9.775307\n",
      "epoch: 5 step: 259, loss is 5.4442167\n",
      "epoch: 5 step: 260, loss is 3.6159\n",
      "epoch: 5 step: 261, loss is 7.79292\n",
      "epoch: 5 step: 262, loss is 5.1962895\n",
      "epoch: 5 step: 263, loss is 10.529631\n",
      "epoch: 5 step: 264, loss is 2.2757719\n",
      "epoch: 5 step: 265, loss is 3.3210568\n",
      "epoch: 5 step: 266, loss is 7.5334296\n",
      "epoch: 5 step: 267, loss is 12.313452\n",
      "epoch: 5 step: 268, loss is 3.119498\n",
      "epoch: 5 step: 269, loss is 12.617778\n",
      "epoch: 5 step: 270, loss is 3.5836098\n",
      "epoch: 5 step: 271, loss is 10.1419935\n",
      "epoch: 5 step: 272, loss is 5.3244247\n",
      "epoch: 5 step: 273, loss is 14.506012\n",
      "epoch: 5 step: 274, loss is 9.065284\n",
      "epoch: 5 step: 275, loss is 7.1014833\n",
      "epoch: 5 step: 276, loss is 4.549492\n",
      "epoch: 5 step: 277, loss is 8.913678\n",
      "epoch: 5 step: 278, loss is 9.7163\n",
      "epoch: 5 step: 279, loss is 13.618973\n",
      "epoch: 5 step: 280, loss is 11.507527\n",
      "epoch: 5 step: 281, loss is 9.818935\n",
      "epoch: 5 step: 282, loss is 12.376059\n",
      "epoch: 5 step: 283, loss is 10.621506\n",
      "epoch: 5 step: 284, loss is 8.115376\n",
      "epoch: 5 step: 285, loss is 12.524125\n",
      "epoch: 5 step: 286, loss is 11.934016\n",
      "epoch: 5 step: 287, loss is 18.978323\n",
      "epoch: 5 step: 288, loss is 5.2660456\n",
      "epoch: 5 step: 289, loss is 5.11286\n",
      "epoch: 5 step: 290, loss is 6.446734\n",
      "epoch: 5 step: 291, loss is 4.856027\n",
      "epoch: 5 step: 292, loss is 9.004395\n",
      "epoch: 5 step: 293, loss is 9.165318\n",
      "epoch: 5 step: 294, loss is 8.424228\n",
      "epoch: 5 step: 295, loss is 6.32342\n",
      "epoch: 5 step: 296, loss is 5.8498797\n",
      "epoch: 5 step: 297, loss is 9.703807\n",
      "epoch: 5 step: 298, loss is 8.799947\n",
      "epoch: 5 step: 299, loss is 13.354802\n",
      "epoch: 5 step: 300, loss is 3.7787483\n",
      "epoch: 5 step: 301, loss is 8.219623\n",
      "epoch: 5 step: 302, loss is 8.6753435\n",
      "epoch: 5 step: 303, loss is 4.068034\n",
      "epoch: 5 step: 304, loss is 9.44405\n",
      "epoch: 5 step: 305, loss is 7.0157714\n",
      "epoch: 5 step: 306, loss is 9.052187\n",
      "epoch: 5 step: 307, loss is 7.4884334\n",
      "epoch: 5 step: 308, loss is 4.1641817\n",
      "epoch: 5 step: 309, loss is 5.55895\n",
      "epoch: 5 step: 310, loss is 5.693998\n",
      "epoch: 5 step: 311, loss is 6.2011943\n",
      "epoch: 5 step: 312, loss is 15.261699\n",
      "epoch: 5 step: 313, loss is 7.934396\n",
      "epoch: 5 step: 314, loss is 7.193046\n",
      "epoch: 5 step: 315, loss is 8.417132\n",
      "epoch: 5 step: 316, loss is 10.485958\n",
      "epoch: 5 step: 317, loss is 10.631312\n",
      "epoch: 5 step: 318, loss is 5.3854804\n",
      "epoch: 5 step: 319, loss is 4.3416204\n",
      "epoch: 5 step: 320, loss is 6.133428\n",
      "epoch: 5 step: 321, loss is 11.038399\n",
      "epoch: 5 step: 322, loss is 10.795598\n",
      "epoch: 5 step: 323, loss is 7.526134\n",
      "epoch: 5 step: 324, loss is 11.69377\n",
      "epoch: 5 step: 325, loss is 15.343103\n",
      "epoch: 5 step: 326, loss is 4.180414\n",
      "epoch: 5 step: 327, loss is 1.9247597\n",
      "epoch: 5 step: 328, loss is 2.562195\n",
      "epoch: 5 step: 329, loss is 9.181924\n",
      "epoch: 5 step: 330, loss is 3.468705\n",
      "epoch: 5 step: 331, loss is 7.6786075\n",
      "epoch: 5 step: 332, loss is 5.6610374\n",
      "epoch: 5 step: 333, loss is 1.8532251\n",
      "epoch: 5 step: 334, loss is 8.089282\n",
      "epoch: 5 step: 335, loss is 6.310372\n",
      "epoch: 5 step: 336, loss is 18.303768\n",
      "epoch: 5 step: 337, loss is 9.46337\n",
      "epoch: 5 step: 338, loss is 7.6183686\n",
      "epoch: 5 step: 339, loss is 6.296453\n",
      "epoch: 5 step: 340, loss is 12.350784\n",
      "epoch: 5 step: 341, loss is 11.734832\n",
      "epoch: 5 step: 342, loss is 7.058208\n",
      "epoch: 5 step: 343, loss is 14.124316\n",
      "epoch: 5 step: 344, loss is 14.062975\n",
      "epoch: 5 step: 345, loss is 11.118648\n",
      "epoch: 5 step: 346, loss is 14.661054\n",
      "epoch: 5 step: 347, loss is 18.050169\n",
      "epoch: 5 step: 348, loss is 10.386849\n",
      "epoch: 5 step: 349, loss is 17.819105\n",
      "epoch: 5 step: 350, loss is 9.1744585\n",
      "epoch: 5 step: 351, loss is 5.092346\n",
      "epoch: 5 step: 352, loss is 7.669666\n",
      "epoch: 5 step: 353, loss is 5.966626\n",
      "epoch: 5 step: 354, loss is 4.989822\n",
      "epoch: 5 step: 355, loss is 19.305593\n",
      "epoch: 5 step: 356, loss is 6.2722297\n",
      "epoch: 5 step: 357, loss is 17.060827\n",
      "epoch: 5 step: 358, loss is 12.174474\n",
      "epoch: 5 step: 359, loss is 15.584104\n",
      "epoch: 5 step: 360, loss is 2.7462678\n",
      "epoch: 5 step: 361, loss is 12.883452\n",
      "epoch: 5 step: 362, loss is 7.7744904\n",
      "epoch: 5 step: 363, loss is 4.8834033\n",
      "epoch: 5 step: 364, loss is 7.3042274\n",
      "epoch: 5 step: 365, loss is 8.934322\n",
      "epoch: 5 step: 366, loss is 1.8163586\n",
      "epoch: 5 step: 367, loss is 14.792688\n",
      "epoch: 5 step: 368, loss is 6.5286202\n",
      "epoch: 5 step: 369, loss is 10.896334\n",
      "epoch: 5 step: 370, loss is 5.369243\n",
      "epoch: 5 step: 371, loss is 6.807532\n",
      "epoch: 5 step: 372, loss is 13.986018\n",
      "epoch: 5 step: 373, loss is 6.5641456\n",
      "epoch: 5 step: 374, loss is 3.7626512\n",
      "epoch: 5 step: 375, loss is 5.4657474\n",
      "epoch: 5 step: 376, loss is 10.283322\n",
      "epoch: 5 step: 377, loss is 7.860248\n",
      "epoch: 5 step: 378, loss is 4.517271\n",
      "epoch: 5 step: 379, loss is 6.7254114\n",
      "epoch: 5 step: 380, loss is 12.755939\n",
      "epoch: 5 step: 381, loss is 9.718998\n",
      "epoch: 5 step: 382, loss is 6.1242285\n",
      "epoch: 5 step: 383, loss is 13.625025\n",
      "epoch: 5 step: 384, loss is 7.9344134\n",
      "epoch: 5 step: 385, loss is 8.680602\n",
      "epoch: 5 step: 386, loss is 7.1456604\n",
      "epoch: 5 step: 387, loss is 11.936925\n",
      "epoch: 5 step: 388, loss is 9.427384\n",
      "epoch: 5 step: 389, loss is 5.386045\n",
      "epoch: 5 step: 390, loss is 7.9937325\n",
      "epoch: 5 step: 391, loss is 4.4265428\n",
      "epoch: 5 step: 392, loss is 18.11367\n",
      "epoch: 5 step: 393, loss is 11.8551655\n",
      "epoch: 5 step: 394, loss is 3.7888184\n",
      "epoch: 5 step: 395, loss is 9.754228\n",
      "epoch: 5 step: 396, loss is 7.669852\n",
      "epoch: 5 step: 397, loss is 0.9869246\n",
      "epoch: 5 step: 398, loss is 14.705731\n",
      "epoch: 5 step: 399, loss is 10.468576\n",
      "epoch: 5 step: 400, loss is 6.882686\n",
      "Train epoch time: 1691109.624 ms, per step time: 4227.774 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 11:24:52,789 - forecast.py[line:191] - INFO: ================================Start Evaluation================================\n",
      "2024-01-31 11:24:52,790 - forecast.py[line:192] - INFO: The length of data is: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 11:24:56,256 - forecast.py[line:179] - INFO: CSI Neighborhood threshold 16 T+10 min: 0.4118216017414204 T+60 min: 0.15679251293172677 T+120 min: 0.10144497020636714\n",
      "2024-01-31 11:24:56,322 - forecast.py[line:211] - INFO: ================================End Evaluation================================\n"
     ]
    }
   ],
   "source": [
    "# loss_scale = ms.amp.DynamicLossScaleManager(init_loss_scale=2 ** 18, scale_factor=2, scale_window=1000)\n",
    "loss_scale = ms.train.loss_scale_manager.FixedLossScaleManager(loss_scale=2048)\n",
    "evo_loss_fn = EvolutionLoss(evo_model, config)\n",
    "trainer = EvolutionTrainer(config, evo_model, evo_loss_fn, logger, loss_scale)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluation and Visualization\n",
    "\n",
    "After training, we use the checkpoint for inference. The visualization of predictions, ground truth and their error is shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T02:47:16.480410600Z",
     "start_time": "2024-02-01T02:47:15.755875100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(693605:281472989458464,MainProcess):2024-02-01-10:47:42.791.427 [mindspore/train/serialization.py:1469] For 'load_param_into_net', remove parameter prefix name: model., continue to load.\n"
     ]
    }
   ],
   "source": [
    "config[\"data\"][\"batch_size\"] = 1\n",
    "config[\"summary\"][\"visual\"] = True\n",
    "params = load_checkpoint('./summary/ckpt/evolution_1-15_380.ckpt')\n",
    "evo_model.set_train(False)\n",
    "load_param_into_net(evo_model, params)\n",
    "evo_inference = EvolutionPredictor(config, evo_model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T02:47:23.394983200Z",
     "start_time": "2024-02-01T02:47:23.379025Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_params = config.get(\"data\")\n",
    "test_dataset_generator = RadarData(data_params, run_mode='test', module_name=\"evolution\")\n",
    "test_dataset = NowcastDataset(test_dataset_generator,\n",
    "                              module_name=\"evolution\",\n",
    "                              distribute=train_params.get('distribute', False),\n",
    "                              num_workers=data_params.get('num_workers', 1),\n",
    "                              shuffle=False)\n",
    "test_dataset = test_dataset.create_dataset(data_params.get('batch_size', 1))\n",
    "# data = next(test_dataset.create_dict_iterator())\n",
    "steps = 1\n",
    "for d in test_dataset.create_dict_iterator():\n",
    "    if steps == 6:\n",
    "        data = d\n",
    "        break\n",
    "    steps += 1\n",
    "inputs = data['inputs']\n",
    "pred = evo_inference.forecast(inputs)\n",
    "labels = inputs[:, data_params.get(\"t_in\"):]\n",
    "plt_idx = [x // data_params.get(\"data_frequency\") - 1 for x in data_params.get(\"key_info_timestep\", [10, 60, 120])]\n",
    "plt_img(field=pred[0].asnumpy(), label=labels[0].asnumpy(), idx=plt_idx, fig_name=\"./evolution_example.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T02:55:35.341415900Z",
     "start_time": "2024-02-01T02:55:34.131605Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config[\"model\"][\"module_name\"] = 'generation'\n",
    "config[\"data\"][\"batch_size\"] = 1\n",
    "config[\"summary\"][\"visual\"] = False\n",
    "config[\"summary\"][\"save_checkpoint_epochs\"] = 1\n",
    "logger = get_logger(config)\n",
    "train_params = config.get(\"train\")\n",
    "data_params = config.get(\"data\")\n",
    "summary_params = config.get(\"summary\")\n",
    "loss_scale = nn.DynamicLossScaleUpdateCell(loss_scale_value=2 ** 12, scale_factor=2, scale_window=1000)\n",
    "g_model, d_model = init_generation_model(config)\n",
    "g_loss_fn = GenerateLoss(g_model, d_model)\n",
    "d_loss_fn = DiscriminatorLoss(g_model, d_model)\n",
    "trainer = GenerationTrainer(config, g_model, d_model, g_loss_fn, d_loss_fn, logger, loss_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluation and Visualization\n",
    "\n",
    "After training, we use the checkpoint for inference. The visualization of predictions, ground truth and their error is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T05:51:51.977957700Z",
     "start_time": "2024-02-01T05:51:51.185154400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config[\"summary\"][\"visual\"] = True\n",
    "config[\"train\"][\"load_ckpt\"] = True\n",
    "config[\"summary\"][\"generate_ckpt_path\"] = './summary/ckpt/generator_15.ckpt'\n",
    "gen_inference = GenerationPredictor(config, g_model, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T05:51:57.747532100Z",
     "start_time": "2024-02-01T05:51:55.365145300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_params = config.get(\"data\")\n",
    "model_params = config.get(\"model\")\n",
    "test_dataset_generator = RadarData(data_params, run_mode='test', module_name=\"generation\")\n",
    "test_dataset = NowcastDataset(test_dataset_generator,\n",
    "                              module_name=\"generation\",\n",
    "                              distribute=train_params.get('distribute', False),\n",
    "                              num_workers=data_params.get('num_workers', 1),\n",
    "                              shuffle=False)\n",
    "test_dataset = test_dataset.create_dataset(data_params.get('batch_size', 1))\n",
    "data = next(test_dataset.create_dict_iterator())\n",
    "inp, evo_result, labels = data.get(\"inputs\"), data.get(\"evo\"), data.get(\"labels\")\n",
    "noise_scale = data_params.get(\"noise_scale\", 32)\n",
    "threshold = summary_params.get(\"csin_threshold\", 16)\n",
    "batch_size = data_params.get(\"batch_size\", 1)\n",
    "w_size = data_params.get(\"w_size\", 512)\n",
    "h_size = data_params.get(\"h_size\", 512)\n",
    "ngf = model_params.get(\"ngf\", 32)\n",
    "noise = ms.tensor(ms.numpy.randn((batch_size, ngf, h_size // noise_scale, w_size // noise_scale)), inp.dtype)\n",
    "pred = gen_inference.generator(inp, evo_result, noise)\n",
    "plt_idx = [x // data_params.get(\"data_frequency\") - 1 for x in data_params.get(\"key_info_timestep\", [10, 60, 120])]\n",
    "plt_img(field=pred[0].asnumpy(), label=labels[0].asnumpy(), idx=plt_idx, fig_name=\"./generation_example.png\", evo=evo_result[0].asnumpy() * 128, plot_evo=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
