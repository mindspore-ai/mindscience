model:
  arch:
    type: T5ForConditionalGeneration
  model_config:
    attention_dropout_rate: 0.1
    batch_size: 8
    d_ff: 16384
    d_kv: 128
    do_sample: false
    embedding_dropout_prob: 0.1
    eos_token_id: 1
    has_relative_bias: true
    hidden_act: relu
    hidden_dropout_rate: 0.1
    hidden_size: 1024
    is_encoder_decoder: true
    layer_norm_epsilon: 1.0e-06
    length_penalty_weight: 1.0
    max_position_embeddings: 512
    num_heads: 32
    num_layers: 24
    offset: 0
    pad_token_id: 0
    post_layernorm_residual: false
    relative_attention_num_buckets: 32
    repetition_penalty: 1
    scale_output: true
    seq_length: 512
    max_decode_length: 512
    start_token_id: 0
    top_k: 1
    top_p: 0.95
    type: T5Config
    use_cache: False
    use_past: False
    vocab_size: 128

    initializer_factor: 0.7
    initializer_range: 0.02
    param_init_type: "float32"
    layernorm_compute_type: "float32"
    softmax_compute_type: "float32"
    compute_dtype: "float32"