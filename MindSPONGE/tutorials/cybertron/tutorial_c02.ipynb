{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021-2022 @ Shenzhen Bay Laboratory & Peking University & Huawei Technologies Co., Ltd\n",
    "\n",
    "This code is a part of Cybertron package.\n",
    "\n",
    "The Cybertron is open-source software based on the AI-framework:\n",
    "MindSpore (https://www.mindspore.cn/)\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "\n",
    "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "Cybertron tutorial 02: Setup for model and readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(10115:139887459878720,MainProcess):2022-08-10-17:07:27.294.144 [mindspore/run_check/_check_version.py:137] Can not found cuda libs, please confirm that the correct cuda version has been installed, you can refer to the installation guidelines: https://www.mindspore.cn/install\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from mindspore import nn\n",
    "from mindspore import context\n",
    "from mindspore import dataset as ds\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import LossMonitor\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\n",
    "from cybertron import Cybertron\n",
    "from cybertron import MolCT\n",
    "from cybertron import AtomwiseReadout\n",
    "from cybertron.train import WithLabelLossCell\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = sys.path[0] + '/dataset_qm9_origin_trainset_1024.npz'\n",
    "\n",
    "train_data = np.load(train_file)\n",
    "\n",
    "idx = [7]  # U0\n",
    "\n",
    "num_atom = int(train_data['num_atoms'])\n",
    "scale = train_data['scale'][idx]\n",
    "shift = train_data['shift'][idx]\n",
    "ref = train_data['type_ref'][:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = MolCT(\n",
    "    cutoff=1,\n",
    "    n_interaction=3,\n",
    "    dim_feature=128,\n",
    "    n_heads=8,\n",
    "    fixed_cycles=False,\n",
    "    activation='swish',\n",
    "    max_cycles=10,\n",
    "    length_unit='nm',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout = AtomwiseReadout(\n",
    "    mod, dim_output=1, scale=scale, shift=shift, type_ref=ref, energy_unit='kj/mol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Cybertron Engine, Ride-on!\n",
      "--------------------------------------------------------------------------------\n",
      "    Length unit: nm\n",
      "    Input unit scale: 1\n",
      "--------------------------------------------------------------------------------\n",
      "    Deep molecular model:  MolCT\n",
      "--------------------------------------------------------------------------------\n",
      "       Length unit: nm\n",
      "       Atom embedding size: 64\n",
      "       Cutoff distance: 1.0 nm\n",
      "       Radical basis function (RBF): LogGaussianBasis\n",
      "          Minimum distance: 0.04 nm\n",
      "          Maximum distance: 1.0 nm\n",
      "          Reference distance: 1.0 nm\n",
      "          Log Gaussian begin: -3.218876\n",
      "          Log Gaussian end: 0.006724119\n",
      "          Interval for log Gaussian: 0.0512\n",
      "          Sigma for log gaussian: 0.3\n",
      "          Number of basis functions: 64\n",
      "          Rescale the range of RBF to (-1,1).\n",
      "       Calculate distance: Yes\n",
      "       Calculate bond: No\n",
      "       Feature dimension: 128\n",
      "--------------------------------------------------------------------------------\n",
      "       Using 3 independent interaction layers:\n",
      "--------------------------------------------------------------------------------\n",
      "       0. Neural Interaction Unit\n",
      "          Feature dimension: 128\n",
      "          Activation function: Swish\n",
      "          Encoding distance: Yes\n",
      "          Encoding bond: No\n",
      "          Number of heads in multi-haed attention: 8\n",
      "          Use feed forward network: No\n",
      "          Adaptive computation time (ACT) with maximum cycles: 10\n",
      "          Cycle mode: Fixible\n",
      "          Threshold for ACT: 0.9\n",
      "--------------------------------------------------------------------------------\n",
      "       1. Neural Interaction Unit\n",
      "          Feature dimension: 128\n",
      "          Activation function: Swish\n",
      "          Encoding distance: Yes\n",
      "          Encoding bond: No\n",
      "          Number of heads in multi-haed attention: 8\n",
      "          Use feed forward network: No\n",
      "          Adaptive computation time (ACT) with maximum cycles: 10\n",
      "          Cycle mode: Fixible\n",
      "          Threshold for ACT: 0.9\n",
      "--------------------------------------------------------------------------------\n",
      "       2. Neural Interaction Unit\n",
      "          Feature dimension: 128\n",
      "          Activation function: Swish\n",
      "          Encoding distance: Yes\n",
      "          Encoding bond: No\n",
      "          Number of heads in multi-haed attention: 8\n",
      "          Use feed forward network: No\n",
      "          Adaptive computation time (ACT) with maximum cycles: 10\n",
      "          Cycle mode: Fixible\n",
      "          Threshold for ACT: 0.9\n",
      "--------------------------------------------------------------------------------\n",
      "    Readout network: AtomwiseReadout\n",
      "--------------------------------------------------------------------------------\n",
      "       Activation function: Swish\n",
      "       Decoder: HalveDecoder\n",
      "       Aggregator: TensorSummation\n",
      "       Representation dimension: 128\n",
      "       Readout dimension: 1\n",
      "       Scale: [18.248537]\n",
      "       Shift: [-409.42038]\n",
      "       Scaleshift mode: Atomwise\n",
      "       Reference value for atom types:\n",
      "          No.0:   [0.]\n",
      "          No.1:   [-1313.4669]\n",
      "          No.2:   [0.]\n",
      "          No.3:   [0.]\n",
      "          No.4:   [0.]\n",
      "          No.5:   [0.]\n",
      "          No.6:   [-99366.71]\n",
      "          No.7:   [-143309.94]\n",
      "          No.8:   [-197082.06]\n",
      "          No.9:   [-261811.55]\n",
      "       Output unit: kJ mol-1\n",
      "       Reduce axis: -2\n",
      "--------------------------------------------------------------------------------\n",
      "    Output dimension: 1\n",
      "    Output unit for Cybertron: kJ mol-1\n",
      "    Output unit scale: 1.0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "net = Cybertron(model=mod, readout=readout, dim_output=1,\n",
    "                num_atoms=num_atom, length_unit='nm', energy_unit='kj/mol')\n",
    "net.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model.atom_embedding.embedding_table (64, 128)\n",
      "1 model.dis_filter.linear.weight (128, 64)\n",
      "2 model.dis_filter.linear.bias (128,)\n",
      "3 model.dis_filter.residual.nonlinear.mlp.0.weight (128, 128)\n",
      "4 model.dis_filter.residual.nonlinear.mlp.0.bias (128,)\n",
      "5 model.dis_filter.residual.nonlinear.mlp.1.weight (128, 128)\n",
      "6 model.dis_filter.residual.nonlinear.mlp.1.bias (128,)\n",
      "7 model.interactions.0.positional_embedding.norm.gamma (128,)\n",
      "8 model.interactions.0.positional_embedding.norm.beta (128,)\n",
      "9 model.interactions.0.positional_embedding.x2q.weight (128, 128)\n",
      "10 model.interactions.0.positional_embedding.x2k.weight (128, 128)\n",
      "11 model.interactions.0.positional_embedding.x2v.weight (128, 128)\n",
      "12 model.interactions.0.multi_head_attention.output.weight (128, 128)\n",
      "13 model.interactions.0.pondering.dense.weight (1, 384)\n",
      "14 model.interactions.0.pondering.dense.bias (1,)\n",
      "15 model.interactions.1.positional_embedding.norm.gamma (128,)\n",
      "16 model.interactions.1.positional_embedding.norm.beta (128,)\n",
      "17 model.interactions.1.positional_embedding.x2q.weight (128, 128)\n",
      "18 model.interactions.1.positional_embedding.x2k.weight (128, 128)\n",
      "19 model.interactions.1.positional_embedding.x2v.weight (128, 128)\n",
      "20 model.interactions.1.multi_head_attention.output.weight (128, 128)\n",
      "21 model.interactions.1.pondering.dense.weight (1, 384)\n",
      "22 model.interactions.1.pondering.dense.bias (1,)\n",
      "23 model.interactions.2.positional_embedding.norm.gamma (128,)\n",
      "24 model.interactions.2.positional_embedding.norm.beta (128,)\n",
      "25 model.interactions.2.positional_embedding.x2q.weight (128, 128)\n",
      "26 model.interactions.2.positional_embedding.x2k.weight (128, 128)\n",
      "27 model.interactions.2.positional_embedding.x2v.weight (128, 128)\n",
      "28 model.interactions.2.multi_head_attention.output.weight (128, 128)\n",
      "29 model.interactions.2.pondering.dense.weight (1, 384)\n",
      "30 model.interactions.2.pondering.dense.bias (1,)\n",
      "31 readout.decoder.output.mlp.0.weight (64, 128)\n",
      "32 readout.decoder.output.mlp.0.bias (64,)\n",
      "33 readout.decoder.output.mlp.1.weight (1, 64)\n",
      "34 readout.decoder.output.mlp.1.bias (1,)\n",
      "Total parameters:  256388\n"
     ]
    }
   ],
   "source": [
    "tot_params = 0\n",
    "for i, param in enumerate(net.get_parameters()):\n",
    "    tot_params += param.size\n",
    "    print(i, param.name, param.shape)\n",
    "print('Total parameters: ', tot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WithLabelLossCell with input type: RZE\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 8\n",
    "repeat_time = 1\n",
    "batch_size = 32\n",
    "\n",
    "ds_train = ds.NumpySlicesDataset(\n",
    "    {'R': train_data['R'], 'Z': train_data['Z'], 'E': train_data['E'][:, idx]}, shuffle=True)\n",
    "ds_train = ds_train.batch(batch_size, drop_remainder=True)\n",
    "ds_train = ds_train.repeat(repeat_time)\n",
    "loss_network = WithLabelLossCell('RZE', net, nn.MAELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optim = nn.Adam(params=net.trainable_params(), learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(loss_network, optimizer=optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_cb = LossMonitor(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = 'Tutorial_C02'\n",
    "params_name = outdir + '_' + net.model_name\n",
    "config_ck = CheckpointConfig(\n",
    "    save_checkpoint_steps=32, keep_checkpoint_max=64, append_info=[net.hyper_param])\n",
    "ckpoint_cb = ModelCheckpoint(\n",
    "    prefix=params_name, directory=outdir, config=config_ck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training ...\n",
      "epoch: 1 step: 16, loss is 154.4375\n",
      "epoch: 1 step: 32, loss is 114.806640625\n",
      "epoch: 2 step: 16, loss is 84.23046875\n",
      "epoch: 2 step: 32, loss is 71.810546875\n",
      "epoch: 3 step: 16, loss is 143.591796875\n",
      "epoch: 3 step: 32, loss is 81.3046875\n",
      "epoch: 4 step: 16, loss is 104.359375\n",
      "epoch: 4 step: 32, loss is 56.529296875\n",
      "epoch: 5 step: 16, loss is 57.82421875\n",
      "epoch: 5 step: 32, loss is 85.54296875\n",
      "epoch: 6 step: 16, loss is 40.58984375\n",
      "epoch: 6 step: 32, loss is 37.1875\n",
      "epoch: 7 step: 16, loss is 52.048828125\n",
      "epoch: 7 step: 32, loss is 48.0390625\n",
      "epoch: 8 step: 16, loss is 40.001953125\n",
      "epoch: 8 step: 32, loss is 56.359375\n",
      "Training Fininshed!\n",
      "Training Time: 00:01:04\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training ...\")\n",
    "beg_time = time.time()\n",
    "model.train(n_epoch, ds_train, callbacks=[monitor_cb, ckpoint_cb], dataset_sink_mode=False)\n",
    "end_time = time.time()\n",
    "used_time = end_time - beg_time\n",
    "m, s = divmod(used_time, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print(\"Training Fininshed!\")\n",
    "print(\"Training Time: %02d:%02d:%02d\" % (h, m, s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('mindsponge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2496ecc683137a232cae2452fbbdd53dab340598b6e499c8995be760f3a431b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
