{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二维Taylor-Green涡流动\n",
    "\n",
    "## 环境安装\n",
    "\n",
    "本案例要求 **MindSpore >= 2.0.0** 版本以调用如下接口: *mindspore.jit, mindspore.jit_class, mindspore.data_sink*。具体请查看[MindSpore安装](https://www.mindspore.cn/install)。\n",
    "\n",
    "此外，你需要安装 **MindFlow >=0.1.0** 版本。如果当前环境还没有安装，请按照下列方式选择后端和版本进行安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "在流体力学中，Taylor-Green涡流动是一种不稳定的衰减的涡流，在二维周期性边界条件时存在精确解，物理启发的神经网络方法（Physics-informed Neural Networks），以下简称PINNs，通过使用逼近控制方程的损失函数以及简单的网络构型，为快速求解复杂流体问题提供了新的方法。本案例将基于PINNs方法实现二维Taylor-Green涡流动的仿真。\n",
    "\n",
    "## 2维不可压缩纳维-斯托克斯方程（Navier-Stokes equation）\n",
    "\n",
    "纳维-斯托克斯方程（Navier-Stokes equation），简称`N-S`方程，是流体力学领域的经典偏微分方程，在粘性不可压缩情况下，无量纲`N-S`方程的形式如下：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u} {\\partial t} + u \\frac{\\partial u}{\\partial x} + v \\frac{\\partial u}{\\partial y} = - \\frac{\\partial p}{\\partial x} + \\frac{1} {Re} (\\frac{\\partial^2u}{\\partial x^2} + \\frac{\\partial^2u}{\\partial y^2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial v} {\\partial t} + u \\frac{\\partial v}{\\partial x} + v \\frac{\\partial v}{\\partial y} = - \\frac{\\partial p}{\\partial y} + \\frac{1} {Re} (\\frac{\\partial^2v}{\\partial x^2} + \\frac{\\partial^2v}{\\partial y^2})\n",
    "$$\n",
    "\n",
    "其中，`Re`表示雷诺数。\n",
    "\n",
    "本案例利用PINNs方法学习位置和时间到相应流场物理量的映射，实现`N-S`方程的求解：\n",
    "\n",
    "$$\n",
    "(x, y, t) \\mapsto (u, v, p)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 技术路径\n",
    "\n",
    "MindFlow求解该问题的具体流程如下：\n",
    "\n",
    "1. 创建数据集。\n",
    "2. 构建模型。\n",
    "3. 自适应损失的多任务学习。\n",
    "4. 优化器。\n",
    "5. 问题建模。\n",
    "6. 模型训练。\n",
    "7. 模型推理及可视化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入所需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sympy\n",
    "import mindspore\n",
    "from mindspore import context, nn, ops, jit, set_seed\n",
    "from mindspore import numpy as mnp\n",
    "\n",
    "from mindflow.cell import MultiScaleFCSequential\n",
    "from mindflow.utils import load_yaml_config\n",
    "from mindflow.pde import NavierStokes, sympy_to_mindspore\n",
    "\n",
    "from src import create_training_dataset, create_test_dataset, calculate_l2_error, NavierStokes2D\n",
    "\n",
    "set_seed(123456)\n",
    "np.random.seed(123456)\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\", device_id=0, save_graphs=False)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "config = load_yaml_config('configs/taylor_green_2D.yaml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集\n",
    "\n",
    "训练数据集通过create_training_dataset函数导入，数据集分为区域内数据点、初始条件点、边界条件点,即['time_rect_domain_points', 'time_rect_IC_points', 'time_rect_BC_points']，均采用mindflow.geometry相应接口采样，内容在/src/dataset.py中的create_training_dataset函数中。\n",
    "\n",
    "测试数据集通过create_test_dataset函数导入。本案例使用 **J Kim, P Moin,Application of a fractional-step method to incompressible Navier-Stokes equations,Journal of Computational Physics,Volume 59, Issue 2,1985**中给出的精确解构建验证集。\n",
    "\n",
    "本案例考虑一个大小为$2\\pi \\times 2\\pi$的正方形区域在$ t \\in (0,2)$时段的aylor-Green涡流动仿真。该问题的精确解为：\n",
    "\n",
    "$$\n",
    "u(x,y,t) = -cos(x)sin(y)e^{-2t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "v(x,y,t) = sin(x)cos(y)e^{-2t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x,y,t) = -0.25(cos(2x)+cos(2y))e^{-4t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataset\n",
    "taylor_dataset = create_training_dataset(config)\n",
    "train_dataset = taylor_dataset.create_dataset(batch_size=config[\"data\"][\"train\"][\"batch_size\"],\n",
    "                                              shuffle=True,\n",
    "                                              prebatched_data=True,\n",
    "                                              drop_remainder=True)\n",
    "\n",
    "# create test dataset\n",
    "inputs, label = create_test_dataset(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型\n",
    "\n",
    "本示例使用一个简单的全连接网络，深度为6层，每层128个神经元，激活函数是tanh函数，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_min = np.array(config[\"geometry\"][\"coord_min\"] + [config[\"geometry\"][\"time_min\"]]).astype(np.float32)\n",
    "coord_max = np.array(config[\"geometry\"][\"coord_max\"] + [config[\"geometry\"][\"time_max\"]]).astype(np.float32)\n",
    "input_center = list(0.5 * (coord_max + coord_min))\n",
    "input_scale = list(2.0 / (coord_max - coord_min))\n",
    "\n",
    "model = MultiScaleFCSequential(in_channels=config[\"model\"][\"in_channels\"],\n",
    "                               out_channels=config[\"model\"][\"out_channels\"],\n",
    "                               layers=config[\"model\"][\"layers\"],\n",
    "                               neurons=config[\"model\"][\"neurons\"],\n",
    "                               residual=config[\"model\"][\"residual\"],\n",
    "                               act=config[\"model\"][\"activation\"],\n",
    "                               num_scales=1,\n",
    "                               input_scale=input_scale,\n",
    "                               input_center=input_center)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.trainable_params()\n",
    "optimizer = nn.Adam(params, learning_rate=config[\"optimizer\"][\"learning_rate\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NavierStokes2D\n",
    "\n",
    "下述NavierStokes2D将圆柱绕流问题同数据集关联起来，包含3个部分：控制方程，边界条件和初始条件。控制方程在mindflow.pde中实现，边界条件与初始条件也是根据上述论文中的解析解实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NavierStokes2D(NavierStokes):\n",
    "    def __init__(self, model, re=100, loss_fn=nn.MSELoss()):\n",
    "        super(NavierStokes2D, self).__init__(model, re=re, loss_fn=loss_fn)\n",
    "        self.ic_nodes = sympy_to_mindspore(self.ic(), self.in_vars, self.out_vars)\n",
    "        self.bc_nodes = sympy_to_mindspore(self.bc(), self.in_vars, self.out_vars)\n",
    "\n",
    "    def ic(self):\n",
    "        \"\"\"\n",
    "        Define initial condition equations based on sympy, abstract method.\n",
    "        \"\"\"\n",
    "        ic_u = self.u + sympy.cos(self.x) * sympy.sin(self.y)\n",
    "        ic_v = self.v - sympy.sin(self.x) * sympy.cos(self.y)\n",
    "        ic_p = self.p + 0.25 * (sympy.cos(2*self.x) + sympy.cos(2*self.y))\n",
    "        equations = {\"ic_u\": ic_u, \"ic_v\": ic_v, \"ic_p\": ic_p}\n",
    "        return equations\n",
    "\n",
    "    def bc(self):\n",
    "        \"\"\"\n",
    "        Define boundary condition equations based on sympy, abstract method.\n",
    "        \"\"\"\n",
    "        bc_u = self.u + sympy.cos(self.x) * sympy.sin(self.y) * sympy.exp(-2*self.t)\n",
    "        bc_v = self.v - sympy.sin(self.x) * sympy.cos(self.y) * sympy.exp(-2*self.t)\n",
    "        bc_p = self.p + 0.25 * (sympy.cos(2*self.x) + sympy.cos(2*self.y)) * sympy.exp(-4*self.t)\n",
    "        equations = {\"bc_u\": bc_u, \"bc_v\": bc_v, \"bc_p\": bc_p}\n",
    "        return equations\n",
    "\n",
    "    def get_loss(self, pde_data, ic_data, bc_data):\n",
    "        \"\"\"\n",
    "        Compute loss of 3 parts: governing equation, initial condition and boundary conditions.\n",
    "\n",
    "        Args:\n",
    "            pde_data (Tensor): the input data of governing equations.\n",
    "            ic_data (Tensor): the input data of initial condition.\n",
    "            bc_data (Tensor): the input data of boundary condition.\n",
    "        \"\"\"\n",
    "        pde_res = self.parse_node(self.pde_nodes, inputs=pde_data)\n",
    "        pde_residual = ops.Concat(1)(pde_res)\n",
    "        pde_loss = self.loss_fn(pde_residual, mnp.zeros_like(pde_residual))\n",
    "\n",
    "        ic_res = self.parse_node(self.ic_nodes, inputs=ic_data)\n",
    "        ic_residual = ops.Concat(1)(ic_res)\n",
    "        ic_loss = self.loss_fn(ic_residual, mnp.zeros_like(ic_residual))\n",
    "\n",
    "        bc_res = self.parse_node(self.bc_nodes, inputs=bc_data)\n",
    "        bc_residual = ops.Concat(1)(bc_res)\n",
    "        bc_loss = self.loss_fn(bc_residual, mnp.zeros_like(bc_residual))\n",
    "\n",
    "        return pde_loss + ic_loss + bc_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "使用MindSpore>= 2.0.0的版本，可以使用函数式编程范式训练神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    problem = NavierStokes2D(model, re=config[\"summary\"][\"Re\"])\n",
    "\n",
    "    if use_ascend:\n",
    "        from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "        loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "        auto_mixed_precision(model, 'O3')\n",
    "\n",
    "    def forward_fn(pde_data, ic_data, bc_data):\n",
    "        loss = problem.get_loss(pde_data, ic_data, bc_data)\n",
    "        if use_ascend:\n",
    "            loss = loss_scaler.scale(loss)\n",
    "        return loss\n",
    "\n",
    "    grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)\n",
    "\n",
    "    @jit\n",
    "    def train_step(pde_data, ic_data, bc_data):\n",
    "        loss, grads = grad_fn(pde_data, ic_data, bc_data)\n",
    "        if use_ascend:\n",
    "            loss = loss_scaler.unscale(loss)\n",
    "            is_finite = all_finite(grads)\n",
    "            if is_finite:\n",
    "                grads = loss_scaler.unscale(grads)\n",
    "                loss = ops.depend(loss, optimizer(grads))\n",
    "            loss_scaler.adjust(is_finite)\n",
    "        else:\n",
    "            loss = ops.depend(loss, optimizer(grads))\n",
    "        return loss\n",
    "\n",
    "    epochs = config[\"data\"][\"train\"][\"epochs\"]\n",
    "    steps_per_epochs = train_dataset.get_dataset_size()\n",
    "    sink_process = mindspore.data_sink(train_step, train_dataset, sink_size=1)\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        # train\n",
    "        time_beg = time.time()\n",
    "        model.set_train(True)\n",
    "        for _ in range(steps_per_epochs):\n",
    "            step_train_loss = sink_process()\n",
    "        print(f\"epoch: {epoch} train loss: {step_train_loss} epoch time: {(time.time() - time_beg) * 1000 :.3f} ms\")\n",
    "        model.set_train(False)\n",
    "\n",
    "        if epoch % config[\"summary\"][\"eval_interval_epochs\"] == 0:\n",
    "            calculate_l2_error(model, inputs, label, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "momentum_x: u(x, y, t)*Derivative(u(x, y, t), x) + v(x, y, t)*Derivative(u(x, y, t), y) + Derivative(p(x, y, t), x) + Derivative(u(x, y, t), t) - 1.0*Derivative(u(x, y, t), (x, 2)) - 1.0*Derivative(u(x, y, t), (y, 2))\n",
      "    Item numbers of current derivative formula nodes: 6\n",
      "momentum_y: u(x, y, t)*Derivative(v(x, y, t), x) + v(x, y, t)*Derivative(v(x, y, t), y) + Derivative(p(x, y, t), y) + Derivative(v(x, y, t), t) - 1.0*Derivative(v(x, y, t), (x, 2)) - 1.0*Derivative(v(x, y, t), (y, 2))\n",
      "    Item numbers of current derivative formula nodes: 6\n",
      "continuty: Derivative(u(x, y, t), x) + Derivative(v(x, y, t), y)\n",
      "    Item numbers of current derivative formula nodes: 2\n",
      "ic_u: u(x, y, t) + sin(y)*cos(x)\n",
      "    Item numbers of current derivative formula nodes: 2\n",
      "ic_v: v(x, y, t) - sin(x)*cos(y)\n",
      "    Item numbers of current derivative formula nodes: 2\n",
      "ic_p: p(x, y, t) + 0.25*cos(2*x) + 0.25*cos(2*y)\n",
      "    Item numbers of current derivative formula nodes: 3\n",
      "bc_u: u(x, y, t) + exp(-2*t)*sin(y)*cos(x)\n",
      "    Item numbers of current derivative formula nodes: 2\n",
      "bc_v: v(x, y, t) - exp(-2*t)*sin(x)*cos(y)\n",
      "    Item numbers of current derivative formula nodes: 2\n",
      "bc_p: p(x, y, t) + 0.25*exp(-4*t)*cos(2*x) + 0.25*exp(-4*t)*cos(2*y)\n",
      "    Item numbers of current derivative formula nodes: 3\n",
      "epoch: 20 train loss: 0.11818831 epoch time: 9838.472 ms\n",
      "    predict total time: 342.714786529541 ms\n",
      "    l2_error, U:  0.7095809547153462 , V:  0.7081305150496081 , P:  1.004580707024092 , Total:  0.7376210740866216\n",
      "==================================================================================================\n",
      "epoch: 40 train loss: 0.025397364 epoch time: 9853.950 ms\n",
      "    predict total time: 67.26336479187012 ms\n",
      "    l2_error, U:  0.09177234501446464 , V:  0.14504987645942635 , P:  1.0217915750380309 , Total:  0.3150453016208772\n",
      "==================================================================================================\n",
      "epoch: 60 train loss: 0.0049396083 epoch time: 10158.307 ms\n",
      "    predict total time: 121.54984474182129 ms\n",
      "    l2_error, U:  0.08648064925211238 , V:  0.07875554509736878 , P:  0.711385847511365 , Total:  0.2187113170206073\n",
      "==================================================================================================\n",
      "epoch: 80 train loss: 0.0018874758 epoch time: 10349.795 ms\n",
      "    predict total time: 85.42561531066895 ms\n",
      "    l2_error, U:  0.08687053366212526 , V:  0.10624717784645109 , P:  0.3269822261697911 , Total:  0.1319986181134018\n",
      "==================================================================================================\n",
      "......\n",
      "epoch: 460 train loss: 0.00015093417 epoch time: 9928.474 ms\n",
      "    predict total time: 81.79974555969238 ms\n",
      "    l2_error, U:  0.033782269766829076 , V:  0.025816595720090357 , P:  0.08782072926563861 , Total:  0.03824859644715835\n",
      "==================================================================================================\n",
      "epoch: 480 train loss: 6.400551e-05 epoch time: 9956.549 ms\n",
      "    predict total time: 104.77519035339355 ms\n",
      "    l2_error, U:  0.02242134127961232 , V:  0.021098481157660533 , P:  0.06210985820202502 , Total:  0.027418651376509482\n",
      "==================================================================================================\n",
      "epoch: 500 train loss: 8.7400025e-05 epoch time: 10215.720 ms\n",
      "    predict total time: 77.20041275024414 ms\n",
      "    l2_error, U:  0.021138056243295636 , V:  0.013343674071961624 , P:  0.045241559122240635 , Total:  0.02132725837819097\n",
      "==================================================================================================\n",
      "End-to-End total time: 5011.718255519867 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train()\n",
    "print(\"End-to-End total time: {} s\".format(time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练结果即可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import visual\n",
    "\n",
    "# visualization\n",
    "visual(model=model, epoch=config[\"data\"][\"train\"][\"epochs\"], input_data=inputs, label=label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Time_error](./images/TimeError_30000.png \"error after training\")\n",
    "\n",
    "因速度呈指数下降的趋势，随着时间推移，误差变大，但整体处于5%的误差范围内。下方图片展示了中间过程中各指标的情况。\n",
    "\n",
    "![mid_stage](./images/mid_stage.png \"mid stage status\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57ace93c29d9374277a79956c3f1b916d7d9a05468d906842f9921d0d494a29f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
