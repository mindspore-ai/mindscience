{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7a09e7-32fc-4059-9478-6c6fc6667f57",
   "metadata": {},
   "source": [
    "# ICNet 不变性约束发现偏微分方程\n",
    "\n",
    "## 环境安装\n",
    "\n",
    "本案例要求 MindSpore >= 2.0.0 版本以调用如下接口: mindspore.jit, mindspore.jit_class, mindspore.data_sink。具体请查看MindSpore安装。\n",
    "\n",
    "此外，你需要安装 MindFlow >=0.1.0 版本。如果当前环境还没有安装，请按照下列方式选择后端和版本进行安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a449343-731b-46bb-b8dd-f7a8c1ba8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fe4081-9d91-44c1-b7de-b50a7645e090",
   "metadata": {},
   "source": [
    "## 背景介绍\n",
    "\n",
    "由偏微分方程描述的物理规律广泛存在于自然环境之中，物理系统的计算与模拟依赖于准确的基本方程和模型，传统方法推导控制方程主要基于第一性原理，例如Navier-Stokes方程基于动量守恒，传统方法难点在于复杂动力学的模型与方程常常难以推导，例如多相流、神经科学以及生物科学等，在大数据时代，通过人工智能的方法从数据中挖掘控制方程成为一种新的研究思路。已有的数据驱动发现方程的方法依然存在一定的局限性，目前构建过完备库的候选项时缺乏指导原则，无法保证发现的方程满足基本的物理要求，同时在处理复杂多维系统时候选库过大，而难以发现出简约准确的方程。考虑到基本的物理要求（不变性，守恒性等）是很多物理问题出发的基石，因此有必要研究如何在发现方程中施加物理约束。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50540e43-3c8e-45f0-8e2b-78831ec89684",
   "metadata": {},
   "source": [
    "## 模型框架\n",
    "\n",
    "模型框架图如下所示:\n",
    "\n",
    "![ICNet](images/ICNet.png)\n",
    "\n",
    "图中：\n",
    "A. 嵌入不变性约束至发现偏微分方程框架中的推导过程示意图；\n",
    "B. 不变性约束发现偏微分方程的神经网络模块，利用神经网络自动微分求出构建不变性候选函数所需要的偏导数，损失函数包括数据损失Data loss，不变性损失Invariance loss以及增强稀疏性的正则化损失Regularization loss。\n",
    "\n",
    "## 准备环节\n",
    "\n",
    "实践前，确保已经正确安装合适版本的MindSpore。如果没有，可以通过：\n",
    "\n",
    "* [MindSpore安装页面](https://www.mindspore.cn/install) 安装MindSpore。\n",
    "\n",
    "## 数据集的准备\n",
    "\n",
    "数据集下载地址：[ICNet/dataset](https://download-mindspore.osinfra.cn/mindscience/mindflow/dataset/applications/research/ICNet/)。将数据集保存在`./dataset`路径下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23990483-d613-4c8b-aa7e-0a8b16a89b13",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "引入代码包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d17b8a-bde1-4ccd-9345-ccfaa2cd1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import mindspore as ms\n",
    "from mindspore import set_seed, context, nn\n",
    "from src.network import InvarianceConstrainedNN, InvarianceConstrainedNN_STRdige\n",
    "from src.datasets import read_training_data, print_pde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e1d64-580b-4ae9-a7f6-164b0ee0adf3",
   "metadata": {},
   "source": [
    "模型相关参数的设置以及训练模型的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84c0ff-d4cf-41dd-8afc-db8f234d2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_name', type=str, default='ICNet')\n",
    "parser.add_argument('--case', type=str, default='Kuramoto-Sivashinsky equation')\n",
    "parser.add_argument('--device', type=str, default='GPU')    #default='GPU' or 'Ascend'\n",
    "parser.add_argument('--device_id', type=str, default=3)\n",
    "parser.add_argument('--init_steps', type=str, default=0)\n",
    "parser.add_argument('--stop_steps', type=str, default=150)\n",
    "parser.add_argument('--time_steps', type=str, default=50)\n",
    "parser.add_argument('--load_params', type=str, default='True')\n",
    "parser.add_argument('--second_path', type=str, default='pretrain')\n",
    "parser.add_argument('--data_name', type=str, default='KS.mat')\n",
    "parser.add_argument('--description_ks', type=str, default=['uu_x', '1', 'u_x', 'u_xx', 'u_xxx', 'u_xxxx'])\n",
    "parser.add_argument('--network_size', type=int, default=[2] + 8*[40] + [1])\n",
    "parser.add_argument('--learning_rate', type=int, default=[0.001, 0.0005, 1.0e-04, 1.0e-05])\n",
    "parser.add_argument('--epochs', type=int, default=[30e4, 30e4, 1e4, 1e4])\n",
    "parser.add_argument('--BatchNo', type=int, default=1)\n",
    "parser.add_argument('--lam', type=float, default=1e-5)\n",
    "parser.add_argument('--d_tol', type=float, default=1.0)\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "model_name = args.model_name\n",
    "case = args.case\n",
    "device = args.device\n",
    "device_id = args.device_id\n",
    "network_size = args.network_size\n",
    "learning_rate = args.learning_rate\n",
    "epochs = args.epochs\n",
    "BatchNo = args.BatchNo\n",
    "load_params = args.load_params\n",
    "second_path = args.second_path\n",
    "description_ks = args.description_ks\n",
    "lam = args.lam\n",
    "d_tol = args.d_tol\n",
    "\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "if use_ascend:\n",
    "    msfloat_type = ms.float16\n",
    "else:\n",
    "    msfloat_type = ms.float32\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, save_graphs=False, device_target=device, device_id=device_id)\n",
    "\n",
    "X_u_train, u_train, X_f_train = read_training_data(args)\n",
    "\n",
    "model_pretrain = InvarianceConstrainedNN(X_u_train, u_train, X_f_train, network_size, BatchNo, use_ascend, msfloat_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387cb210-078e-41e1-b960-e432af9c8d5f",
   "metadata": {},
   "source": [
    "设置种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482e625a-262a-4f06-a4a7-834766ed6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "set_seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8c191-ea21-4055-9d32-dfae30c96a33",
   "metadata": {},
   "source": [
    "代码训练与输出结果部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1733f-6e6a-47ff-928f-be3a348e98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, niter, lr):\n",
    "    # Get the gradients function\n",
    "\n",
    "    params = model.dnn.trainable_params()\n",
    "    params.append(model.lambda_u)\n",
    "    params.append(model.lambda_uux)\n",
    "\n",
    "    optimizer_Adam = nn.Adam(params, learning_rate=lr)\n",
    "\n",
    "    grad_fn = ms.value_and_grad(model.loss_fn, None, optimizer_Adam.parameters, has_aux=True)\n",
    "\n",
    "    model.dnn.set_train()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, 1+niter):\n",
    "        (loss, loss_u, loss_f_u, loss_lambda_u), grads = grad_fn(model.x, model.t, model.x_f, model.t_f, model.u)\n",
    "\n",
    "        optimizer_Adam(grads)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('It: %d, Loss: %.3e, loss_u:  %.3e, loss_f:  %.3e, loss_lambda:  %.3e, Lambda_uux: %.3f, Lambda_uxx: %.3f, Lambda_uxxxx: %.3f, Time: %.2f'  %\\\n",
    "                    (epoch, loss.item(), loss_u.item(), loss_f_u.item(), loss_lambda_u.item(),\n",
    "                     model.lambda_uux.item(), model.lambda_u[2].item(), model.lambda_u[4].item(), elapsed))\n",
    "\n",
    "            initial_size = 5\n",
    "\n",
    "            loss_history_Adam_Pretrain = np.empty([0])\n",
    "            loss_u_history_Adam_Pretrain = np.empty([0])\n",
    "            loss_f_u_history_Adam_Pretrain = np.empty([0])\n",
    "            loss_lambda_u_history_Adam_Pretrain = np.empty([0])\n",
    "\n",
    "            lambda_u_history_Adam_Pretrain = np.zeros((initial_size, 1))\n",
    "            lambda_uux_history_Adam_Pretrain = np.zeros((1, 1))\n",
    "\n",
    "            loss_history_Adam_Pretrain = np.append(loss_history_Adam_Pretrain, loss.numpy())\n",
    "            lambda_u_history_Adam_Pretrain = np.append(lambda_u_history_Adam_Pretrain, model.lambda_u.numpy(), axis=1)\n",
    "            loss_u_history_Adam_Pretrain = np.append(loss_u_history_Adam_Pretrain, loss_u.numpy())\n",
    "            loss_f_u_history_Adam_Pretrain = np.append(loss_f_u_history_Adam_Pretrain, loss_f_u.numpy())\n",
    "            loss_lambda_u_history_Adam_Pretrain = np.append(loss_lambda_u_history_Adam_Pretrain, loss_lambda_u.numpy())\n",
    "\n",
    "            lambda_uux_new = np.array([model.lambda_uux.numpy()])\n",
    "            lambda_uux_history_Adam_Pretrain = np.append(lambda_uux_history_Adam_Pretrain, lambda_uux_new, axis=1)\n",
    "\n",
    "            start_time = time.time()\n",
    "    np.save(f'Loss-Coe/{second_path}/loss_history_Adam_Pretrain', loss_history_Adam_Pretrain)\n",
    "    np.save(f'Loss-Coe/{second_path}/loss_u_history_Adam_Pretrain', loss_u_history_Adam_Pretrain)\n",
    "    np.save(f'Loss-Coe/{second_path}/loss_f_u_history_Adam_Pretrain', loss_f_u_history_Adam_Pretrain)\n",
    "    np.save(f'Loss-Coe/{second_path}/loss_lambda_u_history_Adam_Pretrain', loss_lambda_u_history_Adam_Pretrain)\n",
    "\n",
    "    np.save(f'Loss-Coe/{second_path}/lambda_u_history_Adam_Pretrain', lambda_u_history_Adam_Pretrain)\n",
    "    np.save(f'Loss-Coe/{second_path}/lambda_uux_history_Adam_Pretrain', lambda_uux_history_Adam_Pretrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfedd05b-3d38-4156-b061-8278d232a7f9",
   "metadata": {},
   "source": [
    "运行训练与保存训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658395b-cade-408e-b999-585ba1ae73d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 1.059e+00, loss_u:  1.059e+00, loss_f:  2.203e-07, loss_lambda:  0.000e+00, Lambda_uux: -0.000, Lambda_uxx: -0.000, Lambda_uxxxx: -0.000, Time: 9.18\n",
      "It: 10, Loss: 1.045e+00, loss_u:  1.045e+00, loss_f:  4.615e-05, loss_lambda:  1.824e-09, Lambda_uux: 0.004, Lambda_uxx: 0.003, Lambda_uxxxx: -0.003, Time: 2.72\n",
      "It: 20, Loss: 1.040e+00, loss_u:  1.039e+00, loss_f:  1.004e-04, loss_lambda:  3.732e-09, Lambda_uux: 0.011, Lambda_uxx: 0.005, Lambda_uxxxx: 0.001, Time: 2.72\n",
      "It: 30, Loss: 1.034e+00, loss_u:  1.034e+00, loss_f:  2.701e-04, loss_lambda:  6.927e-09, Lambda_uux: 0.004, Lambda_uxx: -0.005, Lambda_uxxxx: 0.009, Time: 2.70\n",
      "It: 40, Loss: 1.029e+00, loss_u:  1.028e+00, loss_f:  6.826e-04, loss_lambda:  1.216e-08, Lambda_uux: -0.009, Lambda_uxx: -0.019, Lambda_uxxxx: 0.023, Time: 2.73\n",
      "It: 50, Loss: 1.022e+00, loss_u:  1.021e+00, loss_f:  1.178e-03, loss_lambda:  1.785e-08, Lambda_uux: -0.020, Lambda_uxx: -0.033, Lambda_uxxxx: 0.035, Time: 2.70\n",
      "It: 60, Loss: 1.017e+00, loss_u:  1.016e+00, loss_f:  1.510e-03, loss_lambda:  2.169e-08, Lambda_uux: -0.022, Lambda_uxx: -0.041, Lambda_uxxxx: 0.031, Time: 2.70\n",
      "It: 70, Loss: 1.011e+00, loss_u:  1.010e+00, loss_f:  1.533e-03, loss_lambda:  2.363e-08, Lambda_uux: -0.020, Lambda_uxx: -0.039, Lambda_uxxxx: 0.019, Time: 2.71\n",
      "It: 80, Loss: 1.005e+00, loss_u:  1.003e+00, loss_f:  1.808e-03, loss_lambda:  2.458e-08, Lambda_uux: -0.025, Lambda_uxx: -0.025, Lambda_uxxxx: 0.008, Time: 2.71\n",
      "It: 90, Loss: 1.002e+00, loss_u:  1.001e+00, loss_f:  1.830e-03, loss_lambda:  2.689e-08, Lambda_uux: -0.036, Lambda_uxx: -0.012, Lambda_uxxxx: 0.013, Time: 2.70\n",
      "It: 100, Loss: 9.948e-01, loss_u:  9.930e-01, loss_f:  1.814e-03, loss_lambda:  2.944e-08, Lambda_uux: -0.051, Lambda_uxx: -0.000, Lambda_uxxxx: 0.015, Time: 2.72\n",
      "It: 110, Loss: 9.889e-01, loss_u:  9.870e-01, loss_f:  1.827e-03, loss_lambda:  3.257e-08, Lambda_uux: -0.068, Lambda_uxx: 0.003, Lambda_uxxxx: 0.012, Time: 2.71\n",
      "It: 120, Loss: 9.842e-01, loss_u:  9.825e-01, loss_f:  1.755e-03, loss_lambda:  3.524e-08, Lambda_uux: -0.084, Lambda_uxx: -0.004, Lambda_uxxxx: 0.008, Time: 2.70\n",
      "It: 130, Loss: 9.779e-01, loss_u:  9.764e-01, loss_f:  1.576e-03, loss_lambda:  3.899e-08, Lambda_uux: -0.099, Lambda_uxx: -0.012, Lambda_uxxxx: 0.008, Time: 2.70\n",
      "It: 140, Loss: 9.749e-01, loss_u:  9.733e-01, loss_f:  1.547e-03, loss_lambda:  4.163e-08, Lambda_uux: -0.110, Lambda_uxx: -0.010, Lambda_uxxxx: 0.011, Time: 2.72\n",
      "It: 150, Loss: 9.759e-01, loss_u:  9.744e-01, loss_f:  1.534e-03, loss_lambda:  4.491e-08, Lambda_uux: -0.121, Lambda_uxx: -0.008, Lambda_uxxxx: 0.019, Time: 2.72\n",
      "It: 160, Loss: 9.755e-01, loss_u:  9.741e-01, loss_f:  1.461e-03, loss_lambda:  4.490e-08, Lambda_uux: -0.133, Lambda_uxx: -0.001, Lambda_uxxxx: 0.010, Time: 2.71\n",
      "It: 170, Loss: 9.721e-01, loss_u:  9.707e-01, loss_f:  1.486e-03, loss_lambda:  4.799e-08, Lambda_uux: -0.144, Lambda_uxx: -0.012, Lambda_uxxxx: 0.011, Time: 2.74\n",
      "It: 180, Loss: 9.721e-01, loss_u:  9.706e-01, loss_f:  1.440e-03, loss_lambda:  4.967e-08, Lambda_uux: -0.157, Lambda_uxx: -0.019, Lambda_uxxxx: 0.004, Time: 2.73\n",
      "It: 190, Loss: 9.735e-01, loss_u:  9.721e-01, loss_f:  1.418e-03, loss_lambda:  5.220e-08, Lambda_uux: -0.169, Lambda_uxx: -0.029, Lambda_uxxxx: 0.005, Time: 2.72\n",
      "It: 200, Loss: 9.713e-01, loss_u:  9.699e-01, loss_f:  1.337e-03, loss_lambda:  5.401e-08, Lambda_uux: -0.180, Lambda_uxx: -0.034, Lambda_uxxxx: 0.001, Time: 2.71\n",
      "It: 210, Loss: 9.706e-01, loss_u:  9.692e-01, loss_f:  1.425e-03, loss_lambda:  5.662e-08, Lambda_uux: -0.191, Lambda_uxx: -0.041, Lambda_uxxxx: -0.005, Time: 2.71\n",
      "It: 220, Loss: 9.686e-01, loss_u:  9.673e-01, loss_f:  1.375e-03, loss_lambda:  5.876e-08, Lambda_uux: -0.202, Lambda_uxx: -0.046, Lambda_uxxxx: -0.006, Time: 2.74\n",
      "It: 230, Loss: 9.677e-01, loss_u:  9.663e-01, loss_f:  1.388e-03, loss_lambda:  5.992e-08, Lambda_uux: -0.213, Lambda_uxx: -0.046, Lambda_uxxxx: 0.004, Time: 2.72\n",
      "It: 240, Loss: 9.676e-01, loss_u:  9.661e-01, loss_f:  1.486e-03, loss_lambda:  6.205e-08, Lambda_uux: -0.223, Lambda_uxx: -0.037, Lambda_uxxxx: 0.021, Time: 2.72\n",
      "It: 250, Loss: 9.684e-01, loss_u:  9.671e-01, loss_f:  1.229e-03, loss_lambda:  6.069e-08, Lambda_uux: -0.233, Lambda_uxx: -0.021, Lambda_uxxxx: 0.013, Time: 2.70\n",
      "It: 260, Loss: 9.647e-01, loss_u:  9.633e-01, loss_f:  1.416e-03, loss_lambda:  6.224e-08, Lambda_uux: -0.242, Lambda_uxx: -0.034, Lambda_uxxxx: 0.010, Time: 2.71\n",
      "It: 270, Loss: 9.621e-01, loss_u:  9.607e-01, loss_f:  1.396e-03, loss_lambda:  6.493e-08, Lambda_uux: -0.253, Lambda_uxx: -0.052, Lambda_uxxxx: 0.012, Time: 2.72\n",
      "It: 280, Loss: 9.598e-01, loss_u:  9.582e-01, loss_f:  1.606e-03, loss_lambda:  6.514e-08, Lambda_uux: -0.261, Lambda_uxx: -0.057, Lambda_uxxxx: 0.003, Time: 2.71\n",
      "It: 290, Loss: 9.581e-01, loss_u:  9.563e-01, loss_f:  1.801e-03, loss_lambda:  6.523e-08, Lambda_uux: -0.267, Lambda_uxx: -0.061, Lambda_uxxxx: -0.003, Time: 2.71\n",
      "It: 300, Loss: 9.566e-01, loss_u:  9.546e-01, loss_f:  1.953e-03, loss_lambda:  6.513e-08, Lambda_uux: -0.270, Lambda_uxx: -0.065, Lambda_uxxxx: -0.005, Time: 2.73\n",
      "It: 310, Loss: 9.619e-01, loss_u:  9.597e-01, loss_f:  2.203e-03, loss_lambda:  6.383e-08, Lambda_uux: -0.269, Lambda_uxx: -0.065, Lambda_uxxxx: -0.003, Time: 2.72\n",
      "It: 320, Loss: 9.561e-01, loss_u:  9.539e-01, loss_f:  2.218e-03, loss_lambda:  6.235e-08, Lambda_uux: -0.265, Lambda_uxx: -0.062, Lambda_uxxxx: -0.004, Time: 2.72\n",
      "It: 330, Loss: 9.534e-01, loss_u:  9.511e-01, loss_f:  2.237e-03, loss_lambda:  6.176e-08, Lambda_uux: -0.258, Lambda_uxx: -0.062, Lambda_uxxxx: -0.005, Time: 2.71\n",
      "It: 340, Loss: 9.550e-01, loss_u:  9.530e-01, loss_f:  1.951e-03, loss_lambda:  6.189e-08, Lambda_uux: -0.247, Lambda_uxx: -0.064, Lambda_uxxxx: -0.004, Time: 2.72\n",
      "It: 350, Loss: 9.509e-01, loss_u:  9.488e-01, loss_f:  2.093e-03, loss_lambda:  6.213e-08, Lambda_uux: -0.233, Lambda_uxx: -0.063, Lambda_uxxxx: -0.003, Time: 2.72\n",
      "It: 360, Loss: 9.492e-01, loss_u:  9.471e-01, loss_f:  2.096e-03, loss_lambda:  6.202e-08, Lambda_uux: -0.216, Lambda_uxx: -0.058, Lambda_uxxxx: -0.002, Time: 2.70\n",
      "It: 370, Loss: 9.456e-01, loss_u:  9.429e-01, loss_f:  2.712e-03, loss_lambda:  6.208e-08, Lambda_uux: -0.200, Lambda_uxx: -0.054, Lambda_uxxxx: -0.003, Time: 2.69\n",
      "It: 380, Loss: 9.416e-01, loss_u:  9.392e-01, loss_f:  2.438e-03, loss_lambda:  6.259e-08, Lambda_uux: -0.186, Lambda_uxx: -0.055, Lambda_uxxxx: -0.002, Time: 2.70\n",
      "It: 390, Loss: 9.524e-01, loss_u:  9.504e-01, loss_f:  1.969e-03, loss_lambda:  6.241e-08, Lambda_uux: -0.174, Lambda_uxx: -0.051, Lambda_uxxxx: -0.002, Time: 2.72\n",
      "It: 400, Loss: 9.411e-01, loss_u:  9.384e-01, loss_f:  2.686e-03, loss_lambda:  6.227e-08, Lambda_uux: -0.162, Lambda_uxx: -0.048, Lambda_uxxxx: -0.002, Time: 2.71\n",
      "It: 410, Loss: 9.402e-01, loss_u:  9.374e-01, loss_f:  2.822e-03, loss_lambda:  6.297e-08, Lambda_uux: -0.150, Lambda_uxx: -0.049, Lambda_uxxxx: -0.002, Time: 2.73\n",
      "It: 420, Loss: 9.366e-01, loss_u:  9.339e-01, loss_f:  2.694e-03, loss_lambda:  6.415e-08, Lambda_uux: -0.141, Lambda_uxx: -0.050, Lambda_uxxxx: -0.002, Time: 2.69\n",
      "It: 430, Loss: 9.362e-01, loss_u:  9.333e-01, loss_f:  2.821e-03, loss_lambda:  6.503e-08, Lambda_uux: -0.134, Lambda_uxx: -0.049, Lambda_uxxxx: -0.003, Time: 2.69\n",
      "It: 440, Loss: 9.325e-01, loss_u:  9.288e-01, loss_f:  3.690e-03, loss_lambda:  6.555e-08, Lambda_uux: -0.129, Lambda_uxx: -0.047, Lambda_uxxxx: -0.003, Time: 2.72\n",
      "It: 450, Loss: 9.346e-01, loss_u:  9.304e-01, loss_f:  4.119e-03, loss_lambda:  6.614e-08, Lambda_uux: -0.127, Lambda_uxx: -0.046, Lambda_uxxxx: -0.003, Time: 2.70\n",
      "It: 460, Loss: 9.408e-01, loss_u:  9.385e-01, loss_f:  2.311e-03, loss_lambda:  6.689e-08, Lambda_uux: -0.129, Lambda_uxx: -0.046, Lambda_uxxxx: -0.004, Time: 2.72\n",
      "It: 470, Loss: 9.487e-01, loss_u:  9.458e-01, loss_f:  2.874e-03, loss_lambda:  6.778e-08, Lambda_uux: -0.132, Lambda_uxx: -0.047, Lambda_uxxxx: -0.005, Time: 2.72\n",
      "It: 480, Loss: 9.364e-01, loss_u:  9.345e-01, loss_f:  1.819e-03, loss_lambda:  6.915e-08, Lambda_uux: -0.133, Lambda_uxx: -0.047, Lambda_uxxxx: -0.007, Time: 2.72\n",
      "It: 490, Loss: 9.298e-01, loss_u:  9.268e-01, loss_f:  3.022e-03, loss_lambda:  7.036e-08, Lambda_uux: -0.137, Lambda_uxx: -0.046, Lambda_uxxxx: -0.006, Time: 2.71\n",
      "It: 500, Loss: 9.227e-01, loss_u:  9.185e-01, loss_f:  4.195e-03, loss_lambda:  7.049e-08, Lambda_uux: -0.153, Lambda_uxx: -0.043, Lambda_uxxxx: -0.001, Time: 2.72\n",
      "It: 510, Loss: 9.152e-01, loss_u:  9.109e-01, loss_f:  4.319e-03, loss_lambda:  6.961e-08, Lambda_uux: -0.180, Lambda_uxx: -0.038, Lambda_uxxxx: -0.001, Time: 2.71\n",
      "It: 520, Loss: 9.371e-01, loss_u:  9.329e-01, loss_f:  4.194e-03, loss_lambda:  6.900e-08, Lambda_uux: -0.214, Lambda_uxx: -0.043, Lambda_uxxxx: -0.002, Time: 2.71\n",
      "It: 530, Loss: 9.078e-01, loss_u:  9.035e-01, loss_f:  4.278e-03, loss_lambda:  6.863e-08, Lambda_uux: -0.246, Lambda_uxx: -0.045, Lambda_uxxxx: -0.001, Time: 2.71\n",
      "It: 540, Loss: 9.105e-01, loss_u:  9.054e-01, loss_f:  5.100e-03, loss_lambda:  6.960e-08, Lambda_uux: -0.275, Lambda_uxx: -0.042, Lambda_uxxxx: -0.002, Time: 2.70\n",
      "It: 550, Loss: 9.005e-01, loss_u:  8.956e-01, loss_f:  4.898e-03, loss_lambda:  7.213e-08, Lambda_uux: -0.302, Lambda_uxx: -0.047, Lambda_uxxxx: -0.001, Time: 2.70\n",
      "It: 560, Loss: 9.124e-01, loss_u:  9.073e-01, loss_f:  5.051e-03, loss_lambda:  7.482e-08, Lambda_uux: -0.328, Lambda_uxx: -0.054, Lambda_uxxxx: -0.001, Time: 2.72\n",
      "It: 570, Loss: 9.070e-01, loss_u:  9.026e-01, loss_f:  4.311e-03, loss_lambda:  7.724e-08, Lambda_uux: -0.350, Lambda_uxx: -0.060, Lambda_uxxxx: -0.002, Time: 2.72\n",
      "It: 580, Loss: 8.993e-01, loss_u:  8.942e-01, loss_f:  5.032e-03, loss_lambda:  7.835e-08, Lambda_uux: -0.371, Lambda_uxx: -0.057, Lambda_uxxxx: -0.001, Time: 2.72\n",
      "It: 590, Loss: 8.963e-01, loss_u:  8.913e-01, loss_f:  5.062e-03, loss_lambda:  7.946e-08, Lambda_uux: -0.392, Lambda_uxx: -0.055, Lambda_uxxxx: -0.001, Time: 2.71\n",
      "It: 600, Loss: 8.942e-01, loss_u:  8.889e-01, loss_f:  5.303e-03, loss_lambda:  8.157e-08, Lambda_uux: -0.414, Lambda_uxx: -0.060, Lambda_uxxxx: -0.001, Time: 2.72\n",
      "It: 610, Loss: 9.091e-01, loss_u:  9.040e-01, loss_f:  5.119e-03, loss_lambda:  8.314e-08, Lambda_uux: -0.434, Lambda_uxx: -0.059, Lambda_uxxxx: -0.001, Time: 2.71\n",
      "It: 620, Loss: 8.914e-01, loss_u:  8.864e-01, loss_f:  4.988e-03, loss_lambda:  8.435e-08, Lambda_uux: -0.453, Lambda_uxx: -0.060, Lambda_uxxxx: -0.001, Time: 2.71\n",
      "It: 630, Loss: 8.900e-01, loss_u:  8.848e-01, loss_f:  5.195e-03, loss_lambda:  8.533e-08, Lambda_uux: -0.469, Lambda_uxx: -0.061, Lambda_uxxxx: -0.001, Time: 2.72\n",
      "It: 640, Loss: 8.898e-01, loss_u:  8.842e-01, loss_f:  5.603e-03, loss_lambda:  8.592e-08, Lambda_uux: -0.486, Lambda_uxx: -0.059, Lambda_uxxxx: -0.001, Time: 2.71\n",
      "It: 650, Loss: 8.925e-01, loss_u:  8.867e-01, loss_f:  5.759e-03, loss_lambda:  8.690e-08, Lambda_uux: -0.501, Lambda_uxx: -0.059, Lambda_uxxxx: -0.001, Time: 2.71\n",
      "It: 660, Loss: 8.884e-01, loss_u:  8.829e-01, loss_f:  5.522e-03, loss_lambda:  8.766e-08, Lambda_uux: -0.515, Lambda_uxx: -0.059, Lambda_uxxxx: -0.001, Time: 2.72\n",
      "It: 670, Loss: 8.842e-01, loss_u:  8.785e-01, loss_f:  5.737e-03, loss_lambda:  8.794e-08, Lambda_uux: -0.528, Lambda_uxx: -0.057, Lambda_uxxxx: -0.001, Time: 2.74\n",
      "It: 680, Loss: 8.909e-01, loss_u:  8.849e-01, loss_f:  6.057e-03, loss_lambda:  8.817e-08, Lambda_uux: -0.540, Lambda_uxx: -0.055, Lambda_uxxxx: -0.001, Time: 2.69\n",
      "It: 690, Loss: 8.858e-01, loss_u:  8.798e-01, loss_f:  6.055e-03, loss_lambda:  8.863e-08, Lambda_uux: -0.549, Lambda_uxx: -0.056, Lambda_uxxxx: -0.001, Time: 2.72\n"
     ]
    }
   ],
   "source": [
    "for epoch, lr in zip(epochs, learning_rate):\n",
    "    train(model_pretrain, int(epoch), lr)\n",
    "ms.save_checkpoint(model_pretrain.dnn, f'model/{second_path}/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9233f-3748-4481-9d91-0c6c4ff42d26",
   "metadata": {},
   "source": [
    "保存最后一次训练的可学习参数用于方程发现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba9195-6d20-46ef-8bb4-f77e00914aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_uux_value = model_pretrain.lambda_uux.numpy()\n",
    "lambda_u_value = model_pretrain.lambda_u.numpy()\n",
    "np.save(f'Loss-Coe/{second_path}/lambda_uux_value', lambda_uux_value)\n",
    "np.save(f'Loss-Coe/{second_path}/lambda_u_value', lambda_u_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f276c8-9b5a-4f01-a76e-90e4c5addff9",
   "metadata": {},
   "source": [
    "训练结束后直接进行方程发现可能会超出显存，因此需要根据计算机显存大小判断是否需要重新加载模型进行方程发现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b672fa0-3903-4ac7-9395-211895cfaeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_params:\n",
    "    lambda_u_value = np.load(f'Loss-Coe/{second_path}/lambda_u_value.npy')\n",
    "    lambda_uux_value = np.load(f'Loss-Coe/{second_path}/lambda_uux_value.npy')\n",
    "    model_ICCO = InvarianceConstrainedNN_STRdige(X_u_train, u_train, X_f_train, network_size, BatchNo, lambda_u_value, lambda_uux_value, load_params, second_path, msfloat_type)\n",
    "else:\n",
    "    model_ICCO = InvarianceConstrainedNN_STRdige(X_u_train, u_train, X_f_train, network_size, BatchNo, lambda_u_value, lambda_uux_value, load_params, second_path, msfloat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8887fa-9550-4873-a5cf-edd2a49b76ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_u_STRidge = model_ICCO.call_trainstridge(lam, d_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0acd9-8890-4bb9-bde1-77cf4e9b17f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_t = (0.973947)uu_x\n",
      "   (-0.967219)u_xx\n",
      "    + (-0.967183)u_xxxx\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "# GPU results\n",
    "print_pde(lambda_uux_value, lambda_u_STRidge, description_ks, ut='u_t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
