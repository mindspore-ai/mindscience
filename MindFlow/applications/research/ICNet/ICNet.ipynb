{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7a09e7-32fc-4059-9478-6c6fc6667f57",
   "metadata": {},
   "source": [
    "# ICNet: Invariance Constrained Discovery for Partial Differential Equations\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "This notebook requires **MindSpore version >= 2.0.0** to support new APIs including: *mindspore.jit, mindspore.jit_class, mindspore.data_sink*. Please check [MindSpore Installation](https://www.mindspore.cn/install/en) for details.\n",
    "\n",
    "In addition, **MindFlow version >=0.1.0** is also required. If it has not been installed in your environment, please select the right version and hardware, then install it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a449343-731b-46bb-b8dd-f7a8c1ba8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fe4081-9d91-44c1-b7de-b50a7645e090",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The physical laws described by partial differential equations are widely present in the natural environment. The calculation and simulation of physical systems rely on accurate basic equations and models. The traditional method of deriving control equations is mainly based on first principles, such as the Navier-Stokes equations based on momentum conservation. The difficulty of traditional methods lies in the fact that models and equations of complex dynamics are often difficult to derive, such as multiphase flow, neuroscience, and biological science. In the era of big data, mining control equations from data through artificial intelligence methods has become a new research idea. The existing data-driven method of discovering equations still has certain limitations. At present, there is a lack of guiding principles when constructing candidates for a complete library, and it is impossible to ensure that the discovered equations meet basic physical requirements. At the same time, when dealing with complex multidimensional systems, the candidate library is too large, and it is difficult to discover simple and accurate equations. Considering that basic physical requirements (invariance, conservation, etc.) are the cornerstones of many physical problems, it is necessary to study how to impose physical constraints in discovering equations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50540e43-3c8e-45f0-8e2b-78831ec89684",
   "metadata": {},
   "source": [
    "## Model framework\n",
    "\n",
    "The model framework is as shown in the following figure:\n",
    "\n",
    "![ICNet](images/ICNet.png)\n",
    "\n",
    "In the figure:\n",
    "A. Schematic diagram of the derivation process of embedding invariance constraints into the framework of partial differential equation discovery;\n",
    "B. The neural network module of partial differential equation discovery with invariance constraints uses neural network automatic differentiation to obtain the partial derivatives required to construct the invariance candidate function. The loss function includes data loss, invariance loss, and regularization loss for enhancing sparsity.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before practice, ensure that MindSpore of suitable version has been correctly installed. If not, you can run the following command:\n",
    "\n",
    "* [MindSpore installation page](https://www.mindspore.cn/install) Install MindSpore.\n",
    "\n",
    "## Datasets Preparation\n",
    "\n",
    "Dataset download link: [ICNet/dataset](https://download-mindspore.osinfra.cn/mindscience/mindflow/dataset/applications/research/ICNet/)ã€‚Save the dataset under path `./dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23990483-d613-4c8b-aa7e-0a8b16a89b13",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Import code packs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d17b8a-bde1-4ccd-9345-ccfaa2cd1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import mindspore as ms\n",
    "from mindspore import set_seed, context, nn\n",
    "from src.network import InvarianceConstrainedNN, InvarianceConstrainedNN_STRdige\n",
    "from src.datasets import read_training_data, print_pde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e1d64-580b-4ae9-a7f6-164b0ee0adf3",
   "metadata": {},
   "source": [
    "Setting of model-related parameters and definition of training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84c0ff-d4cf-41dd-8afc-db8f234d2108",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_name', type=str, default='ICNet')\n",
    "parser.add_argument('--case', type=str, default='Kuramoto-Sivashinsky equation')\n",
    "parser.add_argument('--device', type=str, default='GPU')    #default='GPU' or 'Ascend'\n",
    "parser.add_argument('--device_id', type=str, default=3)\n",
    "parser.add_argument('--init_steps', type=str, default=0)\n",
    "parser.add_argument('--stop_steps', type=str, default=150)\n",
    "parser.add_argument('--time_steps', type=str, default=50)\n",
    "parser.add_argument('--load_params', type=str, default='True')\n",
    "parser.add_argument('--second_path', type=str, default='pretrain')\n",
    "parser.add_argument('--data_name', type=str, default='KS.mat')\n",
    "parser.add_argument('--description_ks', type=str, default=['uu_x', '1', 'u_x', 'u_xx', 'u_xxx', 'u_xxxx'])\n",
    "parser.add_argument('--network_size', type=int, default=[2] + 8*[40] + [1])\n",
    "parser.add_argument('--learning_rate', type=int, default=[0.001, 0.0005, 1.0e-04, 1.0e-05])\n",
    "parser.add_argument('--epochs', type=int, default=[30e4, 30e4, 1e4, 1e4])\n",
    "parser.add_argument('--BatchNo', type=int, default=1)\n",
    "parser.add_argument('--lam', type=float, default=1e-5)\n",
    "parser.add_argument('--d_tol', type=float, default=1.0)\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "model_name = args.model_name\n",
    "case = args.case\n",
    "device = args.device\n",
    "device_id = args.device_id\n",
    "network_size = args.network_size\n",
    "learning_rate = args.learning_rate\n",
    "epochs = args.epochs\n",
    "BatchNo = args.BatchNo\n",
    "load_params = args.load_params\n",
    "second_path = args.second_path\n",
    "description_ks = args.description_ks\n",
    "lam = args.lam\n",
    "d_tol = args.d_tol\n",
    "\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "if use_ascend:\n",
    "    msfloat_type = ms.float16\n",
    "else:\n",
    "    msfloat_type = ms.float32\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, save_graphs=False, device_target=device, device_id=device_id)\n",
    "\n",
    "X_u_train, u_train, X_f_train = read_training_data(args)\n",
    "\n",
    "model_pretrain = InvarianceConstrainedNN(X_u_train, u_train, X_f_train, network_size, BatchNo, use_ascend, msfloat_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387cb210-078e-41e1-b960-e432af9c8d5f",
   "metadata": {},
   "source": [
    "Set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482e625a-262a-4f06-a4a7-834766ed6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123456)\n",
    "set_seed(123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f8c191-ea21-4055-9d32-dfae30c96a33",
   "metadata": {},
   "source": [
    "Code training and output results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1733f-6e6a-47ff-928f-be3a348e98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, niter, lr):\n",
    "    # Get the gradients function\n",
    "    params = model.dnn.trainable_params()\n",
    "    params.append(model.lambda_u)\n",
    "    params.append(model.lambda_uux)\n",
    "\n",
    "    optimizer_Adam = nn.Adam(params, learning_rate=lr)\n",
    "\n",
    "    grad_fn = ms.value_and_grad(model.loss_fn, None, optimizer_Adam.parameters, has_aux=True)\n",
    "\n",
    "    model.dnn.set_train()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, 1+niter):\n",
    "        (loss, loss_u, loss_f_u, loss_lambda_u), grads = grad_fn(model.x, model.t, model.x_f, model.t_f, model.u)\n",
    "\n",
    "        optimizer_Adam(grads)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('It: %d, Loss: %.3e, loss_u:  %.3e, loss_f:  %.3e, loss_lambda:  %.3e, Lambda_uux: %.3f, Lambda_uxx: %.3f, Lambda_uxxxx: %.3f, Time: %.2f'  %\\\n",
    "                    (epoch, loss.item(), loss_u.item(), loss_f_u.item(), loss_lambda_u.item(),\n",
    "                     model.lambda_uux.item(), model.lambda_u[2].item(), model.lambda_u[4].item(), elapsed))\n",
    "\n",
    "            initial_size = 5\n",
    "\n",
    "            loss_history_Adam_Pretrain = np.empty([0])\n",
    "            loss_u_history_Adam_Pretrain = np.empty([0])\n",
    "            loss_f_u_history_Adam_Pretrain = np.empty([0])\n",
    "            loss_lambda_u_history_Adam_Pretrain = np.empty([0])\n",
    "\n",
    "            lambda_u_history_Adam_Pretrain = np.zeros((initial_size, 1))\n",
    "            lambda_uux_history_Adam_Pretrain = np.zeros((1, 1))\n",
    "\n",
    "            loss_history_Adam_Pretrain = np.append(loss_history_Adam_Pretrain, loss.numpy())\n",
    "            lambda_u_history_Adam_Pretrain = np.append(lambda_u_history_Adam_Pretrain, model.lambda_u.numpy(), axis=1)\n",
    "            loss_u_history_Adam_Pretrain = np.append(loss_u_history_Adam_Pretrain, loss_u.numpy())\n",
    "            loss_f_u_history_Adam_Pretrain = np.append(loss_f_u_history_Adam_Pretrain, loss_f_u.numpy())\n",
    "            loss_lambda_u_history_Adam_Pretrain = np.append(loss_lambda_u_history_Adam_Pretrain, loss_lambda_u.numpy())\n",
    "\n",
    "            lambda_uux_new = np.array([model.lambda_uux.numpy()])\n",
    "            lambda_uux_history_Adam_Pretrain = np.append(lambda_uux_history_Adam_Pretrain, lambda_uux_new, axis=1)\n",
    "\n",
    "            start_time = time.time()\n",
    "    np.save(f'Loss-Coe/{second_path}/loss_history_Adam_Pretrain', loss_history_Adam_Pretrain)\n",
    "    np.save(f'Loss-Coe/{second_path}/loss_u_history_Adam_Pretrain', loss_u_history_Adam_Pretrain)\n",
    "    np.save(f'Loss-Coe/{second_path}/loss_f_u_history_Adam_Pretrain', loss_f_u_history_Adam_Pretrain)\n",
    "    np.save(f'Loss-Coe/{second_path}/loss_lambda_u_history_Adam_Pretrain', loss_lambda_u_history_Adam_Pretrain)\n",
    "\n",
    "    np.save(f'Loss-Coe/{second_path}/lambda_u_history_Adam_Pretrain', lambda_u_history_Adam_Pretrain)\n",
    "    np.save(f'Loss-Coe/{second_path}/lambda_uux_history_Adam_Pretrain', lambda_uux_history_Adam_Pretrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfedd05b-3d38-4156-b061-8278d232a7f9",
   "metadata": {},
   "source": [
    "Run training and save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658395b-cade-408e-b999-585ba1ae73d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss: 8.652e-01, loss_u:  8.652e-01, loss_f:  4.359e-08, loss_lambda:  0.000e+00, Lambda_uux: 0.000, Lambda_uxx: -0.000, Lambda_uxxxx: -0.000, Time: 9.59\n",
      "It: 10, Loss: 8.434e-01, loss_u:  8.434e-01, loss_f:  7.940e-05, loss_lambda:  1.668e-09, Lambda_uux: 0.003, Lambda_uxx: 0.003, Lambda_uxxxx: -0.002, Time: 2.70\n",
      "It: 20, Loss: 8.391e-01, loss_u:  8.390e-01, loss_f:  6.748e-05, loss_lambda:  4.801e-09, Lambda_uux: 0.012, Lambda_uxx: 0.011, Lambda_uxxxx: -0.006, Time: 2.71\n",
      "It: 30, Loss: 8.277e-01, loss_u:  8.274e-01, loss_f:  3.814e-04, loss_lambda:  7.764e-09, Lambda_uux: 0.022, Lambda_uxx: 0.012, Lambda_uxxxx: -0.012, Time: 2.71\n",
      "It: 40, Loss: 8.105e-01, loss_u:  8.096e-01, loss_f:  9.378e-04, loss_lambda:  1.053e-08, Lambda_uux: 0.034, Lambda_uxx: 0.001, Lambda_uxxxx: -0.025, Time: 2.70\n",
      "It: 50, Loss: 7.876e-01, loss_u:  7.863e-01, loss_f:  1.300e-03, loss_lambda:  1.481e-08, Lambda_uux: 0.047, Lambda_uxx: -0.014, Lambda_uxxxx: -0.024, Time: 2.70\n",
      "It: 60, Loss: 7.637e-01, loss_u:  7.625e-01, loss_f:  1.200e-03, loss_lambda:  1.795e-08, Lambda_uux: 0.050, Lambda_uxx: -0.031, Lambda_uxxxx: -0.010, Time: 2.71\n",
      "It: 70, Loss: 7.529e-01, loss_u:  7.517e-01, loss_f:  1.191e-03, loss_lambda:  2.110e-08, Lambda_uux: 0.040, Lambda_uxx: -0.043, Lambda_uxxxx: -0.005, Time: 2.71\n",
      "It: 80, Loss: 7.427e-01, loss_u:  7.414e-01, loss_f:  1.279e-03, loss_lambda:  2.508e-08, Lambda_uux: 0.025, Lambda_uxx: -0.048, Lambda_uxxxx: -0.013, Time: 2.72\n",
      "It: 90, Loss: 7.363e-01, loss_u:  7.349e-01, loss_f:  1.400e-03, loss_lambda:  2.884e-08, Lambda_uux: 0.008, Lambda_uxx: -0.049, Lambda_uxxxx: -0.021, Time: 2.73\n",
      "It: 100, Loss: 7.387e-01, loss_u:  7.375e-01, loss_f:  1.260e-03, loss_lambda:  3.227e-08, Lambda_uux: -0.011, Lambda_uxx: -0.052, Lambda_uxxxx: -0.020, Time: 2.72\n",
      "It: 110, Loss: 6.951e-01, loss_u:  6.938e-01, loss_f:  1.347e-03, loss_lambda:  3.469e-08, Lambda_uux: -0.029, Lambda_uxx: -0.050, Lambda_uxxxx: -0.016, Time: 2.71\n",
      "It: 120, Loss: 6.755e-01, loss_u:  6.739e-01, loss_f:  1.603e-03, loss_lambda:  3.688e-08, Lambda_uux: -0.048, Lambda_uxx: -0.041, Lambda_uxxxx: -0.010, Time: 2.73\n",
      "It: 130, Loss: 6.711e-01, loss_u:  6.691e-01, loss_f:  2.080e-03, loss_lambda:  3.856e-08, Lambda_uux: -0.067, Lambda_uxx: -0.031, Lambda_uxxxx: -0.008, Time: 2.73\n",
      "It: 140, Loss: 6.587e-01, loss_u:  6.566e-01, loss_f:  2.077e-03, loss_lambda:  4.122e-08, Lambda_uux: -0.085, Lambda_uxx: -0.030, Lambda_uxxxx: -0.010, Time: 2.73\n",
      "It: 150, Loss: 6.607e-01, loss_u:  6.589e-01, loss_f:  1.852e-03, loss_lambda:  4.403e-08, Lambda_uux: -0.103, Lambda_uxx: -0.038, Lambda_uxxxx: -0.010, Time: 2.72\n",
      "It: 160, Loss: 6.526e-01, loss_u:  6.509e-01, loss_f:  1.731e-03, loss_lambda:  4.603e-08, Lambda_uux: -0.119, Lambda_uxx: -0.041, Lambda_uxxxx: -0.011, Time: 2.74\n",
      "It: 170, Loss: 6.486e-01, loss_u:  6.468e-01, loss_f:  1.820e-03, loss_lambda:  4.645e-08, Lambda_uux: -0.133, Lambda_uxx: -0.039, Lambda_uxxxx: -0.008, Time: 2.75\n",
      "It: 180, Loss: 6.398e-01, loss_u:  6.379e-01, loss_f:  1.904e-03, loss_lambda:  4.652e-08, Lambda_uux: -0.142, Lambda_uxx: -0.037, Lambda_uxxxx: -0.008, Time: 2.75\n",
      "It: 190, Loss: 6.331e-01, loss_u:  6.311e-01, loss_f:  1.962e-03, loss_lambda:  4.687e-08, Lambda_uux: -0.147, Lambda_uxx: -0.041, Lambda_uxxxx: -0.008, Time: 2.75\n",
      "It: 200, Loss: 6.274e-01, loss_u:  6.253e-01, loss_f:  2.085e-03, loss_lambda:  4.720e-08, Lambda_uux: -0.148, Lambda_uxx: -0.045, Lambda_uxxxx: -0.010, Time: 2.75\n",
      "It: 210, Loss: 6.536e-01, loss_u:  6.519e-01, loss_f:  1.771e-03, loss_lambda:  4.710e-08, Lambda_uux: -0.148, Lambda_uxx: -0.046, Lambda_uxxxx: -0.011, Time: 2.77\n",
      "It: 220, Loss: 6.334e-01, loss_u:  6.315e-01, loss_f:  1.926e-03, loss_lambda:  4.675e-08, Lambda_uux: -0.148, Lambda_uxx: -0.042, Lambda_uxxxx: -0.010, Time: 2.77\n",
      "It: 230, Loss: 6.245e-01, loss_u:  6.225e-01, loss_f:  1.961e-03, loss_lambda:  4.706e-08, Lambda_uux: -0.151, Lambda_uxx: -0.042, Lambda_uxxxx: -0.009, Time: 2.77\n",
      "It: 240, Loss: 6.263e-01, loss_u:  6.241e-01, loss_f:  2.160e-03, loss_lambda:  4.861e-08, Lambda_uux: -0.156, Lambda_uxx: -0.048, Lambda_uxxxx: -0.009, Time: 2.78\n",
      "It: 250, Loss: 6.191e-01, loss_u:  6.170e-01, loss_f:  2.121e-03, loss_lambda:  4.961e-08, Lambda_uux: -0.160, Lambda_uxx: -0.047, Lambda_uxxxx: -0.013, Time: 2.79\n",
      "It: 260, Loss: 6.183e-01, loss_u:  6.161e-01, loss_f:  2.112e-03, loss_lambda:  4.981e-08, Lambda_uux: -0.163, Lambda_uxx: -0.046, Lambda_uxxxx: -0.011, Time: 2.78\n",
      "It: 270, Loss: 6.363e-01, loss_u:  6.348e-01, loss_f:  1.559e-03, loss_lambda:  4.977e-08, Lambda_uux: -0.165, Lambda_uxx: -0.046, Lambda_uxxxx: -0.009, Time: 2.79\n",
      "It: 280, Loss: 6.233e-01, loss_u:  6.219e-01, loss_f:  1.398e-03, loss_lambda:  4.956e-08, Lambda_uux: -0.164, Lambda_uxx: -0.039, Lambda_uxxxx: -0.011, Time: 2.76\n",
      "It: 290, Loss: 6.165e-01, loss_u:  6.149e-01, loss_f:  1.583e-03, loss_lambda:  4.968e-08, Lambda_uux: -0.164, Lambda_uxx: -0.041, Lambda_uxxxx: -0.009, Time: 2.78\n",
      "It: 300, Loss: 6.152e-01, loss_u:  6.133e-01, loss_f:  1.894e-03, loss_lambda:  5.086e-08, Lambda_uux: -0.166, Lambda_uxx: -0.045, Lambda_uxxxx: -0.010, Time: 2.79\n",
      "It: 310, Loss: 6.131e-01, loss_u:  6.111e-01, loss_f:  1.962e-03, loss_lambda:  5.149e-08, Lambda_uux: -0.168, Lambda_uxx: -0.044, Lambda_uxxxx: -0.012, Time: 2.76\n",
      "It: 320, Loss: 6.118e-01, loss_u:  6.099e-01, loss_f:  1.951e-03, loss_lambda:  5.119e-08, Lambda_uux: -0.167, Lambda_uxx: -0.042, Lambda_uxxxx: -0.010, Time: 2.77\n",
      "It: 330, Loss: 6.117e-01, loss_u:  6.098e-01, loss_f:  1.895e-03, loss_lambda:  5.083e-08, Lambda_uux: -0.164, Lambda_uxx: -0.040, Lambda_uxxxx: -0.009, Time: 2.83\n",
      "It: 340, Loss: 6.189e-01, loss_u:  6.172e-01, loss_f:  1.712e-03, loss_lambda:  5.067e-08, Lambda_uux: -0.160, Lambda_uxx: -0.039, Lambda_uxxxx: -0.009, Time: 2.78\n",
      "It: 350, Loss: 6.082e-01, loss_u:  6.065e-01, loss_f:  1.698e-03, loss_lambda:  5.041e-08, Lambda_uux: -0.155, Lambda_uxx: -0.037, Lambda_uxxxx: -0.008, Time: 2.77\n",
      "It: 360, Loss: 6.081e-01, loss_u:  6.063e-01, loss_f:  1.809e-03, loss_lambda:  5.056e-08, Lambda_uux: -0.152, Lambda_uxx: -0.036, Lambda_uxxxx: -0.009, Time: 2.79\n",
      "It: 370, Loss: 6.051e-01, loss_u:  6.032e-01, loss_f:  1.876e-03, loss_lambda:  5.059e-08, Lambda_uux: -0.148, Lambda_uxx: -0.036, Lambda_uxxxx: -0.008, Time: 2.79\n",
      "It: 380, Loss: 6.055e-01, loss_u:  6.037e-01, loss_f:  1.803e-03, loss_lambda:  5.015e-08, Lambda_uux: -0.143, Lambda_uxx: -0.035, Lambda_uxxxx: -0.006, Time: 2.77\n",
      "It: 390, Loss: 6.034e-01, loss_u:  6.016e-01, loss_f:  1.792e-03, loss_lambda:  4.962e-08, Lambda_uux: -0.138, Lambda_uxx: -0.034, Lambda_uxxxx: -0.006, Time: 2.77\n",
      "It: 400, Loss: 6.059e-01, loss_u:  6.041e-01, loss_f:  1.862e-03, loss_lambda:  4.929e-08, Lambda_uux: -0.134, Lambda_uxx: -0.034, Lambda_uxxxx: -0.006, Time: 2.77\n",
      "It: 410, Loss: 6.145e-01, loss_u:  6.125e-01, loss_f:  1.953e-03, loss_lambda:  4.881e-08, Lambda_uux: -0.130, Lambda_uxx: -0.033, Lambda_uxxxx: -0.006, Time: 2.79\n",
      "It: 420, Loss: 6.006e-01, loss_u:  5.988e-01, loss_f:  1.864e-03, loss_lambda:  4.812e-08, Lambda_uux: -0.126, Lambda_uxx: -0.032, Lambda_uxxxx: -0.006, Time: 2.78\n",
      "It: 430, Loss: 6.028e-01, loss_u:  6.009e-01, loss_f:  1.912e-03, loss_lambda:  4.785e-08, Lambda_uux: -0.123, Lambda_uxx: -0.031, Lambda_uxxxx: -0.006, Time: 2.77\n",
      "It: 440, Loss: 6.053e-01, loss_u:  6.034e-01, loss_f:  1.977e-03, loss_lambda:  4.752e-08, Lambda_uux: -0.120, Lambda_uxx: -0.031, Lambda_uxxxx: -0.005, Time: 2.78\n",
      "It: 450, Loss: 6.020e-01, loss_u:  6.000e-01, loss_f:  2.001e-03, loss_lambda:  4.713e-08, Lambda_uux: -0.118, Lambda_uxx: -0.030, Lambda_uxxxx: -0.005, Time: 2.77\n",
      "It: 460, Loss: 6.029e-01, loss_u:  6.010e-01, loss_f:  1.983e-03, loss_lambda:  4.692e-08, Lambda_uux: -0.114, Lambda_uxx: -0.029, Lambda_uxxxx: -0.004, Time: 2.76\n",
      "It: 470, Loss: 6.003e-01, loss_u:  5.984e-01, loss_f:  1.935e-03, loss_lambda:  4.677e-08, Lambda_uux: -0.111, Lambda_uxx: -0.029, Lambda_uxxxx: -0.004, Time: 2.82\n",
      "It: 480, Loss: 5.998e-01, loss_u:  5.978e-01, loss_f:  2.000e-03, loss_lambda:  4.657e-08, Lambda_uux: -0.108, Lambda_uxx: -0.028, Lambda_uxxxx: -0.003, Time: 2.85\n",
      "It: 490, Loss: 5.983e-01, loss_u:  5.962e-01, loss_f:  2.034e-03, loss_lambda:  4.634e-08, Lambda_uux: -0.103, Lambda_uxx: -0.027, Lambda_uxxxx: -0.003, Time: 2.78\n",
      "It: 500, Loss: 6.057e-01, loss_u:  6.037e-01, loss_f:  1.992e-03, loss_lambda:  4.605e-08, Lambda_uux: -0.097, Lambda_uxx: -0.026, Lambda_uxxxx: -0.003, Time: 2.77\n",
      "It: 510, Loss: 5.983e-01, loss_u:  5.964e-01, loss_f:  1.930e-03, loss_lambda:  4.612e-08, Lambda_uux: -0.091, Lambda_uxx: -0.026, Lambda_uxxxx: -0.003, Time: 2.77\n",
      "It: 520, Loss: 5.936e-01, loss_u:  5.915e-01, loss_f:  2.025e-03, loss_lambda:  4.610e-08, Lambda_uux: -0.087, Lambda_uxx: -0.026, Lambda_uxxxx: -0.003, Time: 2.76\n",
      "It: 530, Loss: 5.977e-01, loss_u:  5.956e-01, loss_f:  2.026e-03, loss_lambda:  4.607e-08, Lambda_uux: -0.081, Lambda_uxx: -0.025, Lambda_uxxxx: -0.002, Time: 2.76\n",
      "It: 540, Loss: 5.984e-01, loss_u:  5.964e-01, loss_f:  2.023e-03, loss_lambda:  4.599e-08, Lambda_uux: -0.074, Lambda_uxx: -0.026, Lambda_uxxxx: -0.002, Time: 2.78\n",
      "It: 550, Loss: 5.955e-01, loss_u:  5.935e-01, loss_f:  1.976e-03, loss_lambda:  4.590e-08, Lambda_uux: -0.068, Lambda_uxx: -0.026, Lambda_uxxxx: -0.002, Time: 2.79\n",
      "It: 560, Loss: 5.927e-01, loss_u:  5.907e-01, loss_f:  1.977e-03, loss_lambda:  4.610e-08, Lambda_uux: -0.063, Lambda_uxx: -0.026, Lambda_uxxxx: -0.002, Time: 2.78\n"
     ]
    }
   ],
   "source": [
    "for epoch, lr in zip(epochs, learning_rate):\n",
    "    train(model_pretrain, int(epoch), lr)\n",
    "ms.save_checkpoint(model_pretrain.dnn, f'model/{second_path}/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9233f-3748-4481-9d91-0c6c4ff42d26",
   "metadata": {},
   "source": [
    "Save the learnable parameters of the last training for equation discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba9195-6d20-46ef-8bb4-f77e00914aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_uux_value = model_pretrain.lambda_uux.numpy()\n",
    "lambda_u_value = model_pretrain.lambda_u.numpy()\n",
    "np.save(f'Loss-Coe/{second_path}/lambda_uux_value', lambda_uux_value)\n",
    "np.save(f'Loss-Coe/{second_path}/lambda_u_value', lambda_u_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f276c8-9b5a-4f01-a76e-90e4c5addff9",
   "metadata": {},
   "source": [
    "Directly performing equation discovery after training may exceed the memory of GPU or NPU, so it is necessary to determine whether to reload the model for equation discovery based on the GPU or NPU memory size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b672fa0-3903-4ac7-9395-211895cfaeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_params:\n",
    "    lambda_u_value = np.load(f'Loss-Coe/{second_path}/lambda_u_value.npy')\n",
    "    lambda_uux_value = np.load(f'Loss-Coe/{second_path}/lambda_uux_value.npy')\n",
    "    model_ICCO = InvarianceConstrainedNN_STRdige(X_u_train, u_train, X_f_train, network_size, BatchNo, lambda_u_value, lambda_uux_value, load_params, second_path, msfloat_type)\n",
    "else:\n",
    "    model_ICCO = InvarianceConstrainedNN_STRdige(X_u_train, u_train, X_f_train, network_size, BatchNo, lambda_u_value, lambda_uux_value, load_params, second_path, msfloat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8887fa-9550-4873-a5cf-edd2a49b76ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_u_STRidge = model_ICCO.call_trainstridge(lam, d_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0acd9-8890-4bb9-bde1-77cf4e9b17f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_t = (0.973947)uu_x\n",
      "   (-0.967219)u_xx\n",
      "    + (-0.967183)u_xxxx\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "# GPU results\n",
    "print_pde(lambda_uux_value, lambda_u_STRidge, description_ks, ut='u_t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
