{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cascade-Net预测圆柱尾迹脉动速度时空场\n",
    "\n",
    "## 环境安装\n",
    "\n",
    "本案例要求 **MindSpore >= 2.0.0** 版本以调用如下接口: *mindspore.jit, mindspore.jit_class, mindspore.data_sink*。具体请查看[MindSpore安装](https://www.mindspore.cn/install)。\n",
    "\n",
    "此外，你需要安装 **MindFlow >=0.1.0** 版本。如果当前环境还没有安装，请按照下列方式选择后端和版本进行安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 背景介绍\n",
    "\n",
    "在湍流时空演化过程中，脉动速度场包含了一系列重要的流体物理过程，如分离、转捩和能量传递。在高雷诺数下，脉动速度场表现出明显的非线性特征。湍流尾迹中存在着从最大尺度到最小尺度的涡结构，这些流体运动模式构成了复杂的流场结构特征。在这些流场结构中，能量从大尺度结构向小尺度结构转移的过程被称为能量级串物理原理。受到这一原理的启发，可以将小尺度预测问题转化为由大尺度向小尺度逐级预测问题。\n",
    "\n",
    "## 模型框架\n",
    "\n",
    "模型框架如下图所示：\n",
    "\n",
    "![Cascade-Net](images/Cascade-Net.png)\n",
    "\n",
    "图中，Generator为具有空间和通道注意力门的U-Net结构，其框架如下图所示：\n",
    "\n",
    "![The U-Net structure of the generator with spatial and channel attention gates](images/The_U-Net_structure_of_the_generator_with_spatial_and_channel_attention_gates.png)\n",
    "\n",
    "其中空间注意力门*S*和通道注意力门*C*示意图如下：\n",
    "\n",
    "![Spatial attention gate S](images/Spatial_attention_gate_S.png)\n",
    "\n",
    "![Channel attention gate C](images/Channel_attention_gate_C.png)\n",
    "\n",
    "## 准备环节\n",
    "\n",
    "实践前，确保已经正确安装合适版本的MindSpore。如果没有，可以通过：\n",
    "\n",
    "* [MindSpore安装页面](https://www.mindspore.cn/install) 安装MindSpore。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练环节\n",
    "\n",
    "引入代码包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "from mindspore import ops, Tensor, context\n",
    "from mindflow.utils import load_yaml_config\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src import (init_sub_model, DefineCompoundCritic, DefineCompoundGan, WassersteinLoss, GradLoss, AccesstrainDataset,\n",
    "                 validation_test_dataset)\n",
    "\n",
    "matplotlib.use('agg')  # to prevent \"Fail to create pixmap with Tk_GetPixmap in TkImgPhotoInstanceSetSize\"\n",
    "ms.dataset.config.set_prefetch_size(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 数据集的准备\n",
    "\n",
    "数据集下载地址：[Cascade_Net/dataset](https://download-mindspore.osinfra.cn/mindscience/mindflow/dataset/applications/research/Cascade_Net/)。将数据集保存在`./dataset`路径下。\n",
    "\n",
    "数据为mat类型文件，每个文件中包括train、validation、test三个词典，分别表示训练集数据、验证集数据、测试集数据，其中训练集样本10792，验证集样本1704，测试集3408。训练集数据、验证集数据、测试集数据数据雷诺数分布如图所示：\n",
    "\n",
    "![Sample cases for training validation and testing](images/Sample_cases_for_training_validation_and_testing.png)\n",
    "\n",
    "* **conditions_Re_pd.mat** 文件包括样本雷诺数信息，其维度(*sample*, *Re*)为(, 1)。其中，*sample*为样本，*Re*为样本雷诺数。\n",
    "* **Input_flucReal_Cp_pd.mat** 文件包括样本壁面脉动压力的时空特征矩阵，其维度(*sample*, *θ*, *t*, *C*)为(, 128, 128, 3)。其中，*sample*为样本，*θ*为壁面压力场测点相位，*t*为时间，由脉动压力特征周期确定时间长度，*C*为通道数，3个通道分别为三个测面的压力数据。\n",
    "* **Input_scaling_u_pd.mat** 文件包括样本流场补充输入特征，其维度(*sample*, *U*)为(, 20)。其中，*sample*为样本，*U*为10个采样点流场补充输入特征*u*和*v*。\n",
    "* **ur_1.mat**，**ur_3.mat**，**ur_5.mat**，**ur_10.mat**文件为各尺度流场信息，其维度(*sample*, *H*, *W*, *C*)为(, 128, 128, 2)。其中，*sample*为样本，*H*和*W*为流场分辨率，*C*为通道数，2个通道分别为速度*u*和*v*。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset/'\n",
    "loader = AccesstrainDataset(data_dir)\n",
    "train_dataset = GeneratorDataset(source=loader, column_names=[\n",
    "    'u_r10_train', 'u_r5_train', 'u_r3_train', 'u_r1_train', 'cp_fluc_train', 'Re_c_train', 'scaling_input_train'])\n",
    "train_dataset = train_dataset.shuffle(buffer_size=25)\n",
    "\n",
    "(u_r10_validation, u_r5_validation, u_r3_validation, u_r1_validation, cp_fluc_validation, Re_c_validation,\n",
    " scaling_input_validation, u_r10_test, u_r5_test, u_r3_test, u_r1_test, cp_fluc_test, Re_c_test, scaling_input_test) \\\n",
    "    = validation_test_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 配置网络与训练参数\n",
    "\n",
    "从配置文件中读取网络相关参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"parse arguments\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Cascade Net\")\n",
    "    parser.add_argument(\"--mode\", type=str, default=\"PYNATIVE\", choices=[\"PYNATIVE\"],\n",
    "                        help=\"This case only supports PYNATIVE_MODE\")\n",
    "    parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                        help=\"The target device to run, support 'Ascend', 'GPU'\")\n",
    "    parser.add_argument(\"--device_id\", type=int, default=0,\n",
    "                        help=\"ID of the target device\")\n",
    "    parser.add_argument(\"--config_file_path\", type=str,\n",
    "                        default=\"./config/Cascade-Net.yaml\")\n",
    "    result_args = parser.parse_known_args()[0]\n",
    "    return result_args\n",
    "\n",
    "input_args = parse_args()\n",
    "context.set_context(mode=context.PYNATIVE_MODE,\n",
    "                    device_target=input_args.device_target,\n",
    "                    device_id=input_args.device_id)\n",
    "config = load_yaml_config(input_args.config_file_path)\n",
    "\n",
    "data_config = config[\"data\"]\n",
    "critic_config = config[\"critic\"]\n",
    "generator_config = config[\"generator\"]\n",
    "summary_config = config[\"summary\"]\n",
    "\n",
    "data_dir = data_config[\"root_dir\"]\n",
    "latent_z_n_channel = data_config[\"latent_z_n_channel\"]\n",
    "batch_size = data_config[\"batch_size\"]\n",
    "n_channel_p = data_config[\"n_channel_p\"]\n",
    "n_channel_u = data_config[\"n_channel_u\"]\n",
    "column_names = data_config[\"column_names\"]\n",
    "lambda_GP = critic_config[\"lambda_GP\"]\n",
    "critic_model_lr = critic_config[\"critic_model_lr\"]\n",
    "n_critic = critic_config[\"n_critic\"]\n",
    "lambda_L2_u = generator_config[\"lambda_L2_u\"]\n",
    "lambda_L2_gradu = generator_config[\"lambda_L2_gradu\"]\n",
    "gan_model_lr = generator_config[\"gan_model_lr\"]\n",
    "plot_n = summary_config[\"plot_n\"]\n",
    "n_imgs = summary_config[\"n_imgs\"]\n",
    "merge_n_imgs = summary_config[\"merge_n_imgs\"]\n",
    "sample_interval = summary_config[\"sample_interval\"]\n",
    "epochs = summary_config[\"epochs\"]\n",
    "dxy = summary_config[\"dxy\"]\n",
    "losslog = []\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "sample_num_train = loader.__len__()\n",
    "sample_num_val = u_r1_validation.shape[0]\n",
    "sample_num_test = u_r1_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建\n",
    "\n",
    "通过initial_model()函数构建各尺度子网络，包括四个尺度的子生成器和子判别器，并用于生成器和判别器初始化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成器及判别器\n",
    "(merge_model, g_model_I, d_model_I, g_model_II, d_model_II,\n",
    " g_model_III, d_model_III, g_model_IV, d_model_IV) = init_sub_model(n_channel_p, n_channel_u)\n",
    "critic_model = DefineCompoundCritic(n_channel_p, n_channel_u, batch_size,\n",
    "                                    d_model_I, d_model_II, d_model_III, d_model_IV)\n",
    "critic_model.update_parameters_name('critic')\n",
    "gan_model = DefineCompoundGan(n_channel_p, n_channel_u, merge_model,\n",
    "                              g_model_I, g_model_II, g_model_III, g_model_IV)\n",
    "gan_model.update_parameters_name('generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练函数\n",
    "\n",
    "训练主体代码部分，包括损失函数的定义、判别器和生成器前向计算过程和训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "wasserstein_loss = WassersteinLoss()\n",
    "mae_loss = nn.MAELoss(reduction='none')\n",
    "grad_loss = GradLoss(dxy)\n",
    "\n",
    "# 判别器前向计算过程\n",
    "def d_forward_fn(input):\n",
    "    g_input = [input[4], input[5], input[6], input[7]]\n",
    "    g_pred = gan_model(g_input)\n",
    "    d_input = [input[0], input[1], input[2], input[3], g_pred[4], g_pred[0], g_pred[1], g_pred[2], g_pred[3]]\n",
    "\n",
    "    d_pred = critic_model(d_input)\n",
    "    loss_wass = wasserstein_loss(ops.stack(d_pred[:8]), ops.Concat(axis=0)(\n",
    "        [-ops.ones_like(ops.stack(d_pred[:4])), ops.ones_like(ops.stack(d_pred[4:8]))]))\n",
    "    loss_gradp = ops.stack([d_pred[12](), d_pred[13](), d_pred[14](), d_pred[15]()])\n",
    "    loss = ops.sum(1 * loss_wass) + ops.sum(lambda_GP * loss_gradp)\n",
    "    loss_list = ms.numpy.concatenate((ms.numpy.expand_dims(loss, 0), loss_wass, loss_gradp), axis=0).asnumpy()\n",
    "    return loss, loss_list\n",
    "\n",
    "# 生成器前向计算过程\n",
    "def g_forward_fn(true, input):\n",
    "    g_input = [input[4], input[5], input[6], input[7]]\n",
    "    g_pred = gan_model(g_input)\n",
    "    d_input = [input[0], input[1], input[2], input[3], g_pred[4], g_pred[0], g_pred[1], g_pred[2], g_pred[3]]\n",
    "    d_pred = critic_model(d_input)\n",
    "\n",
    "    loss_wass = wasserstein_loss(ops.stack(d_pred[4:8]), -ops.ones_like(ops.stack(d_pred[4:8])))\n",
    "    loss_mae = mae_loss(ops.stack(g_pred[:4]), ops.stack(true[:4]))\n",
    "    loss_mae = ops.mean(loss_mae, axis=(1, 2, 3, 4))\n",
    "    loss_grad = grad_loss(ops.stack(g_pred[5:9]), ops.stack(true[:4]))\n",
    "    loss = (ops.sum(1 * loss_wass) + ops.sum(lambda_L2_u * loss_mae) + ops.sum(lambda_L2_gradu * loss_grad))\n",
    "    loss_list = ms.numpy.concatenate((ms.numpy.expand_dims(loss, 0), loss_wass, loss_mae, loss_grad), axis=0).asnumpy()\n",
    "    return loss, loss_list\n",
    "\n",
    "# 训练过程\n",
    "def train_step(g_real_data, input):\n",
    "    # 计算判别器损失和梯度\n",
    "    for _ in range(n_critic):\n",
    "        (_, d_loss_list), d_grads = d_grad_fn(input)\n",
    "        d_optimizer(d_grads)\n",
    "        ave_g_loss_train_ncritic.append(d_loss_list)\n",
    "    ave_d_loss_train.append(np.mean(ave_g_loss_train_ncritic, axis=0))\n",
    "    (_, g_loss_list), g_grads = g_grad_fn(g_real_data, input)\n",
    "    g_optimizer(g_grads)\n",
    "    ave_g_loss_train.append(g_loss_list)\n",
    "\n",
    "# 测试评价\n",
    "def define_evaluation(u_r10, u_r5, u_r3, u_r1, cp, Re, scaling_input, latent_z, idx):\n",
    "    _, batch_d_loss = d_forward_fn(\n",
    "        [Tensor(u_r10[idx, :, :, :]), Tensor(u_r5[idx, :, :, :]), Tensor(u_r3[idx, :, :, :]), Tensor(u_r1[idx, :, :, :]),\n",
    "         Tensor(cp[idx, :, :, :]), Tensor(Re[idx, :]), Tensor(scaling_input[idx, :]), latent_z])\n",
    "    _, batch_g_loss = g_forward_fn(\n",
    "        [Tensor(u_r10[idx, :, :, :]), Tensor(u_r5[idx, :, :, :]), Tensor(u_r3[idx, :, :, :]), Tensor(u_r1[idx, :, :, :])],\n",
    "        [Tensor(u_r10[idx, :, :, :]), Tensor(u_r5[idx, :, :, :]), Tensor(u_r3[idx, :, :, :]), Tensor(u_r1[idx, :, :, :]),\n",
    "         Tensor(cp[idx, :, :, :]), Tensor(Re[idx, :]), Tensor(scaling_input[idx, :]), latent_z])\n",
    "    return batch_d_loss, batch_g_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "\n",
    "当前案例中的优化器采用RMSProp优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器\n",
    "d_optimizer = nn.RMSProp(critic_model.trainable_params(), learning_rate=critic_model_lr)\n",
    "d_grad_fn = ms.value_and_grad(d_forward_fn, None, d_optimizer.parameters, has_aux=True)\n",
    "g_optimizer = nn.RMSProp(gan_model.trainable_params(), learning_rate=gan_model_lr)\n",
    "g_grad_fn = ms.value_and_grad(g_forward_fn, None, g_optimizer.parameters, has_aux=True)\n",
    "d_optimizer.update_parameters_name('optim_d')\n",
    "g_optimizer.update_parameters_name('optim_g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果可视化\n",
    "\n",
    "绘制网络的预测图，用于结果输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.linspace(-1, 1, 128)\n",
    "x1 = np.linspace(-1, 1, 128)\n",
    "xx, yy = np.meshgrid(x1, y1)  # xy_data.new\n",
    "\n",
    "def sample_images(epoch):  # plot_n = 5\n",
    "    idx_train = np.random.randint(0, sample_num_train, plot_n)\n",
    "    idx_test = np.random.randint(0, sample_num_test, plot_n)\n",
    "    latent_z_input_train = Tensor(np.random.normal(0, 1, (\n",
    "        plot_n, latent_z_n_channel, merge_n_imgs, merge_n_imgs)), dtype=ms.float32)\n",
    "    latent_z_input_test = Tensor(np.random.normal(0, 1, (\n",
    "        plot_n, latent_z_n_channel, merge_n_imgs, merge_n_imgs)), dtype=ms.float32)\n",
    "    gen_u_I, gen_u_II, gen_u_III, gen_u_IV, _, _, _, _, _, _ = gan_model([\n",
    "        Tensor(loader[idx_train][4]),\n",
    "        Tensor(loader[idx_train][5]),\n",
    "        Tensor(loader[idx_train][6]),\n",
    "        latent_z_input_train])\n",
    "    gen_u_I_, gen_u_II_, gen_u_III_, gen_u_IV_, _, _, _, _, _, _ = gan_model([\n",
    "        Tensor(cp_fluc_test[idx_test, :, :, :]),\n",
    "        Tensor(Re_c_test[idx_test, :]),\n",
    "        Tensor(scaling_input_test[idx_test, :]),\n",
    "        latent_z_input_test])\n",
    "    del _\n",
    "    plot_images(epoch,\n",
    "                velocity_part=0,\n",
    "                gen_u_I=gen_u_I,\n",
    "                gen_u_II=gen_u_II,\n",
    "                gen_u_III=gen_u_III,\n",
    "                gen_u_IV=gen_u_IV,\n",
    "                sel_index=idx_train,\n",
    "                is_train=True)\n",
    "    plot_images(epoch,\n",
    "                velocity_part=1,\n",
    "                gen_u_I=gen_u_I,\n",
    "                gen_u_II=gen_u_II,\n",
    "                gen_u_III=gen_u_III,\n",
    "                gen_u_IV=gen_u_IV,\n",
    "                sel_index=idx_train,\n",
    "                is_train=True)\n",
    "    plot_images(epoch,\n",
    "                velocity_part=0,\n",
    "                gen_u_I=gen_u_I_,\n",
    "                gen_u_II=gen_u_II_,\n",
    "                gen_u_III=gen_u_III_,\n",
    "                gen_u_IV=gen_u_IV_,\n",
    "                sel_index=idx_test,\n",
    "                is_test=True)\n",
    "    plot_images(epoch,\n",
    "                velocity_part=1,\n",
    "                gen_u_I=gen_u_I_,\n",
    "                gen_u_II=gen_u_II_,\n",
    "                gen_u_III=gen_u_III_,\n",
    "                gen_u_IV=gen_u_IV_,\n",
    "                sel_index=idx_test, is_test=True)\n",
    "\n",
    "def plot_images(epoch, velocity_part, gen_u_I, gen_u_II, gen_u_III, gen_u_IV, sel_index, is_train=False, is_test=False):\n",
    "    # including ur,vr,gradur, and grad_vr\n",
    "    # velocity_part = 0 for u and 1 for v\n",
    "    velocity_name = list(['u', 'v'])\n",
    "    _, ax = plt.subplots(5, 8, figsize=(20, 16))\n",
    "    if is_train:\n",
    "        index = 0\n",
    "        for i in range(0, 5, 1):\n",
    "            ax[i, 0].contourf(xx, yy,\n",
    "                              gen_u_I[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 0].axis('off')\n",
    "            ax[i, 1].contourf(xx, yy, loader[sel_index[index]][0][velocity_part, :, :], cmap='coolwarm')\n",
    "            ax[i, 1].axis('off')\n",
    "            ax[i, 2].contourf(xx, yy,\n",
    "                              gen_u_II[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 2].axis('off')\n",
    "            ax[i, 3].contourf(xx, yy, loader[sel_index[index]][1][velocity_part, :, :], cmap='coolwarm')\n",
    "            ax[i, 3].axis('off')\n",
    "            ax[i, 4].contourf(xx, yy,\n",
    "                              gen_u_III[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 4].axis('off')\n",
    "            ax[i, 5].contourf(xx, yy, loader[sel_index[index]][2][velocity_part, :, :], cmap='coolwarm')\n",
    "            ax[i, 5].axis('off')\n",
    "            ax[i, 6].contourf(xx, yy,\n",
    "                              gen_u_IV[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 6].axis('off')\n",
    "            ax[i, 7].contourf(xx, yy, loader[sel_index[index]][3][velocity_part, :, :], cmap='coolwarm')\n",
    "            ax[i, 7].axis('off')\n",
    "\n",
    "            index = index + 1\n",
    "        plt.savefig('training_results/images/imgs_train_' + velocity_name[velocity_part] + '%d.png' % (\n",
    "            epoch))\n",
    "        plt.close()\n",
    "    if is_test:\n",
    "        index = 0\n",
    "        for i in range(0, 5, 1):\n",
    "            ax[i, 0].contourf(xx, yy,\n",
    "                              gen_u_I[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 0].axis('off')\n",
    "            ax[i, 1].contourf(xx, yy,\n",
    "                              u_r10_test[sel_index[index], velocity_part, :, :].reshape(n_imgs, n_imgs),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 1].axis('off')\n",
    "            ax[i, 2].contourf(xx, yy,\n",
    "                              gen_u_II[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 2].axis('off')\n",
    "            ax[i, 3].contourf(xx, yy,\n",
    "                              u_r5_test[sel_index[index], velocity_part, :, :].reshape(n_imgs, n_imgs),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 3].axis('off')\n",
    "            ax[i, 4].contourf(xx, yy,\n",
    "                              gen_u_III[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 4].axis('off')\n",
    "            ax[i, 5].contourf(xx, yy,\n",
    "                              u_r3_test[sel_index[index], velocity_part, :, :].reshape(n_imgs, n_imgs),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 5].axis('off')\n",
    "            ax[i, 6].contourf(xx, yy,\n",
    "                              gen_u_IV[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 6].axis('off')\n",
    "            ax[i, 7].contourf(xx, yy,\n",
    "                              u_r1_test[sel_index[index], velocity_part, :, :].reshape(n_imgs, n_imgs),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 7].axis('off')\n",
    "            index = index + 1\n",
    "        plt.savefig('training_results/images/imgs_test_' + velocity_name[velocity_part] + '%d.png' % (\n",
    "            epoch))\n",
    "        plt.close()\n",
    "    plt.cla()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "模型训练过程中边训练边预测，每训练sample_interval个epoch后输出一次训练集、验证集及测试集上的推理精度并保存可视化结果。同时，还可以每隔sample_interval保存一次checkpoint文件并保存loss文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:05<00:00, 32.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[1 min] [D:39.03, 0.99, 0.98, 0.97, 0.98] [G:19059.70, 0.03, 0.07, 0.08, -0.00] [L2_train:0.53217, 0.50981, 0.49375, 0.47186] [L2_val:0.47761, 0.43199, 0.35800, 0.27486] [L2_test:0.50221, 0.42599, 0.35425, 0.28793]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                                                            | 0/2 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m [u_r10_train, u_r5_train, u_r3_train, u_r1_train,\n\u001b[0;32m     15\u001b[0m              cp_fluc_train, Re_c_train, scaling_input_train, latent_z_input_train]\n\u001b[0;32m     16\u001b[0m     g_true \u001b[38;5;241m=\u001b[39m [u_r10_train, u_r5_train, u_r3_train, u_r1_train]\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m ave_d_loss_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ave_d_loss_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m ave_g_loss_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ave_g_loss_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 39\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(g_real_data, input)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(g_real_data, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# 计算判别器损失和梯度\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_critic):\n\u001b[1;32m---> 39\u001b[0m         (_, d_loss_list), d_grads \u001b[38;5;241m=\u001b[39m \u001b[43md_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m         d_optimizer(d_grads)\n\u001b[0;32m     41\u001b[0m         ave_g_loss_train_ncritic\u001b[38;5;241m.\u001b[39mappend(d_loss_list)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:625\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_grad\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad_(fn_, weights)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\common\\api.py:121\u001b[0m, in \u001b[0;36m_wrap_func.<locals>.wrapper\u001b[1;34m(*arg, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39marg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 121\u001b[0m     results \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39marg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_python_data(results)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:600\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;129m@_wrap_func\u001b[39m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_grad\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 600\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pynative_forward_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mgrad(fn, grad_, weights, grad_position, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    602\u001b[0m     out \u001b[38;5;241m=\u001b[39m _pynative_executor()\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:650\u001b[0m, in \u001b[0;36m_Grad._pynative_forward_run\u001b[1;34m(self, fn, grad, weights, args, kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m _pynative_executor\u001b[38;5;241m.\u001b[39mset_grad_flag(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    649\u001b[0m _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[1;32m--> 650\u001b[0m outputs \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m    651\u001b[0m _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(fn, outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:561\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.aux_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maux_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 561\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen has_aux is True, origin fn requires more than one outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m, in \u001b[0;36md_forward_fn\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m      9\u001b[0m g_pred \u001b[38;5;241m=\u001b[39m gan_model(g_input)\n\u001b[0;32m     10\u001b[0m d_input \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m3\u001b[39m], g_pred[\u001b[38;5;241m4\u001b[39m], g_pred[\u001b[38;5;241m0\u001b[39m], g_pred[\u001b[38;5;241m1\u001b[39m], g_pred[\u001b[38;5;241m2\u001b[39m], g_pred[\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m---> 12\u001b[0m d_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcritic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss_wass \u001b[38;5;241m=\u001b[39m wasserstein_loss(ops\u001b[38;5;241m.\u001b[39mstack(d_pred[:\u001b[38;5;241m8\u001b[39m]), ops\u001b[38;5;241m.\u001b[39mConcat(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)(\n\u001b[0;32m     14\u001b[0m     [\u001b[38;5;241m-\u001b[39mops\u001b[38;5;241m.\u001b[39mones_like(ops\u001b[38;5;241m.\u001b[39mstack(d_pred[:\u001b[38;5;241m4\u001b[39m])), ops\u001b[38;5;241m.\u001b[39mones_like(ops\u001b[38;5;241m.\u001b[39mstack(d_pred[\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m8\u001b[39m]))]))\n\u001b[0;32m     15\u001b[0m loss_gradp \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mstack([d_pred[\u001b[38;5;241m12\u001b[39m](), d_pred[\u001b[38;5;241m13\u001b[39m](), d_pred[\u001b[38;5;241m14\u001b[39m](), d_pred[\u001b[38;5;241m15\u001b[39m]()])\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\nn\\cell.py:701\u001b[0m, in \u001b[0;36mCell.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    700\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 701\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(\u001b[38;5;28mself\u001b[39m, output, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\nn\\cell.py:482\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shard_fn(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 482\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_forward_hook:\n\u001b[0;32m    484\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\mindspore\\mindscience\\MindFlow\\applications\\research\\cascade_net\\src\\CompoundModel.py:157\u001b[0m, in \u001b[0;36mDefineCompoundCritic.construct\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    155\u001b[0m diff_fv \u001b[38;5;241m=\u001b[39m in_u_ii \u001b[38;5;241m-\u001b[39m gen_u_ii\n\u001b[0;32m    156\u001b[0m interpolated_img_ii \u001b[38;5;241m=\u001b[39m gen_u_ii \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m diff_fv\n\u001b[1;32m--> 157\u001b[0m d_on_interp_ii \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model_ii\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpolated_img_ii\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_merge\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m partial_gp_loss_ii \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_penalty_loss, d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model_ii,\n\u001b[0;32m    159\u001b[0m                              interpolated_img\u001b[38;5;241m=\u001b[39minterpolated_img_ii, in_merge\u001b[38;5;241m=\u001b[39min_merge)\n\u001b[0;32m    161\u001b[0m d_on_real_iii \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model_iii(in_u_iii, in_merge)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\nn\\cell.py:701\u001b[0m, in \u001b[0;36mCell.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    700\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 701\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(\u001b[38;5;28mself\u001b[39m, output, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\nn\\cell.py:482\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shard_fn(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 482\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_forward_hook:\n\u001b[0;32m    484\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\mindspore\\mindscience\\MindFlow\\applications\\research\\cascade_net\\src\\MultiscaleDiscriminator.py:94\u001b[0m, in \u001b[0;36mMultiscaleDiscriminator.construct\u001b[1;34m(self, in_d, in_merge)\u001b[0m\n\u001b[0;32m     92\u001b[0m     out_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator1(in_d, in_merge)  \u001b[38;5;66;03m# (None, 8,8,1)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_scale:\n\u001b[1;32m---> 94\u001b[0m     ur20 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mave_pool20\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     out_map_20 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator1(ur20, in_merge)  \u001b[38;5;66;03m# (None, 8,8,1)\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     ur10 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mave_pool10(in_d)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\nn\\cell.py:701\u001b[0m, in \u001b[0;36mCell.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    700\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 701\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_construct\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(\u001b[38;5;28mself\u001b[39m, output, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\nn\\cell.py:482\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shard_fn(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 482\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct(\u001b[38;5;241m*\u001b[39mcast_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_forward_hook:\n\u001b[0;32m    484\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\mindspore\\mindscience\\MindFlow\\applications\\research\\cascade_net\\src\\MultiscaleDiscriminator.py:33\u001b[0m, in \u001b[0;36mAveragePool2d.construct\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstruct\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 33\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\ops\\function\\nn_func.py:5507\u001b[0m, in \u001b[0;36mconv2d\u001b[1;34m(input, weight, bias, stride, pad_mode, padding, dilation, groups)\u001b[0m\n\u001b[0;32m   5505\u001b[0m out_channel \u001b[38;5;241m=\u001b[39m weight_shape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   5506\u001b[0m kernel_size \u001b[38;5;241m=\u001b[39m weight_shape[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m-> 5507\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m   5508\u001b[0m in_channel \u001b[38;5;241m=\u001b[39m input_shape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   5509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (in_channel \u001b[38;5;241m%\u001b[39m groups \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out_channel \u001b[38;5;241m%\u001b[39m groups \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\common\\_stub_tensor.py:85\u001b[0m, in \u001b[0;36mStubTensor.shape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstub:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstub_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 85\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstub_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstub_shape\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "critic_model.set_train()\n",
    "gan_model.set_train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.perf_counter()\n",
    "    ave_d_loss_train = list()\n",
    "    ave_g_loss_train = list()\n",
    "    for _, (u_r10_train, u_r5_train, u_r3_train, u_r1_train, cp_fluc_train, Re_c_train, scaling_input_train) in (\n",
    "            enumerate(tqdm(train_dataset))):\n",
    "        ave_g_loss_train_ncritic = list()\n",
    "        latent_z_input_train = ops.normal(\n",
    "            (batch_size, latent_z_n_channel, merge_n_imgs, merge_n_imgs),\n",
    "            0, 1, )\n",
    "        input = [u_r10_train, u_r5_train, u_r3_train, u_r1_train,\n",
    "                 cp_fluc_train, Re_c_train, scaling_input_train, latent_z_input_train]\n",
    "        g_true = [u_r10_train, u_r5_train, u_r3_train, u_r1_train]\n",
    "        train_step(g_true, input)\n",
    "    ave_d_loss_train = np.mean(ave_d_loss_train, axis=0)\n",
    "    ave_g_loss_train = np.mean(ave_g_loss_train, axis=0)\n",
    "\n",
    "    # predict the d_loss and g_loss in validation\n",
    "    idx_ = np.random.randint(0, sample_num_val, batch_size)\n",
    "    latent_z_input_validation = Tensor(np.random.normal(0, 1, (\n",
    "        batch_size, latent_z_n_channel, merge_n_imgs, merge_n_imgs)), dtype=ms.float32)\n",
    "    batch_d_loss_val, batch_g_loss_val = define_evaluation(\n",
    "        u_r10_validation, u_r5_validation, u_r3_validation, u_r1_validation,\n",
    "        cp_fluc_validation, Re_c_validation, scaling_input_validation, latent_z_input_validation, idx_)\n",
    "\n",
    "    # predict the d_loss and g_loss in testing\n",
    "    idx__ = np.random.randint(0, sample_num_test, batch_size)\n",
    "    latent_z_input_test = Tensor(np.random.normal(0, 1, (\n",
    "        batch_size, latent_z_n_channel, merge_n_imgs, merge_n_imgs)), dtype=ms.float32)\n",
    "    batch_d_loss_test, batch_g_loss_test = define_evaluation(\n",
    "        u_r10_test, u_r5_test, u_r3_test, u_r1_test,\n",
    "        cp_fluc_test, Re_c_test, scaling_input_test, latent_z_input_test, idx__)\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    time_consumption = (end - start) // 60  # covert s. to min.\n",
    "    # Plot the progress and index[0] is the weighted loss\n",
    "    print(\n",
    "        \"%d:[%d min] [D:%.2f, %.2f, %.2f, %.2f, %.2f] [G:%.2f, %.2f, %.2f, %.2f, %.2f] \"\n",
    "        \"[L2_train:%.5f, %.5f, %.5f, %.5f] [L2_val:%.5f, %.5f, %.5f, %.5f] [L2_test:%.5f, %.5f, %.5f, %.5f]\" %\n",
    "        (epoch, time_consumption,\n",
    "         ave_d_loss_train[0],\n",
    "         ave_d_loss_train[1] + ave_d_loss_train[5] + ave_d_loss_train[9],\n",
    "         ave_d_loss_train[2] + ave_d_loss_train[6] + ave_d_loss_train[10],\n",
    "         ave_d_loss_train[3] + ave_d_loss_train[7] + ave_d_loss_train[11],\n",
    "         ave_d_loss_train[4] + ave_d_loss_train[8] + ave_d_loss_train[12],\n",
    "         ave_g_loss_train[0],\n",
    "         ave_g_loss_train[1], ave_g_loss_train[2], ave_g_loss_train[3], ave_g_loss_train[4],\n",
    "         ave_g_loss_train[5], ave_g_loss_train[6], ave_g_loss_train[7], ave_g_loss_train[8],\n",
    "         batch_g_loss_val[5], batch_g_loss_val[6], batch_g_loss_val[7], batch_g_loss_val[8],\n",
    "         batch_g_loss_test[5], batch_g_loss_test[6], batch_g_loss_test[7], batch_g_loss_test[8]))\n",
    "\n",
    "    losslog.append(np.concatenate(  # 60\n",
    "        ([ave_d_loss_train[i] for i in range(13)],  # 13\n",
    "         [batch_d_loss_val[i] for i in range(13)],  # 13\n",
    "         [batch_d_loss_test[i] for i in range(13)],  # 13\n",
    "         [ave_g_loss_train[i] for i in range(13)],  # 13\n",
    "         [batch_g_loss_val[i] for i in range(13)],  # 13\n",
    "         [batch_g_loss_test[i] for i in range(13)])))  # 13\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % sample_interval == 0:\n",
    "        sample_images(epoch)\n",
    "        ms.save_checkpoint(gan_model, \"training_results/model/gan_%d\" % epoch + \".ckpt\")\n",
    "        ms.save_checkpoint(critic_model, \"training_results/model/critic_%d\" % epoch + \".ckpt\")\n",
    "        np.savetxt('training_results/loss/loss.txt', losslog, fmt='%.4f')\n",
    "    del ave_d_loss_train, ave_g_loss_train, batch_d_loss_val, batch_g_loss_val, batch_d_loss_test, batch_g_loss_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **结果可视化**\n",
    "\n",
    "300epoch训练下，网络生成训练集速度U和V方向各尺度速度场的预测值与真实值如下图所示：\n",
    "\n",
    "<img src=\"images/train_u.png\" style=\"zoom:25%\" align=\"center\"> <img src=\"images/train_v.png\" style=\"zoom:25%\" align=\"center\">\n",
    "\n",
    "300epoch训练下，网络生成测试集速度U和V方向各尺度速度场的预测值与真实值如下图所示：\n",
    "\n",
    "<img src=\"images/test_u.png\" style=\"zoom:25%\" align=\"center\"> <img src=\"images/test_v.png\" style=\"zoom:25%\" align=\"center\">\n",
    "\n",
    "其中一行为一个样本，每张图两列一组共四组，从左往右尺度依次减小，每组左边为生成值右边为真值。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9063439a3781aed32d6b0dd4804a0c8b51ecec7893a0f31b99846bc91ef39eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
