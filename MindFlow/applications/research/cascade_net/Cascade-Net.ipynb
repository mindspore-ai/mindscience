{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prediction of spatiotemporal field of pulsation velocity in cylindrical wake by Cascade Net\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "This notebook requires **MindSpore version >= 2.0.0** to support new APIs including: *mindspore.jit, mindspore.jit_class, mindspore.data_sink*. Please check [MindSpore Installation](https://www.mindspore.cn/install/en) for details.\n",
    "\n",
    "In addition, **MindFlow version >=0.1.0** is also required. If it has not been installed in your environment, please select the right version and hardware, then install it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In the process of turbulent spatiotemporal evolution, the pulsating velocity field includes a series of important fluid physical processes, such as separation, transition, and energy transfer. At high Reynolds numbers, the pulsating velocity field exhibits significant nonlinear characteristics. There are vortex structures in turbulent wake that range from maximum to minimum scales, and these fluid motion patterns constitute complex flow field structural characteristics. The process of energy transfer from large-scale structures to small-scale structures in these flow field structures is called the energy cascade physics principle. Inspired by this principle, the small-scale prediction problem can be transformed into a step-by-step prediction problem from large-scale to small-scale.\n",
    "\n",
    "## Model framework\n",
    "\n",
    "The model framework is as shown in the following figure:\n",
    "\n",
    "![Cascade-Net](images/Cascade-Net.png)\n",
    "\n",
    "Where, the generator is a U-Net structure with spatial and channel attention gates, and its framework is shown in the following figure:\n",
    "\n",
    "![The U-Net structure of the generator with spatial and channel attention gates](images/The_U-Net_structure_of_the_generator_with_spatial_and_channel_attention_gates.png)\n",
    "\n",
    "And for the spatial attention gate *S* and channel attention gate *C*, the integration diagrams are shown as follows:\n",
    "\n",
    "![Spatial attention gate S](images/Spatial_attention_gate_S.png)\n",
    "\n",
    "![Channel attention gate C](images/Channel_attention_gate_C.png)\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before practice, ensure that MindSpore of suitable version has been correctly installed. If not, you can run the following command:\n",
    "\n",
    "* [MindSpore installation page](https://www.mindspore.cn/install) Install MindSpore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Import code packs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "from mindspore import ops, Tensor, context\n",
    "from mindflow.utils import load_yaml_config\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src import (init_sub_model, DefineCompoundCritic, DefineCompoundGan, WassersteinLoss, GradLoss, AccesstrainDataset,\n",
    "                 validation_test_dataset)\n",
    "\n",
    "matplotlib.use('agg')  # to prevent \"Fail to create pixmap with Tk_GetPixmap in TkImgPhotoInstanceSetSize\"\n",
    "ms.dataset.config.set_prefetch_size(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Datasets Preparation\n",
    "\n",
    "Dataset download link: [Cascade_Net/dataset](https://download-mindspore.osinfra.cn/mindscience/mindflow/dataset/applications/research/Cascade_Net/). Save the dataset under path `./dataset`.\n",
    "\n",
    "The datasets are mat type file, each containing three dictionaries: train, validation, and test, representing training dataset, validation dataset, and test dataset. The samples number of training dataset is 10792, the samples number of validation datase is 1704, and the samples number of test dataset is 3408. The Reynolds number distribution of training set data, validation set data, and test set data is shown in the figure:\n",
    "\n",
    "![Sample cases for training validation and testing](images/Sample_cases_for_training_validation_and_testing.png)\n",
    "\n",
    "* **conditions_Re_pd.mat** including Reynolds number information with a dimensions(*sample*, *Re*) of (, 1), where *Re* is Reynolds number。\n",
    "* **Input_flucReal_Cp_pd.mat** including spatiotemporal characteristic matrix of wall pulsating pressure with a dimensions(*sample*, *θ*, *t*, *C*) of (, 128, 128, 3), where *θ* is measurement point phase of wall pressure field, *t* is time where the time length is controlled by the characteristic period of pulsating pressure, *C* is the channel number (3 channels are 3 measuring planes of wall pulsating pressure).\n",
    "* **Input_scaling_u_pd.mat** including flow field supplementary input featureswith a dimensions (*sample*, *U*) of (, 20), where *U* is supplementary input features of 10 sampling points flow field *u* and *v*.\n",
    "* **ur_1.mat**，**ur_3.mat**，**ur_5.mat**，**ur_10.mat** including flow field information at four scales with a dimensions (*sample*, *H*, *W*, *C*) of (, 128, 128, 2) where *H* and *W* are  flow field resolution, *C* is the channel number(2 channels are velocity U and V).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'dataset/'\n",
    "loader = AccesstrainDataset(data_dir)\n",
    "train_dataset = GeneratorDataset(source=loader, column_names=[\n",
    "    'u_r10_train', 'u_r5_train', 'u_r3_train', 'u_r1_train', 'cp_fluc_train', 'Re_c_train', 'scaling_input_train'])\n",
    "train_dataset = train_dataset.shuffle(buffer_size=25)\n",
    "\n",
    "(u_r10_validation, u_r5_validation, u_r3_validation, u_r1_validation, cp_fluc_validation, Re_c_validation,\n",
    " scaling_input_validation, u_r10_test, u_r5_test, u_r3_test, u_r1_test, cp_fluc_test, Re_c_test, scaling_input_test) \\\n",
    "    = validation_test_dataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Configure Network and Training Parameters\n",
    "\n",
    "Load network related parameters from the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    \"\"\"parse arguments\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Cascade Net\")\n",
    "    parser.add_argument(\"--mode\", type=str, default=\"PYNATIVE\", choices=[\"PYNATIVE\"],\n",
    "                        help=\"This case only supports PYNATIVE_MODE\")\n",
    "    parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                        help=\"The target device to run, support 'Ascend', 'GPU'\")\n",
    "    parser.add_argument(\"--device_id\", type=int, default=0,\n",
    "                        help=\"ID of the target device\")\n",
    "    parser.add_argument(\"--config_file_path\", type=str,\n",
    "                        default=\"./config/Cascade-Net.yaml\")\n",
    "    result_args = parser.parse_known_args()[0]\n",
    "    return result_args\n",
    "\n",
    "input_args = parse_args()\n",
    "context.set_context(mode=context.PYNATIVE_MODE,\n",
    "                    device_target=input_args.device_target,\n",
    "                    device_id=input_args.device_id)\n",
    "config = load_yaml_config(input_args.config_file_path)\n",
    "\n",
    "data_config = config[\"data\"]\n",
    "critic_config = config[\"critic\"]\n",
    "generator_config = config[\"generator\"]\n",
    "summary_config = config[\"summary\"]\n",
    "\n",
    "data_dir = data_config[\"root_dir\"]\n",
    "latent_z_n_channel = data_config[\"latent_z_n_channel\"]\n",
    "batch_size = data_config[\"batch_size\"]\n",
    "n_channel_p = data_config[\"n_channel_p\"]\n",
    "n_channel_u = data_config[\"n_channel_u\"]\n",
    "column_names = data_config[\"column_names\"]\n",
    "lambda_GP = critic_config[\"lambda_GP\"]\n",
    "critic_model_lr = critic_config[\"critic_model_lr\"]\n",
    "n_critic = critic_config[\"n_critic\"]\n",
    "lambda_L2_u = generator_config[\"lambda_L2_u\"]\n",
    "lambda_L2_gradu = generator_config[\"lambda_L2_gradu\"]\n",
    "gan_model_lr = generator_config[\"gan_model_lr\"]\n",
    "plot_n = summary_config[\"plot_n\"]\n",
    "n_imgs = summary_config[\"n_imgs\"]\n",
    "merge_n_imgs = summary_config[\"merge_n_imgs\"]\n",
    "sample_interval = summary_config[\"sample_interval\"]\n",
    "epochs = summary_config[\"epochs\"]\n",
    "dxy = summary_config[\"dxy\"]\n",
    "losslog = []\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "sample_num_train = loader.__len__()\n",
    "sample_num_val = u_r1_validation.shape[0]\n",
    "sample_num_test = u_r1_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Building\n",
    "\n",
    "Build sub networks at various scales using the initial_model(), including sub generators and sub discriminators at four scales, and use them in the initialization of generator and discriminator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization of generator and discriminator\n",
    "(merge_model, g_model_I, d_model_I, g_model_II, d_model_II,\n",
    " g_model_III, d_model_III, g_model_IV, d_model_IV) = init_sub_model(n_channel_p, n_channel_u)\n",
    "critic_model = DefineCompoundCritic(n_channel_p, n_channel_u, batch_size,\n",
    "                                    d_model_I, d_model_II, d_model_III, d_model_IV)\n",
    "critic_model.update_parameters_name('critic')\n",
    "gan_model = DefineCompoundGan(n_channel_p, n_channel_u, merge_model,\n",
    "                              g_model_I, g_model_II, g_model_III, g_model_IV)\n",
    "gan_model.update_parameters_name('generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Function\n",
    "\n",
    "The main part code of model training, including the definition of the loss function, the forward calculation process of the discriminator and generator, and the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "wasserstein_loss = WassersteinLoss()\n",
    "mae_loss = nn.MAELoss(reduction='none')\n",
    "grad_loss = GradLoss(dxy)\n",
    "\n",
    "# forward calculation of discriminator\n",
    "def d_forward_fn(input):\n",
    "    g_input = [input[4], input[5], input[6], input[7]]\n",
    "    g_pred = gan_model(g_input)\n",
    "    d_input = [input[0], input[1], input[2], input[3], g_pred[4], g_pred[0], g_pred[1], g_pred[2], g_pred[3]]\n",
    "\n",
    "    d_pred = critic_model(d_input)\n",
    "    loss_wass = wasserstein_loss(ops.stack(d_pred[:8]), ops.Concat(axis=0)(\n",
    "        [-ops.ones_like(ops.stack(d_pred[:4])), ops.ones_like(ops.stack(d_pred[4:8]))]))\n",
    "    loss_gradp = ops.stack([d_pred[12](), d_pred[13](), d_pred[14](), d_pred[15]()])\n",
    "    loss = ops.sum(1 * loss_wass) + ops.sum(lambda_GP * loss_gradp)\n",
    "    loss_list = ms.numpy.concatenate((ms.numpy.expand_dims(loss, 0), loss_wass, loss_gradp), axis=0).asnumpy()\n",
    "    return loss, loss_list\n",
    "\n",
    "# forward calculation of generator\n",
    "def g_forward_fn(true, input):\n",
    "    g_input = [input[4], input[5], input[6], input[7]]\n",
    "    g_pred = gan_model(g_input)\n",
    "    d_input = [input[0], input[1], input[2], input[3], g_pred[4], g_pred[0], g_pred[1], g_pred[2], g_pred[3]]\n",
    "    d_pred = critic_model(d_input)\n",
    "\n",
    "    loss_wass = wasserstein_loss(ops.stack(d_pred[4:8]), -ops.ones_like(ops.stack(d_pred[4:8])))\n",
    "    loss_mae = mae_loss(ops.stack(g_pred[:4]), ops.stack(true[:4]))\n",
    "    loss_mae = ops.mean(loss_mae, axis=(1, 2, 3, 4))\n",
    "    loss_grad = grad_loss(ops.stack(g_pred[5:9]), ops.stack(true[:4]))\n",
    "    loss = (ops.sum(1 * loss_wass) + ops.sum(lambda_L2_u * loss_mae) + ops.sum(lambda_L2_gradu * loss_grad))\n",
    "    loss_list = ms.numpy.concatenate((ms.numpy.expand_dims(loss, 0), loss_wass, loss_mae, loss_grad), axis=0).asnumpy()\n",
    "    return loss, loss_list\n",
    "\n",
    "# training process\n",
    "def train_step(g_real_data, input):\n",
    "    for _ in range(n_critic):\n",
    "        (_, d_loss_list), d_grads = d_grad_fn(input)\n",
    "        d_optimizer(d_grads)\n",
    "        ave_g_loss_train_ncritic.append(d_loss_list)\n",
    "    ave_d_loss_train.append(np.mean(ave_g_loss_train_ncritic, axis=0))\n",
    "    (_, g_loss_list), g_grads = g_grad_fn(g_real_data, input)\n",
    "    g_optimizer(g_grads)\n",
    "    ave_g_loss_train.append(g_loss_list)\n",
    "\n",
    "# evaluation process\n",
    "def define_evaluation(u_r10, u_r5, u_r3, u_r1, cp, Re, scaling_input, latent_z, idx):\n",
    "    _, batch_d_loss = d_forward_fn(\n",
    "        [Tensor(u_r10[idx, :, :, :]), Tensor(u_r5[idx, :, :, :]), Tensor(u_r3[idx, :, :, :]), Tensor(u_r1[idx, :, :, :]),\n",
    "         Tensor(cp[idx, :, :, :]), Tensor(Re[idx, :]), Tensor(scaling_input[idx, :]), latent_z])\n",
    "    _, batch_g_loss = g_forward_fn(\n",
    "        [Tensor(u_r10[idx, :, :, :]), Tensor(u_r5[idx, :, :, :]), Tensor(u_r3[idx, :, :, :]), Tensor(u_r1[idx, :, :, :])],\n",
    "        [Tensor(u_r10[idx, :, :, :]), Tensor(u_r5[idx, :, :, :]), Tensor(u_r3[idx, :, :, :]), Tensor(u_r1[idx, :, :, :]),\n",
    "         Tensor(cp[idx, :, :, :]), Tensor(Re[idx, :]), Tensor(scaling_input[idx, :]), latent_z])\n",
    "    return batch_d_loss, batch_g_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "Apply the RMSProp optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "d_optimizer = nn.RMSProp(critic_model.trainable_params(), learning_rate=critic_model_lr)\n",
    "d_grad_fn = ms.value_and_grad(d_forward_fn, None, d_optimizer.parameters, has_aux=True)\n",
    "g_optimizer = nn.RMSProp(gan_model.trainable_params(), learning_rate=gan_model_lr)\n",
    "g_grad_fn = ms.value_and_grad(g_forward_fn, None, g_optimizer.parameters, has_aux=True)\n",
    "d_optimizer.update_parameters_name('optim_d')\n",
    "g_optimizer.update_parameters_name('optim_g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Visualization of training result and prediction result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.linspace(-1, 1, 128)\n",
    "x1 = np.linspace(-1, 1, 128)\n",
    "xx, yy = np.meshgrid(x1, y1)  # xy_data.new\n",
    "\n",
    "def sample_images(epoch):  # plot_n = 5\n",
    "    idx_train = np.random.randint(0, sample_num_train, plot_n)\n",
    "    idx_test = np.random.randint(0, sample_num_test, plot_n)\n",
    "    latent_z_input_train = Tensor(np.random.normal(0, 1, (\n",
    "        plot_n, latent_z_n_channel, merge_n_imgs, merge_n_imgs)), dtype=ms.float32)\n",
    "    latent_z_input_test = Tensor(np.random.normal(0, 1, (\n",
    "        plot_n, latent_z_n_channel, merge_n_imgs, merge_n_imgs)), dtype=ms.float32)\n",
    "    gen_u_I, gen_u_II, gen_u_III, gen_u_IV, _, _, _, _, _, _ = gan_model([\n",
    "        Tensor(loader[idx_train][4]),\n",
    "        Tensor(loader[idx_train][5]),\n",
    "        Tensor(loader[idx_train][6]),\n",
    "        latent_z_input_train])\n",
    "    gen_u_I_, gen_u_II_, gen_u_III_, gen_u_IV_, _, _, _, _, _, _ = gan_model([\n",
    "        Tensor(cp_fluc_test[idx_test, :, :, :]),\n",
    "        Tensor(Re_c_test[idx_test, :]),\n",
    "        Tensor(scaling_input_test[idx_test, :]),\n",
    "        latent_z_input_test])\n",
    "    del _\n",
    "    plot_images(epoch,\n",
    "                velocity_part=0,\n",
    "                gen_u_I=gen_u_I,\n",
    "                gen_u_II=gen_u_II,\n",
    "                gen_u_III=gen_u_III,\n",
    "                gen_u_IV=gen_u_IV,\n",
    "                sel_index=idx_train,\n",
    "                is_train=True)\n",
    "    plot_images(epoch,\n",
    "                velocity_part=1,\n",
    "                gen_u_I=gen_u_I,\n",
    "                gen_u_II=gen_u_II,\n",
    "                gen_u_III=gen_u_III,\n",
    "                gen_u_IV=gen_u_IV,\n",
    "                sel_index=idx_train,\n",
    "                is_train=True)\n",
    "    plot_images(epoch,\n",
    "                velocity_part=0,\n",
    "                gen_u_I=gen_u_I_,\n",
    "                gen_u_II=gen_u_II_,\n",
    "                gen_u_III=gen_u_III_,\n",
    "                gen_u_IV=gen_u_IV_,\n",
    "                sel_index=idx_test,\n",
    "                is_test=True)\n",
    "    plot_images(epoch,\n",
    "                velocity_part=1,\n",
    "                gen_u_I=gen_u_I_,\n",
    "                gen_u_II=gen_u_II_,\n",
    "                gen_u_III=gen_u_III_,\n",
    "                gen_u_IV=gen_u_IV_,\n",
    "                sel_index=idx_test, is_test=True)\n",
    "\n",
    "def plot_images(epoch, velocity_part, gen_u_I, gen_u_II, gen_u_III, gen_u_IV, sel_index, is_train=False, is_test=False):\n",
    "    # including ur,vr,gradur, and grad_vr\n",
    "    # velocity_part = 0 for u and 1 for v\n",
    "    velocity_name = list(['u', 'v'])\n",
    "    _, ax = plt.subplots(5, 8, figsize=(20, 16))\n",
    "    if is_train:\n",
    "        index = 0\n",
    "        for i in range(0, 5, 1):\n",
    "            ax[i, 0].contourf(xx, yy,\n",
    "                              gen_u_I[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 0].axis('off')\n",
    "            ax[i, 1].contourf(xx, yy, loader[sel_index[index]][0][velocity_part, :, :], cmap='coolwarm')\n",
    "            ax[i, 1].axis('off')\n",
    "            ax[i, 2].contourf(xx, yy,\n",
    "                              gen_u_II[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 2].axis('off')\n",
    "            ax[i, 3].contourf(xx, yy, loader[sel_index[index]][1][velocity_part, :, :], cmap='coolwarm')\n",
    "            ax[i, 3].axis('off')\n",
    "            ax[i, 4].contourf(xx, yy,\n",
    "                              gen_u_III[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 4].axis('off')\n",
    "            ax[i, 5].contourf(xx, yy, loader[sel_index[index]][2][velocity_part, :, :], cmap='coolwarm')\n",
    "            ax[i, 5].axis('off')\n",
    "            ax[i, 6].contourf(xx, yy,\n",
    "                              gen_u_IV[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 6].axis('off')\n",
    "            ax[i, 7].contourf(xx, yy, loader[sel_index[index]][3][velocity_part, :, :], cmap='coolwarm')\n",
    "            ax[i, 7].axis('off')\n",
    "\n",
    "            index = index + 1\n",
    "        plt.savefig('training_results/images/imgs_train_' + velocity_name[velocity_part] + '%d.png' % (\n",
    "            epoch))\n",
    "        plt.close()\n",
    "    if is_test:\n",
    "        index = 0\n",
    "        for i in range(0, 5, 1):\n",
    "            ax[i, 0].contourf(xx, yy,\n",
    "                              gen_u_I[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 0].axis('off')\n",
    "            ax[i, 1].contourf(xx, yy,\n",
    "                              u_r10_test[sel_index[index], velocity_part, :, :].reshape(n_imgs, n_imgs),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 1].axis('off')\n",
    "            ax[i, 2].contourf(xx, yy,\n",
    "                              gen_u_II[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 2].axis('off')\n",
    "            ax[i, 3].contourf(xx, yy,\n",
    "                              u_r5_test[sel_index[index], velocity_part, :, :].reshape(n_imgs, n_imgs),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 3].axis('off')\n",
    "            ax[i, 4].contourf(xx, yy,\n",
    "                              gen_u_III[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 4].axis('off')\n",
    "            ax[i, 5].contourf(xx, yy,\n",
    "                              u_r3_test[sel_index[index], velocity_part, :, :].reshape(n_imgs, n_imgs),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 5].axis('off')\n",
    "            ax[i, 6].contourf(xx, yy,\n",
    "                              gen_u_IV[index, velocity_part, :, :].reshape(n_imgs, n_imgs).asnumpy(),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 6].axis('off')\n",
    "            ax[i, 7].contourf(xx, yy,\n",
    "                              u_r1_test[sel_index[index], velocity_part, :, :].reshape(n_imgs, n_imgs),\n",
    "                              cmap='coolwarm')\n",
    "            ax[i, 7].axis('off')\n",
    "            index = index + 1\n",
    "        plt.savefig('training_results/images/imgs_test_' + velocity_name[velocity_part] + '%d.png' % (\n",
    "            epoch))\n",
    "        plt.close()\n",
    "    plt.cla()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Predict is performed during model training. The accuracy on the training dataset, validation dataset, and test dataset, and the visualization of the predict results are saved every sample_interval epochs. Simultaneously, users could save checkpoint file every sample_interval steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:06<00:00, 33.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[1 min] [D:38.91, 0.99, 0.96, 0.96, 0.97] [G:17944.48, 0.01, 0.11, 0.00, -0.10] [L2_train:0.46022, 0.48499, 0.47539, 0.43928] [L2_val:0.39236, 0.37077, 0.35429, 0.25296] [L2_test:0.40963, 0.35561, 0.35587, 0.25345]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1/2 [00:31<00:31, 31.67s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m [u_r10_train, u_r5_train, u_r3_train, u_r1_train,\n\u001b[0;32m     15\u001b[0m              cp_fluc_train, Re_c_train, scaling_input_train, latent_z_input_train]\n\u001b[0;32m     16\u001b[0m     g_true \u001b[38;5;241m=\u001b[39m [u_r10_train, u_r5_train, u_r3_train, u_r1_train]\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m ave_d_loss_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ave_d_loss_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m ave_g_loss_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ave_g_loss_train, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 38\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(g_real_data, input)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(g_real_data, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_critic):\n\u001b[1;32m---> 38\u001b[0m         (_, d_loss_list), d_grads \u001b[38;5;241m=\u001b[39m \u001b[43md_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m         d_optimizer(d_grads)\n\u001b[0;32m     40\u001b[0m         ave_g_loss_train_ncritic\u001b[38;5;241m.\u001b[39mappend(d_loss_list)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:625\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_grad\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad_(fn_, weights)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\common\\api.py:121\u001b[0m, in \u001b[0;36m_wrap_func.<locals>.wrapper\u001b[1;34m(*arg, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39marg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 121\u001b[0m     results \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39marg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_python_data(results)\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:600\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;129m@_wrap_func\u001b[39m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_grad\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 600\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pynative_forward_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mgrad(fn, grad_, weights, grad_position, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    602\u001b[0m     out \u001b[38;5;241m=\u001b[39m _pynative_executor()\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:650\u001b[0m, in \u001b[0;36m_Grad._pynative_forward_run\u001b[1;34m(self, fn, grad, weights, args, kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m _pynative_executor\u001b[38;5;241m.\u001b[39mset_grad_flag(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    649\u001b[0m _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[1;32m--> 650\u001b[0m outputs \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m    651\u001b[0m _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(fn, outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:561\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.aux_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maux_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 561\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen has_aux is True, origin fn requires more than one outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m, in \u001b[0;36md_forward_fn\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m      9\u001b[0m g_pred \u001b[38;5;241m=\u001b[39m gan_model(g_input)\n\u001b[0;32m     10\u001b[0m d_input \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m3\u001b[39m], g_pred[\u001b[38;5;241m4\u001b[39m], g_pred[\u001b[38;5;241m0\u001b[39m], g_pred[\u001b[38;5;241m1\u001b[39m], g_pred[\u001b[38;5;241m2\u001b[39m], g_pred[\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m---> 12\u001b[0m d_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcritic_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m loss_wass \u001b[38;5;241m=\u001b[39m wasserstein_loss(ops\u001b[38;5;241m.\u001b[39mstack(d_pred[:\u001b[38;5;241m8\u001b[39m]), ops\u001b[38;5;241m.\u001b[39mConcat(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)(\n\u001b[0;32m     14\u001b[0m     [\u001b[38;5;241m-\u001b[39mops\u001b[38;5;241m.\u001b[39mones_like(ops\u001b[38;5;241m.\u001b[39mstack(d_pred[:\u001b[38;5;241m4\u001b[39m])), ops\u001b[38;5;241m.\u001b[39mones_like(ops\u001b[38;5;241m.\u001b[39mstack(d_pred[\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m8\u001b[39m]))]))\n\u001b[0;32m     15\u001b[0m loss_gradp \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mstack([d_pred[\u001b[38;5;241m12\u001b[39m](), d_pred[\u001b[38;5;241m13\u001b[39m](), d_pred[\u001b[38;5;241m14\u001b[39m](), d_pred[\u001b[38;5;241m15\u001b[39m]()])\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\nn\\cell.py:702\u001b[0m, in \u001b[0;36mCell.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mnew_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    701\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_construct(args, kwargs)\n\u001b[1;32m--> 702\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mend_graph(\u001b[38;5;28mself\u001b[39m, output, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    704\u001b[0m     _pynative_executor\u001b[38;5;241m.\u001b[39mclear_res()\n",
      "File \u001b[1;32mD:\\PycharmProjects\\Cascade-Net_Code_mindspore\\venv\\lib\\site-packages\\mindspore\\common\\api.py:1215\u001b[0m, in \u001b[0;36m_PyNativeExecutor.end_graph\u001b[1;34m(self, obj, output, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mend_graph\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, output, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;124;03m    Clean resources after building forward and backward graph.\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;124;03m        None.\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "critic_model.set_train()\n",
    "gan_model.set_train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.perf_counter()\n",
    "    ave_d_loss_train = list()\n",
    "    ave_g_loss_train = list()\n",
    "    for _, (u_r10_train, u_r5_train, u_r3_train, u_r1_train, cp_fluc_train, Re_c_train, scaling_input_train) in (\n",
    "            enumerate(tqdm(train_dataset))):\n",
    "        ave_g_loss_train_ncritic = list()\n",
    "        latent_z_input_train = ops.normal(\n",
    "            (batch_size, latent_z_n_channel, merge_n_imgs, merge_n_imgs),\n",
    "            0, 1, )\n",
    "        input = [u_r10_train, u_r5_train, u_r3_train, u_r1_train,\n",
    "                 cp_fluc_train, Re_c_train, scaling_input_train, latent_z_input_train]\n",
    "        g_true = [u_r10_train, u_r5_train, u_r3_train, u_r1_train]\n",
    "        train_step(g_true, input)\n",
    "    ave_d_loss_train = np.mean(ave_d_loss_train, axis=0)\n",
    "    ave_g_loss_train = np.mean(ave_g_loss_train, axis=0)\n",
    "\n",
    "    # predict the d_loss and g_loss in validation\n",
    "    idx_ = np.random.randint(0, sample_num_val, batch_size)\n",
    "    latent_z_input_validation = Tensor(np.random.normal(0, 1, (\n",
    "        batch_size, latent_z_n_channel, merge_n_imgs, merge_n_imgs)), dtype=ms.float32)\n",
    "    batch_d_loss_val, batch_g_loss_val = define_evaluation(\n",
    "        u_r10_validation, u_r5_validation, u_r3_validation, u_r1_validation,\n",
    "        cp_fluc_validation, Re_c_validation, scaling_input_validation, latent_z_input_validation, idx_)\n",
    "\n",
    "    # predict the d_loss and g_loss in testing\n",
    "    idx__ = np.random.randint(0, sample_num_test, batch_size)\n",
    "    latent_z_input_test = Tensor(np.random.normal(0, 1, (\n",
    "        batch_size, latent_z_n_channel, merge_n_imgs, merge_n_imgs)), dtype=ms.float32)\n",
    "    batch_d_loss_test, batch_g_loss_test = define_evaluation(\n",
    "        u_r10_test, u_r5_test, u_r3_test, u_r1_test,\n",
    "        cp_fluc_test, Re_c_test, scaling_input_test, latent_z_input_test, idx__)\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    time_consumption = (end - start) // 60  # covert s. to min.\n",
    "    # Plot the progress and index[0] is the weighted loss\n",
    "    print(\n",
    "        \"%d:[%d min] [D:%.2f, %.2f, %.2f, %.2f, %.2f] [G:%.2f, %.2f, %.2f, %.2f, %.2f] \"\n",
    "        \"[L2_train:%.5f, %.5f, %.5f, %.5f] [L2_val:%.5f, %.5f, %.5f, %.5f] [L2_test:%.5f, %.5f, %.5f, %.5f]\" %\n",
    "        (epoch, time_consumption,\n",
    "         ave_d_loss_train[0],\n",
    "         ave_d_loss_train[1] + ave_d_loss_train[5] + ave_d_loss_train[9],\n",
    "         ave_d_loss_train[2] + ave_d_loss_train[6] + ave_d_loss_train[10],\n",
    "         ave_d_loss_train[3] + ave_d_loss_train[7] + ave_d_loss_train[11],\n",
    "         ave_d_loss_train[4] + ave_d_loss_train[8] + ave_d_loss_train[12],\n",
    "         ave_g_loss_train[0],\n",
    "         ave_g_loss_train[1], ave_g_loss_train[2], ave_g_loss_train[3], ave_g_loss_train[4],\n",
    "         ave_g_loss_train[5], ave_g_loss_train[6], ave_g_loss_train[7], ave_g_loss_train[8],\n",
    "         batch_g_loss_val[5], batch_g_loss_val[6], batch_g_loss_val[7], batch_g_loss_val[8],\n",
    "         batch_g_loss_test[5], batch_g_loss_test[6], batch_g_loss_test[7], batch_g_loss_test[8]))\n",
    "\n",
    "    losslog.append(np.concatenate(  # 60\n",
    "        ([ave_d_loss_train[i] for i in range(13)],  # 13\n",
    "         [batch_d_loss_val[i] for i in range(13)],  # 13\n",
    "         [batch_d_loss_test[i] for i in range(13)],  # 13\n",
    "         [ave_g_loss_train[i] for i in range(13)],  # 13\n",
    "         [batch_g_loss_val[i] for i in range(13)],  # 13\n",
    "         [batch_g_loss_test[i] for i in range(13)])))  # 13\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % sample_interval == 0:\n",
    "        sample_images(epoch)\n",
    "        ms.save_checkpoint(gan_model, \"training_results/model/gan_%d\" % epoch + \".ckpt\")\n",
    "        ms.save_checkpoint(critic_model, \"training_results/model/critic_%d\" % epoch + \".ckpt\")\n",
    "        np.savetxt('training_results/loss/loss.txt', losslog, fmt='%.4f')\n",
    "    del ave_d_loss_train, ave_g_loss_train, batch_d_loss_val, batch_g_loss_val, batch_d_loss_test, batch_g_loss_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **Result visualization**\n",
    "\n",
    "The predicted and true values of the velocity fields at various scales in the U and V directions generated by the network in the train dataset under 300 epochs of training are shown in the following figure:\n",
    "\n",
    "<img src=\"images/train_u.png\" style=\"zoom:25%\" align=\"center\"> <img src=\"images/train_v.png\" style=\"zoom:25%\" align=\"center\">\n",
    "\n",
    "The predicted and true values of the velocity fields at various scales in the U and V directions generated by the network in the test dataset under 300 epochs of training are shown in the following figure:\n",
    "\n",
    "<img src=\"images/test_u.png\" style=\"zoom:25%\" align=\"center\"> <img src=\"images/test_v.png\" style=\"zoom:25%\" align=\"center\">\n",
    "\n",
    "Here, each row give one sample. And one sample give eight figures, each group has two figures including generated flow field at left and the true flow field at right, and the scale decreases from left to right among each group.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9063439a3781aed32d6b0dd4804a0c8b51ecec7893a0f31b99846bc91ef39eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
