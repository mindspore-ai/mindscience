{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda19887",
   "metadata": {},
   "source": [
    "# 运动边界非定常流场预测\n",
    "\n",
    "## 环境安装\n",
    "\n",
    "本案例要求 **MindSpore >= 2.0.0** 版本以调用如下接口: *mindspore.jit, mindspore.jit_class, mindspore.data_sink*。具体请查看[MindSpore安装](https://www.mindspore.cn/install)。\n",
    "\n",
    "此外，你需要安装 **MindFlow >=0.1.0** 版本。如果当前环境还没有安装，请按照下列方式选择后端和版本进行安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4216556",
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b427c68",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "CFD作为一种通过数值方法来模拟和解析流体运动的重要工具，极大便利了流体力学相关问题的科学研究，在设计、优化和研究领域提供准确的数据和见解并发挥着重要作用。流体力学中具有代表性和研究价值的一类问题是：对具有移动边界的非定常流场系统进行模拟，以分析运动结构在流场中的受力情况，可在工程上优化设计运动结构，为航空航天飞行器以及航海器等外形优化提供方案策略。高精确度计算流体力学技术（CFD）能够准确模拟流场演化和结构受力情况，但是高精度动边界问题需要大量网格，导致硬件消耗和计算时间成本巨大，另外对动态网格的构造也格外耗时。\n",
    "\n",
    "面对CFD在应用于复杂问题时计算量巨大并且计算精度有待提高等问题，智能流体力学领域给出了行之有效的解决方案，深度学习可以通过深度神经网络可学习流动工况与流场之间的演化关系，快速实现流场高精度预测与重构。为了高效解决动边界流场重构问题，提出了一种混合深度神经网络(HDNN)，以实现非定常动边界流场重构，并基于此实现流场快速预测。\n",
    "\n",
    "## 问题描述\n",
    "\n",
    "流场相关尺寸如图所示，其中 $Y = Asin(2πft)$ 代表圆柱体在竖直方向做简谐运动的运动表达式，A为振幅，f为频率；D代表圆柱体直径；矩形边界代表计算域。均匀来流流过运动圆柱体时，在流体与固体相互作用的影响下，会在圆柱体后方形成一系列复杂的流动现象，如边界层分离、交替出现的卡门涡街等，并演化为物理量随时间周期性变化的非均匀流场。\n",
    "\n",
    "## 技术路径\n",
    "\n",
    "MindFlow求解该问题的具体流程如下：\n",
    "\n",
    "1.根据CFD数值模拟结果创建数据集。\n",
    "\n",
    "2.使用MindSpore深度学习框架构建模型。\n",
    "\n",
    "3.定义优化器与损失函数。\n",
    "\n",
    "4.使用MindSpore的即时编译等加速模型训练。\n",
    "\n",
    "5.利用训练好的模型进行推理和可视化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af9033",
   "metadata": {},
   "source": [
    "![p1.png](./images/p1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39552eaf",
   "metadata": {},
   "source": [
    "## 模型架构\n",
    "\n",
    "HDNN的基本框架由卷积神经网络（CNN）、卷积长短期记忆网络（ConvLSTM）和反卷积神经网络（DeCNN）组成。CNN降低了时间序列流场的维数，实现特征提取；ConvLSTM学习低维时空特征并进行预测；最后，DeCNN实现预测流场的重建\n",
    "\n",
    "+ 输入层：输入历史流场\n",
    "+ 卷积层：通过多层CNN对输入流场进行降维，提取高维时空流动特征\n",
    "+ 记忆层：通过ConvLSTM学习低维空间流场时空特征的演变，预测下一时刻\n",
    "+ 反卷积输出层：将预测流场的低维特征恢复到高维空间，通过多层DeCNN重构下一时刻的瞬态流场，并输出可视化预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5c41",
   "metadata": {},
   "source": [
    "![HDNN.jpg](./images/HDNN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f317de2",
   "metadata": {},
   "source": [
    "## 训练数据集\n",
    "\n",
    "数据集由非定常二维圆柱绕流的数值仿真流场数据构建的多维矩阵流场快照矩阵构建而成\n",
    "\n",
    "+ 二维圆柱在均匀来流流场中做一维简谐振动，振动频率f（Hz）分别为1.25、1.43、1.67、2.00，振幅比A/D分别为0.5、0.6、0.7、0.8。两两组合总共16组运动状态\n",
    "+ 数据集为某一状态（f,A/D）下的非定常流场序列数据\n",
    "+ 每张流场快照包含3个通道，代表流场的压强分布信息、水平速度信息、竖直速度信息，多维矩阵流场快照矩阵尺寸为：T×C×H×W(C为通道数，H，W分别为快照的高和宽）\n",
    "+ 数据集：[下载位置](https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/move_boundary_hdnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2847f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, data_sink, jit\n",
    "from mindflow.utils import load_yaml_config\n",
    "\n",
    "from src import my_train_dataset, AEnet, save_loss_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7406dd",
   "metadata": {},
   "source": [
    "## 训练环境\n",
    "\n",
    "+ 训练采用Mindspore框架的静态图模式（GRAPH）\n",
    "+ 在CPU、GPU或Ascend进行训练（单卡）\n",
    "+ 训练数据集中的圆柱振动频率f（Hz）分别为1.25、1.43、1.67，振幅比A/D分别为0.5、0.6、0.7。两两组合总共9组运动状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c6d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ca2c",
   "metadata": {},
   "source": [
    "## 训练超参数\n",
    "\n",
    "从config中获得模型、数据、优化器的超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3ba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"cylinder around flow ROM\")\n",
    "\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False, choices=[True, False],\n",
    "                    help=\"Whether to save intermediate compilation graphs\")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./summary\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'GPU','Ascend'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0, help=\"ID of the target device\")\n",
    "parser.add_argument(\"--data_list\", type=list, default=['0.00', '0.25', '0.35', '0.45'],\n",
    "                    help=\"The type for training, [0.00, 0.25, 0.35, 0.45] for multi_state training /n\"\n",
    "                         \"[0.25],....,[0.45] for single_state training\")\n",
    "parser.add_argument('--batch_size', type=int, default=16, help=\"mini batch_size\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs, save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target, device_id=args.device_id)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "config = load_yaml_config(args.config_file_path)\n",
    "data_params = config[\"data\"]\n",
    "model_params = config[\"model\"]\n",
    "optimizer_params = config[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53d5ec",
   "metadata": {},
   "source": [
    "## 训练过程文件保存路径\n",
    "\n",
    "将训练好的模型文件每隔一定训练次数保存在文件夹下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa53aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = optimizer_params[\"ckpt_dir\"]\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505908fc",
   "metadata": {},
   "source": [
    "## 构建神经网络及优化器\n",
    "\n",
    "神经网络的卷积层共有12层，ConvLSTM有1层，反卷积共有12层\n",
    "\n",
    "损失函数使用均方误差（Mean Squared Error）损失函数，优化器使用Adam（Adaptive Moment Estimation）优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e0f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AEnet(in_channels=model_params[\"in_channels\"],\n",
    "              num_layers=model_params[\"num_layers\"],\n",
    "              kernel_size=model_params[\"kernel_size\"],\n",
    "              num_convlstm_layers=model_params[\"num_convlstm_layers\"])\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = nn.Adam(params=model.trainable_params(), learning_rate=optimizer_params[\"lr\"])\n",
    "if use_ascend:\n",
    "    from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(model, 'O1')\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d32ff9",
   "metadata": {},
   "source": [
    "## 训练框架\n",
    "\n",
    "定义前向传播函数forward_fn，将预测值和真值比较得到损失值loss并返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e34bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(inputs, velocity, label):\n",
    "    pred = model(inputs, velocity)\n",
    "    loss = loss_func(pred, label)\n",
    "\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf783",
   "metadata": {},
   "source": [
    "## 数据集加载\n",
    "\n",
    "给my_train_dataset传参，得到训练数据集和验证数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe1356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"==================Load data sample ===================\")\n",
    "dataset_train, dataset_eval = my_train_dataset(data_params[\"data_dir\"],\n",
    "                                               data_params[\"time_steps\"],\n",
    "                                               args.data_list)\n",
    "print(f\"======================End Load========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7331a",
   "metadata": {},
   "source": [
    "## 数据下沉及模型训练\n",
    "\n",
    "定义train_step和eval_step并使用data_sink加速训练，输出训练过程的损失值和使用时间，并每隔一定训练轮次保存模型文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c63294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"====================Start train=======================\")\n",
    "@jit\n",
    "def train_step(inputs, velocity, label):\n",
    "    loss, grads = grad_fn(inputs, velocity, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        if all_finite(grads):\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    loss = ops.depend(loss, optimizer(grads))\n",
    "    return loss\n",
    "\n",
    "@jit\n",
    "def eval_step(inputs, velocity, label):\n",
    "    loss = forward_fn(inputs, velocity, label)\n",
    "    loss = ops.sqrt(loss)\n",
    "    return loss\n",
    "\n",
    "train_sink_process = data_sink(train_step, dataset_train, sink_size=1)\n",
    "eval_sink_process = data_sink(eval_step, dataset_eval, sink_size=1)\n",
    "train_data_size, eval_data_size = dataset_train.get_dataset_size(), dataset_eval.get_dataset_size()\n",
    "\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = []\n",
    "\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    train_losses = 0\n",
    "    valid_losses = 0\n",
    "\n",
    "    local_time_beg = time.time()\n",
    "    model.set_train(True)\n",
    "\n",
    "    for _ in range(train_data_size):\n",
    "        step_train_loss = ops.squeeze(train_sink_process(), axis=())\n",
    "        step_train_loss = step_train_loss.asnumpy().item()\n",
    "        train_losses += step_train_loss\n",
    "\n",
    "    train_loss = train_losses / train_data_size\n",
    "    avg_train_losses.append(train_loss)\n",
    "\n",
    "    print(f\"epoch: {epoch}, epoch average train loss: {train_loss :.6f}, \"\n",
    "          f\"epoch time: {(time.time() - local_time_beg):.2f}s\")\n",
    "\n",
    "    if epoch % optimizer_params[\"eval_interval\"] == 0:\n",
    "        print(f\"=================Start Evaluation=====================\")\n",
    "\n",
    "        eval_time_beg = time.time()\n",
    "        model.set_train(False)\n",
    "        for _ in range(eval_data_size):\n",
    "            step_eval_loss = ops.squeeze(eval_sink_process(), axis=())\n",
    "            step_eval_loss = step_eval_loss.asnumpy().item()\n",
    "            valid_losses += step_eval_loss\n",
    "\n",
    "        valid_loss = valid_losses / eval_data_size\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        print(f\"epoch: {epoch}, epoch average valid loss: {valid_loss :.6f}, \"\n",
    "              f\"epoch time: {(time.time() - eval_time_beg):.2f}s\")\n",
    "        print(f\"==================End Evaluation======================\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(model, f\"{ckpt_dir}/net_{epoch}.ckpt\")\n",
    "\n",
    "save_loss_curve(avg_train_losses, 'Epoch', 'avg_train_losses', 'Avg_train_losses Curve', 'Avg_train_losses.png')\n",
    "save_loss_curve(avg_valid_losses, 'Epoch', 'avg_valid_losses', 'Avg_valid_losses Curve', 'Avg_valid_losses.png')\n",
    "\n",
    "print(f\"=====================End train========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1262b22",
   "metadata": {},
   "source": [
    "## 设置训练条件 传参\n",
    "\n",
    "当运行该文件时，通过参数解析器传入必要参数，开始训练，并打印进程和设备id，以及训练总时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505f3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Process ID:\", os.getpid())\n",
    "    print(f\"device id: {args.device_id}\")\n",
    "    start_time = time.time()\n",
    "    train()\n",
    "    print(f\"End-to-End total time: {(time.time() - start_time):.2f}s\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bcfdbdd",
   "metadata": {},
   "source": [
    "Process ID: 2801010\n",
    "device id: 0\n",
    "==================Load data sample ===================\n",
    "======================End Load========================\n",
    "\n",
    "====================Start train=======================\n",
    "epoch: 1, epoch average train loss: 0.069304, epoch time: 51.62s\n",
    "epoch: 2, epoch average train loss: 0.011798, epoch time: 24.36s\n",
    "epoch: 3, epoch average train loss: 0.010980, epoch time: 16.55s\n",
    "epoch: 4, epoch average train loss: 0.010644, epoch time: 24.14s\n",
    "epoch: 5, epoch average train loss: 0.010608, epoch time: 22.38s\n",
    "epoch: 6, epoch average train loss: 0.010324, epoch time: 21.66s\n",
    "epoch: 7, epoch average train loss: 0.010152, epoch time: 32.79s\n",
    "epoch: 8, epoch average train loss: 0.009601, epoch time: 24.62s\n",
    "epoch: 9, epoch average train loss: 0.009147, epoch time: 22.19s\n",
    "epoch: 10, epoch average train loss: 0.008809, epoch time: 19.52s\n",
    "=================Start Evaluation=====================\n",
    "epoch: 10, epoch average valid loss: 0.098904, epoch time: 12.86s\n",
    "==================End Evaluation======================\n",
    "\n",
    "...\n",
    "\n",
    "epoch: 91, epoch average train loss: 0.000274, epoch time: 28.49s\n",
    "epoch: 92, epoch average train loss: 0.000280, epoch time: 27.60s\n",
    "epoch: 93, epoch average train loss: 0.000231, epoch time: 20.99s\n",
    "epoch: 94, epoch average train loss: 0.000297, epoch time: 18.26s\n",
    "epoch: 95, epoch average train loss: 0.000417, epoch time: 21.94s\n",
    "epoch: 96, epoch average train loss: 0.000228, epoch time: 27.41s\n",
    "epoch: 97, epoch average train loss: 0.000232, epoch time: 18.61s\n",
    "epoch: 98, epoch average train loss: 0.000250, epoch time: 26.81s\n",
    "epoch: 99, epoch average train loss: 0.000217, epoch time: 21.16s\n",
    "epoch: 100, epoch average train loss: 0.000244, epoch time: 18.09s\n",
    "=================Start Evaluation=====================\n",
    "epoch: 100, epoch average valid loss: 0.015813, epoch time: 15.06s\n",
    "==================End Evaluation======================\n",
    "=====================End train========================\n",
    "End-to-End total time: 2575.05s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aac646",
   "metadata": {},
   "source": [
    "## 预测流场结果可视化\n",
    "\n",
    "+ 动边界流场预测通过执行eval.py开始预测，分为两种预测方式：单步流场预测（infer_mode为\"one\"）和一个振动周期内连续流场预测（infer_mode为\"cycle\"）；单步流场预测仅预测下一时刻一个时间步长的流场，连续流场预测则持续预测一个完整周期的流场\n",
    "+ 下图为训练完备的HDNN模型实现对振动频率为1.43Hz，振幅为0.8（振幅比泛化状态）下非定常动边界单步预测和一完整周期预测的结果（展示压强场、水平速度场和竖直速度场）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229664b",
   "metadata": {},
   "source": [
    "![pred_single_step_puv.jpg](./images/pred_single_step_puv.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e40259",
   "metadata": {},
   "source": [
    "![pred_cycle_puv.jpg](./images/pred_cycle_puv.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
