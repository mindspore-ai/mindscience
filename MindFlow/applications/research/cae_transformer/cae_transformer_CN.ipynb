{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAE-Transformer流场预测模型\n",
    "\n",
    "## 环境安装\n",
    "\n",
    "本案例要求 **MindSpore >= 2.0.0** 版本以调用如下接口: *mindspore.jit, mindspore.jit_class, mindspore.data_sink*。具体请查看[MindSpore安装](https://www.mindspore.cn/install)。\n",
    "\n",
    "此外，你需要安装 **MindFlow >=0.1.0** 版本。如果当前环境还没有安装，请按照下列方式选择后端和版本进行安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "### 背景介绍\n",
    "\n",
    "降阶模型可有效降低使用CFD方法的设计成本和周期。对于复杂的可压缩流动，使用POD等线性方法进行流场降维，需要大量的模态才能保证流场重建的精度，而采用非线性降维方法能够有效减少所需模态数。卷积自编码器(CAE)是一种由编码器和解码器组成的神经网络，能够实现数据降维和重构，可看作是POD方法的非线性拓展。采用CAE进行流场数据的非线性降维，同时使用Transformer进行流场状态的时间演化。对于非定常可压缩流动，“CAE-Transformer”降阶模型能够在使用较少自由变量数与较短计算周期的前提下获得较高的重构和预测精度。\n",
    "\n",
    "### 模型架构\n",
    "\n",
    "CAE-Transformer的基本框架主要基于[论文1](https://doi.org/10.13700/j.bh.1001-5965.2022.0085)和[论文2](https://doi.org/10.1609/aaai.v35i12.17325)，其由CAE和Transformer组成，其中CAE中的编码器降低时间序列流场的维数，实现特征提取，Transformer学习低维时空特征并进行预测，CAE中的解码器实现流场重建：\n",
    "\n",
    "+ 输入：输入一段时间的流场；\n",
    "\n",
    "+ 压缩：通过CAE的编码器对流场进行降维，提取高维时空流动特征；\n",
    "\n",
    "+ 演化：通过Transformer学习低维空间流场时空特征的演变，预测下一时刻；\n",
    "\n",
    "+ 重建：通过CAE的解码器将预测的流场低维特征恢复到高维空间；\n",
    "\n",
    "+ 输出：输出对下一时刻瞬态流场的预测结果。\n",
    "\n",
    "![CAE-Transformer1.png](./images/cae_transformer_structure.png)\n",
    "\n",
    "### 数据集\n",
    "\n",
    "来源：二维圆柱绕流数值仿真流场数据，由北京航空航天大学航空科学与工程学院于剑副教授团队提供。\n",
    "\n",
    "生成方法：二维圆柱绕流的数据集计算状态与建立方法见论文[Ma Z, Yu J, Xiao R. Data-driven reduced order modeling for parametrized time-dependent flow problems[J]. Physics of Fluids, 2022, 34(7).](https://pubs.aip.org/aip/pof/article/34/7/075109/2847227/Data-driven-reduced-order-modeling-for)\n",
    "\n",
    "数据说明：数据集针对10个雷诺数的圆柱绕流进行了数值模拟，每个雷诺数下的流场数据包含401个时间步，每个时间步的流场数据为256*256的二维流场，每个变量的数据类型为float32，数据集总大小为约1.96GB。\n",
    "数据集下载链接:\n",
    "\n",
    "[2D_cylinder_flow.npy](https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/cae-transformer/2D_cylinder_flow.npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备工作\n",
    "\n",
    "导入训练所需函数库，其中src文件夹包括数据集处理函数、网络模型和训练loss可视化函数。\n",
    "\n",
    "训练默认采用Mindspore框架的动态图模式(PYNATIVE)，在GPU(默认)或Ascend进行训练(单卡)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, jit, data_sink\n",
    "from src import create_caetransformer_dataset, plot_train_loss, CAE_Informer\n",
    "from eval import cae_transformer_prediction, cae_transformer_eval\n",
    "\n",
    "np.random.seed(0)\n",
    "set_seed(0)\n",
    "parser = argparse.ArgumentParser(description=\"CAE-Transformer for 2D cylinder flow\")\n",
    "parser.add_argument(\n",
    "    \"--mode\",\n",
    "    type=str,\n",
    "    default=\"PYNATIVE\",\n",
    "    choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_graphs\",\n",
    "    type=bool,\n",
    "    default=False,\n",
    "    choices=[True, False],\n",
    "    help=\"Whether to save intermediate compilation graphs\",\n",
    ")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./graphs\")\n",
    "parser.add_argument(\n",
    "    \"--device_target\",\n",
    "    type=str,\n",
    "    default=\"GPU\",\n",
    "    choices=[\"GPU\", \"Ascend\"],\n",
    "    help=\"The target device to run, support 'Ascend', 'GPU'\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--device_id\", type=int, default=0, help=\"ID of the target device\"\n",
    ")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "args = parser.parse_args()\n",
    "context.set_context(mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs,\n",
    "                    save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target,\n",
    "                    device_id=args.device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取参数\n",
    "\n",
    "从`config.yaml`文件里导入相应的数据集、CAE模型和优化器的参数配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = \"./config.yaml\"\n",
    "# prepare params\n",
    "with open(config_file_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "data_params = config[\"data\"]\n",
    "model_params = config[\"cae_transformer\"]\n",
    "optimizer_params = config[\"optimizer\"]\n",
    "\n",
    "# prepare summary file\n",
    "summary_dir = optimizer_params[\"summary_dir\"]\n",
    "ckpt_dir = os.path.join(summary_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型初始化\n",
    "\n",
    "根据config.yaml中的配置，初始化模型，包括CAE和Transformer网络。使用MSELoss损失函数和Adam优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "model = CAE_Informer(**model_params)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = nn.AdamWeightDecay(\n",
    "    model.trainable_params(),\n",
    "    optimizer_params[\"lr\"],\n",
    "    weight_decay=optimizer_params[\"weight_decay\"],\n",
    ")\n",
    "\n",
    "def forward_fn(data, label):\n",
    "    logits = model(data)\n",
    "    loss = loss_fn(logits, label)\n",
    "    return loss\n",
    "\n",
    "time_now = time.time()\n",
    "model.set_train()\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)\n",
    "\n",
    "@jit\n",
    "def train_step(data, label):\n",
    "    loss, grads = grad_fn(data, label)\n",
    "    loss = ops.depend(loss, optimizer(grads))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集构建\n",
    "\n",
    "根据config.yaml中读取的数据路径构建CAE-Transforme数据集，并做数据下沉。\n",
    "\n",
    "数据集链接为: [2D_cylinder_flow.npy](https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/cae-transformer/2D_cylinder_flow.npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "dataset, eval_data = create_caetransformer_dataset(\n",
    "    data_params['data_path'],\n",
    "    data_params[\"batch_size\"],\n",
    "    data_params[\"seq_len\"],\n",
    "    data_params[\"pred_len\"],\n",
    ")\n",
    "\n",
    "# data sink\n",
    "sink_process = data_sink(train_step, dataset, sink_size=1)\n",
    "train_data_size = dataset.get_dataset_size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "使用MindSpore >= 2.0.0的版本，可以使用函数式编程范式训练神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Start cae transformer train=====================\n",
      "epoch: 1 train loss: 1.6767721 epoch time: 20.05s\n",
      "epoch: 2 train loss: 1.3125554 epoch time: 11.43s\n",
      "epoch: 3 train loss: 1.0195727 epoch time: 11.36s\n",
      "epoch: 4 train loss: 0.78560066 epoch time: 11.45s\n",
      "epoch: 6 train loss: 0.45436704 epoch time: 11.63s\n",
      "epoch: 7 train loss: 0.34071732 epoch time: 11.28s\n",
      "epoch: 8 train loss: 0.25292587 epoch time: 11.78s\n",
      "epoch: 9 train loss: 0.18576089 epoch time: 11.50s\n",
      "epoch: 10 train loss: 0.13489997 epoch time: 11.36s\n",
      "=================Start cae-transformer evaluation=====================\n",
      "eval loss: 0.1344970128662193\n",
      "===================End transformer evaluation====================\n",
      "epoch: 11 train loss: 0.09680262 epoch time: 11.57s\n",
      "epoch: 12 train loss: 0.06859333 epoch time: 11.35s\n",
      "epoch: 13 train loss: 0.04796055 epoch time: 11.57s\n",
      "epoch: 14 train loss: 0.03306444 epoch time: 11.67s\n",
      "epoch: 15 train loss: 0.022457568 epoch time: 11.77s\n",
      "epoch: 16 train loss: 0.0150149 epoch time: 10.95s\n",
      "epoch: 17 train loss: 0.009872699 epoch time: 11.57s\n",
      "epoch: 18 train loss: 0.0063783163 epoch time: 11.32s\n",
      "epoch: 19 train loss: 0.004044703 epoch time: 11.27s\n",
      "epoch: 20 train loss: 0.0025148452 epoch time: 11.24s\n",
      "=================Start cae-transformer evaluation=====================\n",
      "eval loss: 0.0025034045636145035\n",
      "===================End transformer evaluation====================\n",
      "epoch: 21 train loss: 0.0015316431 epoch time: 10.97s\n",
      "epoch: 22 train loss: 0.00091252924 epoch time: 10.95s\n",
      "epoch: 23 train loss: 0.0005314545 epoch time: 11.07s\n",
      "epoch: 24 train loss: 0.00030210355 epoch time: 11.14s\n",
      "epoch: 25 train loss: 0.0001675461 epoch time: 11.27s\n",
      "epoch: 26 train loss: 9.066265e-05 epoch time: 11.31s\n",
      "epoch: 27 train loss: 4.7929763e-05 epoch time: 11.05s\n",
      "epoch: 28 train loss: 2.4869172e-05 epoch time: 11.33s\n",
      "epoch: 29 train loss: 1.2829796e-05 epoch time: 11.46s\n",
      "epoch: 30 train loss: 6.614075e-06 epoch time: 11.41s\n",
      "=================Start cae-transformer evaluation=====================\n",
      "eval loss: 6.312924863346573e-06\n",
      "===================End transformer evaluation====================\n",
      "====================End cae transformer train=======================\n",
      "=================Start cae-transformer prediction=====================\n",
      "===================End transformer prediction====================\n"
     ]
    }
   ],
   "source": [
    "print(f\"====================Start cae transformer train=======================\")\n",
    "train_loss = []\n",
    "model.set_train()\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    local_time_beg = time.time()\n",
    "    epoch_train_loss = 0\n",
    "    for _ in range(train_data_size):\n",
    "        epoch_train_loss = ops.squeeze(sink_process(), axis=())\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(f\"epoch: {epoch} train loss: {epoch_train_loss} epoch time: {time.time() - local_time_beg:.2f}s\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(model, f\"{ckpt_dir}/model_{epoch}.ckpt\")\n",
    "    if epoch % optimizer_params[\"eval_interval\"] == 0:\n",
    "        model.set_train(False)\n",
    "        cae_transformer_eval(model, eval_data, data_params)\n",
    "        model.set_train(True)\n",
    "print(f\"=====================End cae transformer train========================\")\n",
    "cae_transformer_prediction(args)\n",
    "plot_train_loss(train_loss, summary_dir, optimizer_params[\"epochs\"], \"cae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测结果\n",
    "\n",
    "下为CAE-Transformer和真实值的对比：\n",
    "\n",
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/prediction_result.gif\" title=\"prediction_result\" width=\"500\"/>\n",
    "</figure>\n",
    "\n",
    "结果展现了流场中不同位置的速度随时间的变化情况。预测结果与真实值的平均相对误差为6.3e-06。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
