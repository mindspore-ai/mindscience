{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 环境安装\n",
    "\n",
    "本案例要求 MindSpore >= 2.2.12 版本以调用如下接口: mindspore.nn, mindspore.jit_class, mindspore.data_sink,mindflow_ascend具体请查看MindSpore安装。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from mindspore import nn, Tensor, context, ops, jit, set_seed, data_sink, save_checkpoint\n",
    "from mindspore import dtype as mstype\n",
    "from mindspore.nn import L1Loss\n",
    "from mindflow.common import get_warmup_cosine_annealing_lr\n",
    "from mindflow.utils import load_yaml_config, print_log\n",
    "from src.utils import Trainer, init_model, check_file_path, count_params, plot_image, plot_image_first\n",
    "from src.dataset import init_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确保代码在Ascend设备上运行，并检查是否成功设置了设备目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"train\"\"\"\n",
    "    set_seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    context.set_context(mode=context.GRAPH_MODE,\n",
    "                        save_graphs=False,\n",
    "                        device_target=\"Ascend\",\n",
    "                        device_id=0)\n",
    "    use_ascend = context.get_context(\"device_target\") == \"Ascend\"\n",
    "    print(use_ascend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    config = load_yaml_config(\"./configs/combined_methods.yaml\")\n",
    "    data_params = config[\"data\"]\n",
    "    model_params = config[\"model\"]\n",
    "    optimizer_params = config[\"optimizer\"]\n",
    "    summary_params = config[\"summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    train_dataset, test_dataset, means, stds = init_dataset(data_params)\n",
    "    print('train_dataset', train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    if use_ascend:\n",
    "        from mindspore.amp import DynamicLossScaler, all_finite, auto_mixed_precision\n",
    "        loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "        compute_dtype = mstype.float16\n",
    "        model = init_model(\"unet2d\", data_params, model_params, compute_dtype=compute_dtype)\n",
    "        auto_mixed_precision(model, optimizer_params[\"amp_level\"][\"unet2d\"])\n",
    "    else:\n",
    "        context.set_context(enable_graph_kernel=False)\n",
    "        loss_scaler = None\n",
    "        compute_dtype = mstype.float32\n",
    "        model = init_model(\"unet2d\", data_params, model_params, compute_dtype=compute_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "损失函数与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    loss_fn = L1Loss()\n",
    "    summary_dir = os.path.join(summary_params[\"summary_dir\"], \"Exp_datadriven\", \"unet2d\")\n",
    "    ckpt_dir = os.path.join(summary_dir, \"ckpt_dir\")\n",
    "    check_file_path(ckpt_dir)\n",
    "    check_file_path(os.path.join(ckpt_dir, 'img'))\n",
    "    print_log('model parameter count:', count_params(model.trainable_params()))\n",
    "    print_log(\n",
    "        f'learning rate: {optimizer_params[\"lr\"][\"unet2d\"]}, '\n",
    "        f'T_in: {data_params[\"T_in\"]}, T_out: {data_params[\"T_out\"]}')\n",
    "    steps_per_epoch = train_dataset.get_dataset_size()\n",
    "\n",
    "    lr = get_warmup_cosine_annealing_lr(optimizer_params[\"lr\"][\"unet2d\"], steps_per_epoch,\n",
    "                                        optimizer_params[\"epochs\"], optimizer_params[\"warm_up_epochs\"])\n",
    "    optimizer = nn.AdamWeightDecay(model.trainable_params(),\n",
    "                                   learning_rate=Tensor(lr),\n",
    "                                   weight_decay=optimizer_params[\"weight_decay\"])\n",
    "    trainer = Trainer(model, data_params, loss_fn, means, stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "执行模型的前向传播并返回损失值，计算前向函数 forward_fn 的输出（即损失）相对于模型参数的梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def forward_fn(inputs, labels):\n",
    "        loss, _, _, _, _, _, _ = trainer.get_loss(inputs, labels)\n",
    "        if use_ascend:\n",
    "            loss = loss_scaler.scale(loss)\n",
    "        return loss\n",
    "\n",
    "    grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "用于通过反向传播算法优化模型以最小化损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    @jit\n",
    "    def train_step(inputs, labels):\n",
    "        loss, grads = grad_fn(inputs, labels)\n",
    "        if use_ascend:\n",
    "            loss = loss_scaler.unscale(loss)\n",
    "            if all_finite(grads):\n",
    "                grads = loss_scaler.unscale(grads)\n",
    "        loss_new = ops.depend(loss, optimizer(grads))\n",
    "        return loss_new, inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "get_loss 方法负责执行模型的前向传播，计算预测输出与真实标签之间的差异，并据此计算损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def test_step(inputs, labels):\n",
    "        return trainer.get_loss(inputs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "获取训练数据集的大小，即训练数据集中的批次总数。这个值用于确定训练循环中的迭代次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    train_size = train_dataset.get_dataset_size()\n",
    "    test_size = test_dataset.get_dataset_size()\n",
    "    train_sink = data_sink(train_step, train_dataset, sink_size=1)\n",
    "    test_sink = data_sink(test_step, test_dataset, sink_size=1)\n",
    "    test_interval = summary_params[\"test_interval\"]\n",
    "    save_ckpt_interval = summary_params[\"save_ckpt_interval\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "        time_beg = time.time()\n",
    "        train_l1 = 0.0\n",
    "        model.set_train()\n",
    "        for _ in range(1, train_size + 1):\n",
    "            loss_train, inputs, labels = train_sink()\n",
    "            train_l1 += loss_train.asnumpy()\n",
    "        train_loss = train_l1 / train_size\n",
    "        if epoch >= trainer.hatch_extent:\n",
    "            _, loss1, loss2, _, _, _, _ = trainer.get_loss(inputs, labels)\n",
    "            trainer.renew_loss_lists(loss1, loss2)\n",
    "            trainer.adjust_hatchs()\n",
    "        print_log(\n",
    "            f\"epoch: {epoch}, \"\n",
    "            f\"step time: {(time.time() - time_beg) / steps_per_epoch:>7f}, \"\n",
    "            f\"loss: {train_loss:>7f}\")\n",
    "\n",
    "        if epoch % test_interval == 0:\n",
    "            model.set_train(False)\n",
    "            test_l1 = 0.0\n",
    "            for _ in range(test_size):\n",
    "                loss_test, loss1, loss2, inputs, pred, labels, _ = test_sink()\n",
    "                test_l1 += loss_test.asnumpy()\n",
    "            test_loss = test_l1 / test_size\n",
    "            print_log(\n",
    "                f\"epoch: {epoch}, \"\n",
    "                f\"step time: {(time.time() - time_beg) / steps_per_epoch:>7f}, \"\n",
    "                f\"loss: {test_loss:>7f}\")\n",
    "\n",
    "            plot_image(inputs, 0)\n",
    "            plot_image_first(inputs, 0)\n",
    "            plot_image(pred, 0)\n",
    "            plot_image(labels, 0)\n",
    "\n",
    "        if epoch % save_ckpt_interval == 0:\n",
    "            save_checkpoint(model, ckpt_file_name=os.path.join(ckpt_dir, 'model_data.ckpt'))\n",
    "\n",
    "    print(\"Training Finished!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch: 1, step time: 7.204487, loss: 30.159577\n",
    "epoch: 2, step time: 0.050003, loss: 16.109943\n",
    "epoch: 3, step time: 23.267395, loss: 14.340383\n",
    "epoch: 4, step time: 0.059521, loss: 11.345826\n",
    "epoch: 5, step time: 0.059669, loss: 8.936566\n",
    "epoch: 6, step time: 0.060332, loss: 7.976031\n",
    "epoch: 7, step time: 0.059778, loss: 7.400826\n",
    "epoch: 8, step time: 0.057766, loss: 7.384783\n",
    "epoch: 9, step time: 0.058148, loss: 6.274703\n",
    "epoch: 10, step time: 0.058232, loss: 7.144862\n",
    "epoch: 10, step time: 0.930520, loss: 0.105834\n",
    "epoch: 11, step time: 0.056829, loss: 6.353740\n",
    "epoch: 12, step time: 0.055501, loss: 7.061435\n",
    "epoch: 13, step time: 0.056191, loss: 5.679731\n",
    "epoch: 14, step time: 0.056355, loss: 6.572665\n",
    "epoch: 15, step time: 0.056130, loss: 5.429127\n",
    "epoch: 16, step time: 0.056419, loss: 5.232585\n",
    "epoch: 17, step time: 0.056626, loss: 4.742438\n",
    "epoch: 18, step time: 0.056156, loss: 5.042458\n",
    "epoch: 19, step time: 0.056799, loss: 4.441929\n",
    "epoch: 20, step time: 0.055955, loss: 4.645259\n",
    "epoch: 20, step time: 0.061364, loss: 0.061257\n",
    "epoch: 21, step time: 0.061526, loss: 4.051717\n",
    "epoch: 22, step time: 0.057296, loss: 4.084571\n",
    "epoch: 23, step time: 0.056526, loss: 3.812290\n",
    "epoch: 24, step time: 0.056620, loss: 4.036302\n",
    "epoch: 25, step time: 0.056961, loss: 4.224667\n",
    "epoch: 26, step time: 0.056612, loss: 3.680945\n",
    "epoch: 27, step time: 0.056421, loss: 3.704518\n",
    "epoch: 28, step time: 0.056409, loss: 3.288220\n",
    "epoch: 29, step time: 0.056580, loss: 3.349201\n",
    "epoch: 30, step time: 0.056552, loss: 4.562499\n",
    "epoch: 30, step time: 0.062123, loss: 0.056036\n",
    "epoch: 31, step time: 0.058193, loss: 5.577391\n",
    "epoch: 32, step time: 0.056697, loss: 4.279838\n",
    "epoch: 33, step time: 0.055909, loss: 4.410978\n",
    "epoch: 34, step time: 0.056718, loss: 3.254215\n",
    "epoch: 35, step time: 0.056718, loss: 3.463492\n",
    "epoch: 36, step time: 0.056144, loss: 3.151621\n",
    "epoch: 37, step time: 0.056268, loss: 2.815826\n",
    "epoch: 38, step time: 0.055588, loss: 2.828014\n",
    "epoch: 39, step time: 0.060484, loss: 2.759430\n",
    "epoch: 40, step time: 0.056569, loss: 2.598535\n",
    "epoch: 40, step time: 0.062142, loss: 0.030793"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 结果展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot1](images/plot1.png)![plot2](images/plot2.png)\n",
    "第一张为输入温度场图片，第二张为训练预测图片"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
