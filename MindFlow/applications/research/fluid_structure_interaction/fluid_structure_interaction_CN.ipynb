{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda19887",
   "metadata": {},
   "source": [
    "\n",
    "# 基于深度神经网络的流固耦合系统建模方法\n",
    "\n",
    "## 环境安装\n",
    "\n",
    "本案例要求 **MindSpore >= 2.0.0** 版本以调用如下接口: *mindspore.jit, mindspore.jit_class, mindspore.data_sink*。具体请查看[MindSpore安装](https://www.mindspore.cn/install)。\n",
    "\n",
    "此外，你需要安装 **MindFlow >=0.1.0** 版本。如果当前环境还没有安装，请按照下列方式选择后端和版本进行安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da927ad",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "飞行器气动弹性问题是研究飞行器结构与气动力相互耦合关系，是一种典型的流固耦合（fluid-structure interaction, FSI）问题。高精确度计算流体力学技术（CFD）能够准确地模拟结构周围流场演化过程从而获得结构受力情况,但是数量巨大的网格导致计算成本极高。许多研究者尝试使用数据驱动的方法构建流场演化模型，实现较高精度流场的快速预测，从而提高流固耦合系统模拟效率。近年来迅速发展的深度神经网络技术依赖于其强大的非线性学习能力以及深度特征捕捉能力，在流场建模问题中已经取得了诸多成功应用。其中流场重构通过构建几何形状和流动工况至空间点处的流场信息之间的映射模型，实现不同流场的快速预测，因其能快速给出当前流场状态而备受关注。\n",
    "\n",
    "为了高效解决流固耦合问题的流场重构，本文将神经网络模型与计算结构动力学方程耦合，实现了流固耦合系统的建模，进一步改进神经网络结构，优化数据结构，从而获得更高精度的流场预测结果，实现更准确的流固耦合响应预测。\n",
    "\n",
    "## 问题描述\n",
    "\n",
    "传统的流固耦合数值仿真框架由计算流体力学求解器和计算固体力学求解器两部分组成，两个求解器分别在流体域和固体域求解下一时刻流体和结构的状态，并在交界面进行信息传递作为下一步计算的输入，耦合过程如下图所示。本文提出的基于深度神经网络的流固耦合建模框架仍然采用相同的策略，该框架使用深度神经网络代替CFD求解器来预测流场演化，结构响应仍由CSD求解器计算得到，结构位移和流场表面压力在深度神经网络和计算固体力学求解器之间传递。\n",
    "\n",
    "## 技术路径\n",
    "\n",
    "MindFlow求解该问题的具体流程如下：\n",
    "\n",
    "1.根据CFD数值模拟结果创建数据集。\n",
    "\n",
    "2.使用MindSpore深度学习框架构建模型。\n",
    "\n",
    "3.定义优化器与损失函数。\n",
    "\n",
    "4.使用MindSpore的即时编译等加速模型训练。\n",
    "\n",
    "5.利用训练好的模型进行推理和可视化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af9033",
   "metadata": {},
   "source": [
    "![p1.png](./images/p1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39552eaf",
   "metadata": {},
   "source": [
    "## 模型架构\n",
    "\n",
    "HDNN的基本框架由卷积神经网络（CNN）、卷积长短期记忆网络（ConvLSTM）和反卷积神经网络（DeCNN）组成。CNN降低了时间序列流场的维数，实现特征提取；ConvLSTM学习低维时空特征并进行预测；最后，DeCNN实现预测流场的重建\n",
    "\n",
    "+ 输入层：当前流场状态和边界条件；\n",
    "+ 卷积层：捕获流场的空间特征并降低维数，使用低维流场特征预测流场演化可以提高计算效率；\n",
    "+ LSTM层：根据捕获的当前时刻流场特征和结构运动条件预测下一时刻的流场特征；\n",
    "+ 反卷积输出层：将预测流场的低维特征恢复到高维空间，通过多层DeCNN重构下一时刻的瞬态流场，并输出可视化预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5c41",
   "metadata": {},
   "source": [
    "![HDNN.jpg](./images/HDNN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f317de2",
   "metadata": {},
   "source": [
    "## 训练数据集\n",
    "\n",
    "数据集由非定常二维圆柱绕流的数值仿真流场数据构建的多维矩阵流场快照矩阵构建而成\n",
    "\n",
    "+ 流场中的运动结构（圆柱）在竖直方向做一维简谐运动。对二维圆柱流场物理建模、网格离散/划分并采用雷诺时均模拟方法求解控制方程获取流场信息。将流场物理量无量纲化，并在采样区域中放置网格采样点，获得用于训练和测试的样本集\n",
    "+ 每张流场快照包含3个通道，代表流场的压强分布信息、水平速度信息、竖直速度信息\n",
    "+ 数据集：[下载位置](https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/fluid_structure_interaction/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce12042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, data_sink, jit\n",
    "from mindflow.utils import load_yaml_config\n",
    "\n",
    "from src import generate_dataset, AEnet, save_loss_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7406dd",
   "metadata": {},
   "source": [
    "## 训练环境\n",
    "\n",
    "+ 训练采用Mindspore框架的静态图模式（GRAPH）\n",
    "+ 在CPU、GPU或Ascend进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c6d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ca2c",
   "metadata": {},
   "source": [
    "## 训练超参数\n",
    "\n",
    "从config中获得模型、数据、优化器的超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f20dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"cylinder around flow ROM\")\n",
    "\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False, choices=[True, False],\n",
    "                    help=\"Whether to save intermediate compilation graphs\")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./summary\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"Ascend\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'GPU','Ascend'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0, help=\"ID of the target device\")\n",
    "parser.add_argument(\"--data_list\", type=list, default=['5.0', '5.5', '6.0', '6.5'], help=\"The type for training\")\n",
    "parser.add_argument('--batch_size', type=int, default=32, help=\"batch size\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs, save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target, device_id=args.device_id)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "config = load_yaml_config(args.config_file_path)\n",
    "data_params = config[\"data\"]\n",
    "model_params = config[\"model\"]\n",
    "optimizer_params = config[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53d5ec",
   "metadata": {},
   "source": [
    "## 训练过程文件保存路径\n",
    "\n",
    "将训练好的模型文件每隔一定训练次数保存在文件夹下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa53aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = optimizer_params[\"ckpt_dir\"]\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505908fc",
   "metadata": {},
   "source": [
    "## 构建神经网络及优化器\n",
    "\n",
    "神经网络的卷积层共有12层，ConvLSTM有1层，反卷积共有12层\n",
    "\n",
    "损失函数使用均方误差（Mean Squared Error）损失函数，优化器使用Adam（Adaptive Moment Estimation）优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e0f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AEnet(in_channels=model_params[\"in_channels\"],\n",
    "              num_layers=model_params[\"num_layers\"],\n",
    "              kernel_size=model_params[\"kernel_size\"],\n",
    "              num_convlstm_layers=model_params[\"num_convlstm_layers\"])\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = nn.Adam(params=model.trainable_params(), learning_rate=optimizer_params[\"lr\"])\n",
    "if use_ascend:\n",
    "    from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(model, 'O1')\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d32ff9",
   "metadata": {},
   "source": [
    "## 训练框架\n",
    "\n",
    "定义前向传播函数forward_fn，将预测值和真值比较得到损失值loss并返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9864f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(inputs, velocity, ur, label):\n",
    "    pred = model(inputs, velocity, ur)\n",
    "    loss = loss_func(pred, label)\n",
    "\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf783",
   "metadata": {},
   "source": [
    "## 数据集加载\n",
    "\n",
    "给generate_dataset传参，得到训练数据集和验证数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe1356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"==================Load data sample ===================\")\n",
    "dataset_train, dataset_eval = generate_dataset(data_params[\"data_dir\"],\n",
    "                                               data_params[\"time_steps\"],\n",
    "                                               args.data_list)\n",
    "print(f\"======================End Load========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7331a",
   "metadata": {},
   "source": [
    "## 数据下沉及模型训练\n",
    "\n",
    "定义train_step和eval_step并使用data_sink加速训练，输出训练过程的损失值和使用时间，并每隔一定训练轮次保存模型文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e692f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"====================Start train=======================\")\n",
    "@jit\n",
    "def train_step(inputs, velocity, ur, label):\n",
    "    loss, grads = grad_fn(inputs, velocity, ur, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        if all_finite(grads):\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    loss = ops.depend(loss, optimizer(grads))\n",
    "    return loss\n",
    "\n",
    "@jit\n",
    "def eval_step(inputs, velocity, ur, label):\n",
    "    loss = forward_fn(inputs, velocity, ur, label)\n",
    "    loss = ops.sqrt(loss)\n",
    "    return loss\n",
    "\n",
    "train_sink_process = data_sink(train_step, dataset_train, sink_size=1)\n",
    "eval_sink_process = data_sink(eval_step, dataset_eval, sink_size=1)\n",
    "train_data_size, eval_data_size = dataset_train.get_dataset_size(), dataset_eval.get_dataset_size()\n",
    "\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = []\n",
    "\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    train_losses = 0\n",
    "    valid_losses = 0\n",
    "\n",
    "    local_time_beg = time.time()\n",
    "    model.set_train(True)\n",
    "\n",
    "    for _ in range(train_data_size):\n",
    "        step_train_loss = ops.squeeze(train_sink_process(), axis=())\n",
    "        step_train_loss = step_train_loss.asnumpy().item()\n",
    "        train_losses += step_train_loss\n",
    "\n",
    "    train_loss = train_losses / train_data_size\n",
    "    avg_train_losses.append(train_loss)\n",
    "\n",
    "    print(f\"epoch: {epoch}, epoch average train loss: {train_loss :.6f}, \"\n",
    "          f\"epoch time: {(time.time() - local_time_beg):.2f}s\")\n",
    "\n",
    "    if epoch % optimizer_params[\"eval_interval\"] == 0:\n",
    "        print(f\"=================Start Evaluation=====================\")\n",
    "\n",
    "        eval_time_beg = time.time()\n",
    "        model.set_train(False)\n",
    "        for _ in range(eval_data_size):\n",
    "            step_eval_loss = ops.squeeze(eval_sink_process(), axis=())\n",
    "            step_eval_loss = step_eval_loss.asnumpy().item()\n",
    "            valid_losses += step_eval_loss\n",
    "\n",
    "        valid_loss = valid_losses / eval_data_size\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        print(f\"epoch: {epoch}, epoch average valid loss: {valid_loss :.6f}, \"\n",
    "              f\"epoch time: {(time.time() - eval_time_beg):.2f}s\")\n",
    "        print(f\"==================End Evaluation======================\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(model, f\"{ckpt_dir}/net_{epoch}.ckpt\")\n",
    "\n",
    "save_loss_curve(avg_train_losses, 'Epoch', 'avg_train_losses', 'Avg_train_losses Curve', 'Avg_train_losses.png')\n",
    "save_loss_curve(avg_valid_losses, 'Epoch', 'avg_valid_losses', 'Avg_valid_losses Curve', 'Avg_valid_losses.png')\n",
    "\n",
    "print(f\"=====================End train========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1262b22",
   "metadata": {},
   "source": [
    "## 设置训练条件 传参\n",
    "\n",
    "当运行该文件时，通过参数解析器传入必要参数，开始训练，并打印进程和设备id，以及训练总时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26ff8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Process ID:\", os.getpid())\n",
    "    print(f\"device id: {args.device_id}\")\n",
    "    start_time = time.time()\n",
    "    train()\n",
    "    print(f\"End-to-End total time: {(time.time() - start_time):.2f}s\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bcfdbdd",
   "metadata": {},
   "source": [
    "Process ID: 529681\n",
    "device id: 0\n",
    "==================Load data sample ===================\n",
    "======================End Load========================\n",
    "\n",
    "====================Start train=======================\n",
    "epoch: 1, epoch average train loss: 0.092563, epoch time: 60.48s\n",
    "epoch: 2, epoch average train loss: 0.033426, epoch time: 39.88s\n",
    "epoch: 3, epoch average train loss: 0.009924, epoch time: 33.47s\n",
    "epoch: 4, epoch average train loss: 0.003757, epoch time: 34.95s\n",
    "epoch: 5, epoch average train loss: 0.002671, epoch time: 34.38s\n",
    "epoch: 6, epoch average train loss: 0.002416, epoch time: 38.55s\n",
    "epoch: 7, epoch average train loss: 0.001826, epoch time: 38.72s\n",
    "epoch: 8, epoch average train loss: 0.001770, epoch time: 35.42s\n",
    "epoch: 9, epoch average train loss: 0.001415, epoch time: 36.65s\n",
    "epoch: 10, epoch average train loss: 0.001385, epoch time: 35.20s\n",
    "=================Start Evaluation=====================\n",
    "epoch: 10, epoch average valid loss: 0.033140, epoch time: 10.51s\n",
    "==================End Evaluation======================\n",
    "\n",
    "...\n",
    "\n",
    "epoch: 191, epoch average train loss: 0.000208, epoch time: 38.77s\n",
    "epoch: 192, epoch average train loss: 0.000159, epoch time: 39.22s\n",
    "epoch: 193, epoch average train loss: 0.000320, epoch time: 38.57s\n",
    "epoch: 194, epoch average train loss: 0.000156, epoch time: 39.06s\n",
    "epoch: 195, epoch average train loss: 0.000164, epoch time: 39.48s\n",
    "epoch: 196, epoch average train loss: 0.000175, epoch time: 39.90s\n",
    "epoch: 197, epoch average train loss: 0.000210, epoch time: 38.63s\n",
    "epoch: 198, epoch average train loss: 0.000178, epoch time: 38.70s\n",
    "epoch: 199, epoch average train loss: 0.000246, epoch time: 34.93s\n",
    "epoch: 200, epoch average train loss: 0.000165, epoch time: 35.63s\n",
    "=================Start Evaluation=====================\n",
    "epoch: 200, epoch average valid loss: 0.011407, epoch time: 9.19s\n",
    "==================End Evaluation======================\n",
    "=====================End train========================\n",
    "End-to-End total time: 7694.45s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aac646",
   "metadata": {},
   "source": [
    "## 预测流场结果可视化\n",
    "\n",
    "+ 动边界流场预测通过执行eval.py开始预测，耦合模型可在仅给定初始流场状态和圆柱位置情况下，完成整个流固耦合演化过程的预测任务\n",
    "+ 下图为训练完备的HDNN模型实现对一个周期内不同时刻深度神经网络的流场预测状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e40259",
   "metadata": {},
   "source": [
    "![pred_cycle_puv.jpg](./images/pred_cycle_puv.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
