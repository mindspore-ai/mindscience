{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda19887",
   "metadata": {},
   "source": [
    "# CAE-LSTM Reduced Order Model\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "This notebook requires **MindSpore version >= 2.0.0** to support new APIs including: *mindspore.jit, mindspore.jit_class, mindspore.data_sink*. Please check [MindSpore Installation](https://www.mindspore.cn/install/en) for details.\n",
    "\n",
    "In addition, **MindFlow version >=0.1.0** is also required. If it has not been installed in your environment, please select the right version and hardware, then install it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc18076",
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39552eaf",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In order to effectively reduce the design cost and cycle time of using CFD methods, the reduced-order model (ROM) has gained wide attention in recent years. For complex compressible flows, using linear methods such as Proper Orthogonal Decomposition (POD) for flow field dimensionality reduction requires a large number of modes to ensure the reconstruction accuracy. It has been shown that the modes number can be effectively reduced by using nonlinear dimensionality reduction methods. Convolutional Autoencoder (CAE) is a kind of neural network composed of encoder and decoder, which can realize data dimensionality reduction and recon-struction, and can be regarded as a nonlinear extension of POD method. CAE is used for nonlinear dimension-ality reduction, and Long Short-Term Memory (LSTM) is used for time evolution. The CAE-LSTM can obtain high reconstruction and prediction accuracy on the premise of using less latents for unsteady compressible flows.\n",
    "\n",
    "## Framework of CAE-LSTM\n",
    "\n",
    "The CAE-LSTM reduced order model uses a CAE network to reduce the dimensionality of the flow field, extract the characteristics of the flow data, compress it into the hidden space of the encoder, and then use the LSTM network to perform coefficient time evolution on the free variables in the hidden space to obtain the free variables at other times of flow. Then, the decoder of the CAE network decodes the evolved free variables and reconstructs the flow field flow data at the corresponding time. The construction of the CAE-LSTM flow reduction model relies on the data reduction of the CAE network and the coefficient time evolution of the LSTM network. Compared with existing methods such as POD/DMD, using CAE networks for nonlinear dimensionality reduction of flow field data and LSTM networks for equation free evolution of free variables can achieve higher compression ratios and improve the efficiency of flow field prediction while ensuring the accuracy of the flow field reduction model.\n",
    "\n",
    "+ Input：Input the flow field for a period of time.\n",
    "+ Compression：Extract high-dimensional spatiotemporal flow characteristics by dimensionality reduction of the flow field using the encoder of CAE.\n",
    "+ Evolution：Learning the evolution of spatiotemporal characteristics of low dimensional spatial flow fields through LSTM and predicting the next moment.\n",
    "+ Reconstruction：Restore the predicted low-dimensional features of the flow field to high-dimensional space through the decoder of CAE.\n",
    "+ Output：Output the predicted results of the transient flow field at the next moment.\n",
    "\n",
    "The first step is to train the CAE network. After the training is completed, the CAE encoder is used to obtain the low dimensional features of the flow field. This low dimensional feature is used as the dataset of the LSTM network for LSTM network training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5c41",
   "metadata": {},
   "source": [
    "![CAE-LSTM.png](./images/cae_lstm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7406dd",
   "metadata": {},
   "source": [
    "## Training environment\n",
    "\n",
    "Import the required function library for training, where `src` includes dataset creation functions, network models and training loss visualization functions.\n",
    "\n",
    "You can choose different cases to run, i.e. `sod`, `shu_osher`, `riemann`, `kh` or `cylinder`, among which `sod` and `shu_osher` are one-dimension cases, and `riemann`, `kh` and `cylinder` are two-dimension cases. You can change the case name in the `case` of `parser.add_argument` to run the corresponding case. And if you use the command line to run network training, you can also write the case name after `--case` to run the corresponding case. Default `sod`.\n",
    "\n",
    "The static GRAPH of Mindspore framework is adopted for training. Training can be done on GPU (default) or Ascend (single card)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17230db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, jit, data_sink\n",
    "from mindflow.utils import load_yaml_config\n",
    "from src import create_cae_dataset, CaeNet1D, CaeNet2D, plot_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3ba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa53aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='CaeNet')\n",
    "parser.add_argument(\"--case\", type=str, default=\"sod\", choices=[\"sod\", \"shu_osher\", \"riemann\", \"kh\"],\n",
    "                    help=\"Which case to run, support 'sod', 'shu_osher', 'riemann', 'kh'\")\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False, choices=[True, False],\n",
    "                    help=\"Whether to save intermediate compilation graphs\")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./graphs\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'Ascend', 'GPU'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0, help=\"ID of the target device\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "context.set_context(case=args.case,\n",
    "                    mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs,\n",
    "                    save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target,\n",
    "                    device_id=args.device_id,\n",
    "                    config_file_path=args.config_file_path)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ca2c",
   "metadata": {},
   "source": [
    "## CAE training parameter settings\n",
    "\n",
    "Import corresponding parameter configurations for the dataset, CAE model, and optimizer from the config.yaml file according to the case chosen. As for the cylinder case, you should indicate the Reynolds number of the case to read the corresponding data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e0f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml_config(args.config_file_path)\n",
    "if args.case == 'sod' or args.case == 'shu_osher':\n",
    "    data_params = config[\"1D_cae_data\"]\n",
    "    model_params = config[\"1D_cae_model\"]\n",
    "    optimizer_params = config[\"1D_cae_optimizer\"]\n",
    "else:\n",
    "    data_params = config[\"2D_cae_data\"]\n",
    "    model_params = config[\"2D_cae_model\"]\n",
    "    optimizer_params = config[\"2D_cae_optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53d5ec",
   "metadata": {},
   "source": [
    "The default path for saving loss files during training is optimizer_params [\"summary_dir\"], the weight parameters are saved in the ckpt folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e34bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dir = optimizer_params[\"summary_dir\"]\n",
    "if not os.path.exists(summary_dir):\n",
    "    os.mkdir(summary_dir)\n",
    "ckpt_dir = os.path.join(summary_dir, 'ckpt')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505908fc",
   "metadata": {},
   "source": [
    "## Construct CAE neural network\n",
    "\n",
    "The CAE network consists of multiple layers of convolution and maximum pooling to form an encoder, and multiple layers of convolution and upsampling to form a decoder. Use MSELoss loss function and Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe1356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.case == 'sod' or args.case == 'shu_osher':\n",
    "    cae = CaeNet1D(model_params[\"data_dimension\"], model_params[\"conv_kernel_size\"],\n",
    "                   model_params[\"maxpool_kernel_size\"], model_params[\"maxpool_stride\"],\n",
    "                   model_params[\"encoder_channels\"], model_params[\"decoder_channels\"])\n",
    "else:\n",
    "    cae = CaeNet2D(model_params[\"data_dimension\"], model_params[\"conv_kernel_size\"],\n",
    "                   model_params[\"maxpool_kernel_size\"], model_params[\"maxpool_stride\"],\n",
    "                   model_params[\"encoder_channels\"], model_params[\"decoder_channels\"],\n",
    "                   model_params[\"channels_dense\"])\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "cae_opt = nn.Adam(cae.trainable_params(), optimizer_params[\"lr\"], weight_decay=optimizer_params[\"weight_decay\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea2da0",
   "metadata": {},
   "source": [
    "## CAE dataset\n",
    "\n",
    "Dataset download address: [data_driven/cae-lstm/dataset](https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/cae-lstm)\n",
    "\n",
    "After importing the dataset, perform data sinking settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb8487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cae_dataset, _ = create_cae_dataset(data_params[\"data_path\"], data_params[\"batch_size\"], data_params[\"multiple\"])\n",
    "\n",
    "sink_process = data_sink(train_step, cae_dataset, sink_size=1)\n",
    "train_data_size = cae_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771dfcdf",
   "metadata": {},
   "source": [
    "## CAE training\n",
    "\n",
    "Build forward_fn and train_step, start training the CAE network and visualize the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f16d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid:23104\n",
      "====================Start CaeNet train=======================\n",
      "epoch: 1 train loss: 0.00859989 epoch time: 3.23s\n",
      "epoch: 2 train loss: 0.00563688 epoch time: 0.52s\n",
      "epoch: 3 train loss: 0.00485115 epoch time: 0.53s\n",
      "epoch: 4 train loss: 0.00341164 epoch time: 0.62s\n",
      "epoch: 5 train loss: 0.00332990 epoch time: 0.57s\n",
      "...\n",
      "epoch: 4396 train loss: 3.69731242e-06 epoch time: 0.51s\n",
      "epoch: 4397 train loss: 2.65247831e-06 epoch time: 0.55s\n",
      "epoch: 4398 train loss: 1.14417275e-06 epoch time: 0.54s\n",
      "epoch: 4399 train loss: 4.97764995e-06 epoch time:0.52s\n",
      "epoch: 4400 train loss: 2.48092419e-06 epoch time: 0.55s\n",
      "====================End CaeNet train=======================\n"
     ]
    }
   ],
   "source": [
    "def forward_fn(data, label):\n",
    "    logits = cae(data)\n",
    "    loss = loss_fn(logits, label)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, cae_opt.parameters, has_aux=False)\n",
    "\n",
    "@jit\n",
    "def train_step(data, label):\n",
    "    loss, grads = grad_fn(data, label)\n",
    "    loss = ops.depend(loss, cae_opt(grads))\n",
    "    return loss\n",
    "\n",
    "print(f\"====================Start CaeNet train=======================\")\n",
    "train_loss = []\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    local_time_beg = time.time()\n",
    "    cae.set_train()\n",
    "    epoch_train_loss = 0\n",
    "    for _ in range(train_data_size):\n",
    "        epoch_train_loss = ops.squeeze(sink_process(), axis=())\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(f\"epoch: {epoch} train loss: {epoch_train_loss} epoch time: {time.time() - local_time_beg:.2f}s\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(cae, f\"{ckpt_dir}/cae_{epoch}.ckpt\")\n",
    "print(f\"=====================End CaeNet train========================\")\n",
    "plot_train_loss(train_loss, summary_dir, optimizer_params[\"epochs\"], \"cae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a43727",
   "metadata": {},
   "source": [
    "## CAE flow field reconstruction results\n",
    "\n",
    "After training the CAE network, run `cae_eval.py` to view the training results of CAE to determine whether to continue training the LSTM network\n",
    "\n",
    "The following figures show the real flow field, CAE flow field reconstruction results, and the error curves between them in the five cases. The first two flow field results show the variation in the flow field over time, while the third error curve shows the average error of the CAE reconstructed flow field and the real flow field label over time. The errors meeting the accuracy requirements for flow field reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816cf7c6",
   "metadata": {},
   "source": [
    "Sod shock tube:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c7619",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/sod_cae_reconstruction.gif\" title=\"sod_cae_reconstruction\" width=\"600\"/>\n",
    "    <img src=\"./images/sod_cae_error.png\" title=\"sod_cae_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60101d7",
   "metadata": {},
   "source": [
    "Shu_Osher problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08460b",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/shu_osher_cae_reconstruction.gif\" title=\"shu_osher_cae_reconstruction\" width=\"600\"/>\n",
    "    <img src=\"./images/shu_osher_cae_error.png\" title=\"shu_osher_cae_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3f1d1",
   "metadata": {},
   "source": [
    "Riemann problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b1a1e",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/riemann_cae_reconstruction.gif\" title=\"riemann_cae_reconstruction\" width=\"600\"/>\n",
    "    <img src=\"./images/riemann_cae_error.png\" title=\"riemann_cae_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cfad46",
   "metadata": {},
   "source": [
    "Kelvin-Helmholtz instability problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14111ad1",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/kh_cae_reconstruction.gif\" title=\"kh_cae_reconstruction\" width=\"600\"/>\n",
    "    <img src=\"./images/kh_cae_error.png\" title=\"kh_cae_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf2313",
   "metadata": {},
   "source": [
    "cylinder flow (Re = 200):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a01e17",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/cylinder_cae_reconstruction.gif\" title=\"cylinder_cae_reconstruction\" width=\"600\"/>\n",
    "    <img src=\"./images/cylinder_cae_error.png\" title=\"cylinder_cae_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e4826",
   "metadata": {},
   "source": [
    "## LSTM framework and training Settings\n",
    "\n",
    "The construction of LSTM network framework, training environment, and other related processing are similar to those of CAE network.\n",
    "\n",
    "Firstly, import the required function library for training, then import the LSTM network dataset setting parameters, LSTM model, and optimizer parameter settings. The default training loss save path is optimizer_params [\"summary_dir\"], the weight parameters are saved in the ckpt folder. The network consists of multiple LSTM layers and a full connection layer, using MSELoss loss function and Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbef106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, jit, data_sink\n",
    "from mindflow.utils import load_yaml_config\n",
    "from src import create_lstm_dataset, Lstm, plot_train_loss\n",
    "from cae_eval import cae_eval\n",
    "\n",
    "np.random.seed(0)\n",
    "set_seed(0)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Lstm')\n",
    "parser.add_argument(\"--case\", type=str, default=\"sod\", choices=[\"sod\", \"shu_osher\", \"riemann\", \"kh\"],\n",
    "                    help=\"Which case to run, support 'sod', 'shu_osher', 'riemann', 'kh'\")\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False, choices=[True, False],\n",
    "                    help=\"Whether to save intermediate compilation graphs\")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./graphs\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'Ascend', 'GPU'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0, help=\"ID of the target device\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "context.set_context(case=args.case,\n",
    "                    mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs,\n",
    "                    save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target,\n",
    "                    device_id=args.device_id,\n",
    "                    config_file_path=args.config_file_path)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "# prepare params\n",
    "config = load_yaml_config(args.config_file_path)\n",
    "if args.case == 'sod' or args.case == 'shu_osher':\n",
    "    data_params = config[\"1D_lstm_data\"]\n",
    "    model_params = config[\"1D_lstm_model\"]\n",
    "    optimizer_params = config[\"1D_lstm_optimizer\"]\n",
    "else:\n",
    "    data_params = config[\"1D_lstm_data\"]\n",
    "    model_params = config[\"1D_lstm_model\"]\n",
    "    optimizer_params = config[\"1D_lstm_optimizer\"]\n",
    "\n",
    "# prepare summary file\n",
    "summary_dir = optimizer_params[\"summary_dir\"]\n",
    "ckpt_dir = os.path.join(summary_dir, 'ckpt')\n",
    "\n",
    "# prepare model\n",
    "lstm = Lstm(model_params[\"latent_size\"], model_params[\"hidden_size\"], model_params[\"num_layers\"])\n",
    "loss_fn = nn.MSELoss()\n",
    "lstm_opt = nn.Adam(lstm.trainable_params(), optimizer_params[\"lr\"], weight_decay=optimizer_params[\"weight_decay\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a08fc",
   "metadata": {},
   "source": [
    "## LSTM dataset loading and processing\n",
    "\n",
    "The LSTM network dataset is obtained by the CAE encoder, and data sinking settings are performed after creating the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6e5aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "latent_true = cae_eval(args.config_file_path, args.case)\n",
    "lstm_dataset, _ = create_lstm_dataset(latent_true, data_params[\"batch_size\"], data_params[\"time_size\"],\n",
    "                                      data_params[\"latent_size\"], data_params[\"time_window\"],\n",
    "                                      data_params[\"gaussian_filter_sigma\"])\n",
    "\n",
    "# data sink\n",
    "sink_process = data_sink(train_step, lstm_dataset, sink_size=1)\n",
    "train_data_size = lstm_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab5ec56",
   "metadata": {},
   "source": [
    "## LSTM training\n",
    "\n",
    "Build forward_fn and train_step, start training the LSTM network and visualize the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89b97708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid:22152\n",
      "====================Start Lstm train=======================\n",
      "epoch: 1 train loss: 0.4425844 epoch time: 3.75s\n",
      "epoch: 2 train loss: 0.23611887 epoch time: 0.75s\n",
      "epoch: 3 train loss: 0.65945524 epoch time: 0.76s\n",
      "epoch: 4 train loss: 0.77271056 epoch time: 0.80s\n",
      "epoch: 5 train loss: 0.3535387 epoch time: 0.81s\n",
      "...\n",
      "epoch: 4396 train loss: 9.665465e-05 epoch time: 0.76s\n",
      "epoch: 4397 train loss: 5.5045904e-05 epoch time: 0.77s\n",
      "epoch: 4398 train loss: 0.00013155791 epoch time: 0.80s\n",
      "epoch: 4399 train loss: 0.0769522e-05 epoch time: 0.80s\n",
      "epoch: 4400 train loss: 0.0010389996 epoch time: 0.80s\n",
      "====================End Lstm train=======================\n"
     ]
    }
   ],
   "source": [
    "# Define forward function\n",
    "def forward_fn(data, label):\n",
    "    logits = lstm(data)\n",
    "    loss = loss_fn(logits, label)\n",
    "    return loss\n",
    "\n",
    "# Get gradient function\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, lstm_opt.parameters, has_aux=False)\n",
    "\n",
    "@jit\n",
    "def train_step(data, label):\n",
    "    loss, grads = grad_fn(data, label)\n",
    "    loss = ops.depend(loss, lstm_opt(grads))\n",
    "    return loss\n",
    "\n",
    "print(f\"====================Start Lstm train=======================\")\n",
    "train_loss = []\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    local_time_beg = time.time()\n",
    "    lstm.set_train()\n",
    "    epoch_train_loss = 0\n",
    "    for _ in range(train_data_size):\n",
    "        epoch_train_loss = ops.squeeze(sink_process(), axis=())\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(f\"epoch: {epoch} train loss: {epoch_train_loss} epoch time: {time.time() - local_time_beg:.2f}s\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(lstm, f\"{ckpt_dir}/lstm_{epoch}.ckpt\")\n",
    "print(f\"=====================End Lstm train========================\")\n",
    "plot_train_loss(train_loss, summary_dir, optimizer_params[\"epochs\"], \"lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aac646",
   "metadata": {},
   "source": [
    "## Visualization of predicted flow field results\n",
    "\n",
    "Run `cae_lstm_eval.py` to view the prediction results of the CAE-LSTM reduced order model\n",
    "\n",
    "The following figures show the actual flow field, the predicted results of the CAE-LSTM network, and the corresponding average error in the five cases. The overall prediction time errors meeting the accuracy requirements of flow field prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bcbe7b",
   "metadata": {},
   "source": [
    "Sod shock tube:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ba22d",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/sod_cae_lstm_predict.gif\" title=\"sod_cae_lstm_predict\" width=\"600\"/>\n",
    "    <img src=\"./images/sod_cae_lstm_error.png\" title=\"sod_cae_lstm_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e08f65",
   "metadata": {},
   "source": [
    "Shu_Osher problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5eaae",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/shu_osher_cae_lstm_predict.gif\" title=\"shu_osher_cae_lstm_predict\" width=\"600\"/>\n",
    "    <img src=\"./images/shu_osher_cae_lstm_error.png\" title=\"shu_osher_cae_lstm_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc4ba6a",
   "metadata": {},
   "source": [
    "Riemann problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66472b61",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/riemann_cae_lstm_predict.gif\" title=\"riemann_cae_lstm_predict\" width=\"600\"/>\n",
    "    <img src=\"./images/riemann_cae_lstm_error.png\" title=\"riemann_cae_lstm_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b6faf",
   "metadata": {},
   "source": [
    "Kelvin-Helmholtz instability problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc29a1ac",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/kh_cae_lstm_predict.gif\" title=\"kh_cae_lstm_predict\" width=\"600\"/>\n",
    "    <img src=\"./images/kh_cae_lstm_error.png\" title=\"kh_cae_lstm_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ea6b6",
   "metadata": {},
   "source": [
    "cylinder flow (Re = 200):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0232546",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/cylinder_cae_lstm_predict.gif\" title=\"cylinder_cae_lstm_predict\" width=\"600\"/>\n",
    "    <img src=\"./images/cylinder_cae_lstm_error.png\" title=\"cylinder_cae_lstm_error\" width=\"300\"/>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
