{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda19887",
   "metadata": {},
   "source": [
    "\n",
    "# Prediction of unsteady transonic buffet flow field\n",
    "\n",
    "## Introduction\n",
    "\n",
    "At transonic flow conditions, the self-sustained large-scale oscillation of shock wave on airfoils is called transonic buffet. The reason is related to the flow separation and interaction between shock wave and boundary layer. After entering the buffet boundary, the change of separation zone induces the flow instability and affects the position of shock wave, which makes the shock wave move forward and backward and comes with complex unsteady and nonlinear characteristics. Learning the unsteady shock buffet flow directly from the flow field (spatial-temporal flow characteristics) is a valuable and challenging method for buffet research. In order to find an efficient DL modeling method for the complex unsteady transonic buffet flow, an enhanced hybrid deep neural network (eHDNN) is designed to predict the unsteady flow field based on flow field reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af9033",
   "metadata": {},
   "source": [
    "![p1.png](./images/p1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39552eaf",
   "metadata": {},
   "source": [
    "## Framework of eHDNN\n",
    "\n",
    "The basic framework of the eHDNN is mainly based on the hybrid deep neural network framework, which is constituted by CNN, ConvLSTM and DeCNN.CNN reduces the dimensionality of time series flow fields and realizes the characteristic extraction; ConvLSTM learns the evolution of low-dimensional spatial-temporal characteristics and make prediction; finally, DeCNN achieves the reconstruction of predicted flow field characteristics\n",
    "\n",
    "+ Input layer: inputting the historical flow fields\n",
    "+ Convolutional layer: reducing the dimensionality of flow fields and extract the high-dimensional spatial-temporal flow characteristics by CNN\n",
    "+ Memory layer: learning the evolution of the spatial-temporal characteristics of flow fields in the low-dimensional space and predicting the next moment by ConvLSTM\n",
    "+ Deconvolutional output layer: restoring the predicted low-dimensional characteristics of flow fields to high-dimensional space to achieve the reconstruction of the prediction of transient flow field at the next moment by DeCNN, then outputting the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5c41",
   "metadata": {},
   "source": [
    "![p2.jpg](./images/p2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f317de2",
   "metadata": {},
   "source": [
    "## Training samples\n",
    "\n",
    "Training samples are constructed from multi-dimensional matrix flow field snapshot matrixs obtained from numerical simulation flow field data of unsteady buffet of OAT15A supercritical airfoil. It is divided into single-state data set and multi-state data set\n",
    "\n",
    "+ The multi-state data set is the sequence data of unsteady buffet flow fields under the condition of multiple angles of attack. The angles of attack include 3.3°, 3.4°, 3.5°, 3.6°, 3.7° and 3.8°, all of which are located within the buffet boundary\n",
    "+ The single-state data set is the sequence data of unsteady buffet flow fields under the condition of single angle of attack, which is any of the above angles (3.5° by default). Each flow field snapshot contains 3 channels, representing pressure distribution information, string velocity information and normal velocity information of flow field. The size of multidimensional matrix flow field snapshot matrix is T×C×H×W(C=3,H=200,W=200,C is the number of channels,H and W are respectively the height and width of the snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2847f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, jit, data_sink, set_seed\n",
    "from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "from mindflow.utils import load_yaml_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c6d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import create_dataset, ForwardNet, HybridLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7406dd",
   "metadata": {},
   "source": [
    "## Training environment\n",
    "\n",
    "+ The static GRAPH of Mindspore framework is adopted for training\n",
    "+ Training can be done on GPU (default) or Ascend (single card)\n",
    "+ There are two differences between single-state and multi-state training conditions: 1) different training data sets; 2) Different depth of memory layer: The memory layer in single-state is 2 layers (num_memory_layers=2); the memory layer in multi-state is 4 layers (num_memory_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3ba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa53aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='eHDNN for Transonic buffet')\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False, choices=[True, False],\n",
    "                    help=\"Whether to save intermediate compilation graphs\")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./summary\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'Ascend', 'GPU'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0, help=\"ID of the target device\")\n",
    "parser.add_argument(\"--train_aoa_list\", type=list, default=[35],\n",
    "                    help=\"The type for training, [33 ,34 , 35 , 36 , 37 , 38] for multi_state training /n\"\n",
    "                         \"[33],....,[38] for single_state training\")\n",
    "parser.add_argument(\"--num_memory_layers\", type=int, default=2, choices=[2, 4],\n",
    "                    help=\"The number of layers of the whole Memory layer， 2 in single_state and 4 in multi state\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "args = parser.parse_args(args=[])\n",
    "context.set_context(mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs, save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target, device_id=args.device_id)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ca2c",
   "metadata": {},
   "source": [
    "## Training hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e0f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml_config(args.config_file_path)\n",
    "data_params = config[\"data\"]\n",
    "model_params = config[\"model\"]\n",
    "optimizer_params = config[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53d5ec",
   "metadata": {},
   "source": [
    "## Path for saving training process files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e34bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dir = optimizer_params[\"summary_dir\"]\n",
    "if not os.path.exists(summary_dir):\n",
    "    os.mkdir(summary_dir)\n",
    "ckpt_dir = os.path.join(summary_dir, 'ckpt')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505908fc",
   "metadata": {},
   "source": [
    "## Construct neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe1356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ForwardNet(model_params[\"in_channels\"],\n",
    "                   model_params[\"out_channels\"],\n",
    "                   model_params[\"num_layers\"],\n",
    "                   args.num_memory_layers,\n",
    "                   model_params[\"kernel_size_conv\"],\n",
    "                   model_params[\"kernel_size_lstm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e86579",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c63294",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = HybridLoss()\n",
    "optimizer = nn.Adam(params=model.trainable_params(), learning_rate=optimizer_params[\"lr\"])\n",
    "if use_ascend:\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(model, 'O1')\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d32ff9",
   "metadata": {},
   "source": [
    "## Training framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505f3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(x, y):\n",
    "    pred = model(x)\n",
    "    loss = loss_func(pred, y)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)\n",
    "@jit\n",
    "def train_step(x, y):\n",
    "    loss, grads = grad_fn(x, y)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        if all_finite(grads):\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    loss = ops.depend(loss, optimizer(grads))\n",
    "    return loss\n",
    "@jit\n",
    "def eval_step(x, y):\n",
    "    loss = forward_fn(x, y)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf783",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b966cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Load data sample ========\n",
      "input shape (2183, 16, 3, 200, 200)\n",
      "label shape (2183, 1, 3, 200, 200)\n",
      "==========End Load=============\n"
     ]
    }
   ],
   "source": [
    "print(f\"======Load data sample ========\")\n",
    "data_dir = data_params[\"data_dir\"]\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "url_1 = \"https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/airfoil/2D_unsteady/\"\n",
    "for aoa in args.train_aoa_list:\n",
    "    url_2 = f\"total{aoa}_puv.mat\"\n",
    "    url_aoa = urllib.parse.urljoin(url_1, url_2)\n",
    "    urllib.request.urlretrieve(url_aoa, data_dir + '/' + url_2)\n",
    "dataset_train, dataset_eval = create_dataset(data_dir,\n",
    "                                             data_params[\"data_length\"],\n",
    "                                             data_params[\"train_ratio\"],\n",
    "                                             args.train_aoa_list)\n",
    "print(f\"==========End Load=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7331a",
   "metadata": {},
   "source": [
    "## Data sink operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb8487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sink_process = data_sink(train_step, dataset_train, sink_size=1)\n",
    "eval_sink_process = data_sink(eval_step, dataset_eval, sink_size=1)\n",
    "train_data_size, eval_data_size = dataset_train.get_dataset_size(), dataset_eval.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10bb3ca",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5df08da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid:22673\n",
      "========Start train============\n",
      "epoch: 1 train loss: 1.3850026 epoch time: 317.26s\n",
      "epoch: 2 train loss: 0.70951277 epoch time: 300.97s\n",
      "epoch: 3 train loss: 0.6354316 epoch time: 314.41s\n",
      "epoch: 4 train loss: 0.599306 epoch time: 309.21s\n",
      "epoch: 5 train loss: 0.5684712 epoch time: 311.57s\n",
      "epoch: 6 train loss: 0.54864025 epoch time: 306.30s\n",
      "epoch: 7 train loss: 0.5113489 epoch time: 304.56s\n",
      "epoch: 8 train loss: 0.34839326 epoch time: 291.30s\n",
      "epoch: 9 train loss: 0.2967865 epoch time: 297.61s\n",
      "epoch: 10 train loss: 0.28633794 epoch time: 298.61s\n",
      "======Start Evaluation=========\n",
      "epoch: 10 eval loss: 0.33136454\n",
      "=======End Evaluation==========\n",
      "=========End train=============\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    local_time_beg = time.time()\n",
    "    model.set_train(True)\n",
    "    epoch_train_loss = 0\n",
    "    for _ in range(train_data_size):\n",
    "        epoch_train_loss = ops.squeeze(train_sink_process(), axis=())\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(f\"epoch: {epoch} train loss: {epoch_train_loss} epoch time: {time.time() - local_time_beg:.2f}s\")\n",
    "    if epoch % optimizer_params[\"eval_interval\"] == 0:\n",
    "        print(f\"=================Start Evaluation=====================\")\n",
    "        model.set_train(False)\n",
    "        eval_loss = []\n",
    "        for _ in range(eval_data_size):\n",
    "            step_eval_loss = ops.squeeze(eval_sink_process(), axis=())\n",
    "            eval_loss.append(step_eval_loss)\n",
    "        epoch_eval_loss = sum(eval_loss) / len(eval_loss)\n",
    "        print(f\"epoch: {epoch} eval loss: {epoch_eval_loss}\")\n",
    "        print(f\"==================End Evaluation======================\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(model, f\"{ckpt_dir}/net_{epoch}.ckpt\")\n",
    "    print(f\"=====================End train========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aac646",
   "metadata": {},
   "source": [
    "## Visualization of predicted flow field results\n",
    "\n",
    "+ run prediction.py\n",
    "+ The following figures show the prediction results of unsteady buffet flow fields in a single period under the angle of attack of 3.75° (generalized state) based on the well-trained eHDNN model (pressure field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ca937",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/375_pressure_cfd.gif\" title=\"cfd\" width=\"200\"/>\n",
    "    <img src=\"./images/375_pressure_prediction.gif\" title=\"prediction\" width=\"200\"/>\n",
    "    <img src=\"./images/375_pressure_abserror.gif\" title=\"abs error\" width=\"200\"/>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
