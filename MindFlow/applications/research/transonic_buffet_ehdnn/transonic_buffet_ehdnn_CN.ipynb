{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda19887",
   "metadata": {},
   "source": [
    "\n",
    "# 跨声速抖振非定常流场预测\n",
    "\n",
    "## 环境安装\n",
    "\n",
    "本案例要求 **MindSpore >= 2.0.0** 版本以调用如下接口: *mindspore.jit, mindspore.jit_class, mindspore.data_sink*。具体请查看[MindSpore安装](https://www.mindspore.cn/install)。\n",
    "\n",
    "此外，你需要安装 **MindFlow >=0.1.0** 版本。如果当前环境还没有安装，请按照下列方式选择后端和版本进行安装。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mindflow_version = \"0.1.0\"  # update if needed\n",
    "# GPU Comment out the following code if you are using NPU.\n",
    "!pip uninstall -y mindflow-gpu\n",
    "!pip install mindflow-gpu==$mindflow_version\n",
    "\n",
    "# NPU Uncomment if needed.\n",
    "# !pip uninstall -y mindflow-ascend\n",
    "# !pip install mindflow-ascend==$mindflow_version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af1112",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "在跨声速流动条件下，翼型上表面出现的自持续大尺度激波振荡现象被称为跨声速抖振。其原因与激波与边界层流动分离及相互作用有关。进入抖振边界后，分离区变化引起流动不稳定，影响了激波的流场位置，使得激波产生前后运动，具有复杂的非定常和非线性特征。从流场(时空流)直接学习非定常激波抖振特征对抖振研究而言是一种有价值且具有挑战性的方法。为了找到一个高效的DL建模方法解决复杂非定常跨声速抖振问题，提出一种增强型混合深度神经网络(eHDNN)，基于流场重构对非定常流场进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af9033",
   "metadata": {},
   "source": [
    "![p1.png](./images/p1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39552eaf",
   "metadata": {},
   "source": [
    "## 模型架构\n",
    "\n",
    "eHDNN的基本框架主要基于混合深度神经网络框架，主要由卷积神经网络（CNNs）、卷积长短时间记忆网络（ConvLSTMs）和反卷积神经网络（DeCNNs）组成。CNN降低了时间序列流场的维数，实现特征提取;ConvLSTM学习低维时空特征并进行预测;最后，DeCNN实现预测流场的重建\n",
    "\n",
    "+ 输入层：输入历史流场\n",
    "+ 卷积层：通过CNN对流场进行降维，提取高维时空流动特征\n",
    "+ 记忆层：通过ConvLSTM学习低维空间流场时空特征的演变，预测下一时刻\n",
    "+ 反卷积输出层：将预测的流场低维特征恢复到高维空间，通过DeCNN实现对下一时刻瞬态流场预测，并输出预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5c41",
   "metadata": {},
   "source": [
    "![p2.jpg](./images/p2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f317de2",
   "metadata": {},
   "source": [
    "## 训练数据集\n",
    "\n",
    "由OAT15A超临界翼型非定常抖振的数值仿真流场数据构建的多维矩阵流场快照矩阵构建而成。分为单状态数据集和多状态数据集两种\n",
    "\n",
    "+ 多状态数据集为多攻角状态下的非定常抖振流场序列数据，攻角状态包括3.3°、3.4°、3.5°、3.6°、3.7°、3.8°六个攻角，均位于抖振边界内\n",
    "+ 单状态数据集为单一攻角状态下的非定常抖振流场序列数据，攻角状态为上述攻角的任意一个（默认3.5°）\n",
    "+ 每张流场快照包含3个通道，代表流场的压强分布信息、弦向速度信息、法向速度信息，多维矩阵流场快照矩阵尺寸为：T×C×H×W(C=3,H=200,W=200,C为通道数，H，W分别为快照的高和宽）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2847f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, jit, data_sink, set_seed\n",
    "from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "from mindflow.utils import load_yaml_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c6d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import create_dataset, ForwardNet, HybridLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7406dd",
   "metadata": {},
   "source": [
    "## 训练环境\n",
    "\n",
    "+ 训练采用Mindspore框架的静态图模式（GRAPH）\n",
    "+ 在GPU（默认）或Ascend进行训练（单卡）\n",
    "+ 单状态与多状态训练条件有两个不同：1）训练数据集不同；2）记忆层深度不同：单状态下记忆层深度为2层（num_memory_layers=2），多状态下记忆层深度为4层（num_memory_layers=4）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3ba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa53aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='eHDNN for Transonic buffet')\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False, choices=[True, False],\n",
    "                    help=\"Whether to save intermediate compilation graphs\")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./summary\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'Ascend', 'GPU'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0, help=\"ID of the target device\")\n",
    "parser.add_argument(\"--train_aoa_list\", type=list, default=[35],\n",
    "                    help=\"The type for training, [33 ,34 , 35 , 36 , 37 , 38] for multi_state training /n\"\n",
    "                         \"[33],....,[38] for single_state training\")\n",
    "parser.add_argument(\"--num_memory_layers\", type=int, default=2, choices=[2, 4],\n",
    "                    help=\"The number of layers of the whole Memory layer， 2 in single_state and 4 in multi state\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "args = parser.parse_args(args=[])\n",
    "context.set_context(mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs, save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target, device_id=args.device_id)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ca2c",
   "metadata": {},
   "source": [
    "## 训练超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e0f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml_config(args.config_file_path)\n",
    "data_params = config[\"data\"]\n",
    "model_params = config[\"model\"]\n",
    "optimizer_params = config[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53d5ec",
   "metadata": {},
   "source": [
    "## 训练过程文件保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e34bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dir = optimizer_params[\"summary_dir\"]\n",
    "if not os.path.exists(summary_dir):\n",
    "    os.mkdir(summary_dir)\n",
    "ckpt_dir = os.path.join(summary_dir, 'ckpt')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505908fc",
   "metadata": {},
   "source": [
    "## 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe1356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ForwardNet(model_params[\"in_channels\"],\n",
    "                   model_params[\"out_channels\"],\n",
    "                   model_params[\"num_layers\"],\n",
    "                   args.num_memory_layers,\n",
    "                   model_params[\"kernel_size_conv\"],\n",
    "                   model_params[\"kernel_size_lstm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e86579",
   "metadata": {},
   "source": [
    "## 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c63294",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = HybridLoss()\n",
    "optimizer = nn.Adam(params=model.trainable_params(), learning_rate=optimizer_params[\"lr\"])\n",
    "if use_ascend:\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(model, 'O1')\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d32ff9",
   "metadata": {},
   "source": [
    "## 训练框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505f3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(x, y):\n",
    "    pred = model(x)\n",
    "    loss = loss_func(pred, y)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)\n",
    "@jit\n",
    "def train_step(x, y):\n",
    "    loss, grads = grad_fn(x, y)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        if all_finite(grads):\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    loss = ops.depend(loss, optimizer(grads))\n",
    "    return loss\n",
    "@jit\n",
    "def eval_step(x, y):\n",
    "    loss = forward_fn(x, y)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf783",
   "metadata": {},
   "source": [
    "## 数据集加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25786be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Load data sample ========\n",
      "input shape (2183, 16, 3, 200, 200)\n",
      "label shape (2183, 1, 3, 200, 200)\n",
      "==========End Load=============\n"
     ]
    }
   ],
   "source": [
    "print(f\"======Load data sample ========\")\n",
    "data_dir = data_params[\"data_dir\"]\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "url_1 = \"https://download.mindspore.cn/mindscience/mindflow/dataset/applications/data_driven/airfoil/2D_unsteady/\"\n",
    "for aoa in args.train_aoa_list:\n",
    "    url_2 = f\"total{aoa}_puv.mat\"\n",
    "    url_aoa = urllib.parse.urljoin(url_1, url_2)\n",
    "    urllib.request.urlretrieve(url_aoa, data_dir + '/' + url_2)\n",
    "dataset_train, dataset_eval = create_dataset(data_dir,\n",
    "                                             data_params[\"data_length\"],\n",
    "                                             data_params[\"train_ratio\"],\n",
    "                                             args.train_aoa_list)\n",
    "print(f\"==========End Load=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7331a",
   "metadata": {},
   "source": [
    "## 数据下沉设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb8487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sink_process = data_sink(train_step, dataset_train, sink_size=1)\n",
    "eval_sink_process = data_sink(eval_step, dataset_eval, sink_size=1)\n",
    "train_data_size, eval_data_size = dataset_train.get_dataset_size(), dataset_eval.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10bb3ca",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5df08da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid:23104\n",
      "========Start train============\n",
      "epoch: 1 train loss: 1.3960425 epoch time: 329.46s\n",
      "epoch: 2 train loss: 0.71045536 epoch time: 302.11s\n",
      "epoch: 3 train loss: 0.63674355 epoch time: 294.79s\n",
      "epoch: 4 train loss: 0.59894246 epoch time: 301.62s\n",
      "epoch: 5 train loss: 0.5694136 epoch time: 311.56s\n",
      "epoch: 6 train loss: 0.55112934 epoch time: 304.45s\n",
      "epoch: 7 train loss: 0.5356926 epoch time: 310.83s\n",
      "epoch: 8 train loss: 0.38834217 epoch time: 318.15s\n",
      "epoch: 9 train loss: 0.31074354 epoch time: 320.24s\n",
      "epoch: 10 train loss: 0.285696 epoch time: 306.86s\n",
      "======Start Evaluation=========\n",
      "epoch: 10 eval loss: 0.3148067\n",
      "=======End Evaluation==========\n",
      "=========End train=============\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    local_time_beg = time.time()\n",
    "    model.set_train(True)\n",
    "    epoch_train_loss = 0\n",
    "    for _ in range(train_data_size):\n",
    "        epoch_train_loss = ops.squeeze(train_sink_process(), axis=())\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(f\"epoch: {epoch} train loss: {epoch_train_loss} epoch time: {time.time() - local_time_beg:.2f}s\")\n",
    "    if epoch % optimizer_params[\"eval_interval\"] == 0:\n",
    "        print(f\"=================Start Evaluation=====================\")\n",
    "        model.set_train(False)\n",
    "        eval_loss = []\n",
    "        for _ in range(eval_data_size):\n",
    "            step_eval_loss = ops.squeeze(eval_sink_process(), axis=())\n",
    "            eval_loss.append(step_eval_loss)\n",
    "        epoch_eval_loss = sum(eval_loss) / len(eval_loss)\n",
    "        print(f\"epoch: {epoch} eval loss: {epoch_eval_loss}\")\n",
    "        print(f\"==================End Evaluation======================\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(model, f\"{ckpt_dir}/net_{epoch}.ckpt\")\n",
    "    print(f\"=====================End train========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aac646",
   "metadata": {},
   "source": [
    "## 预测流场结果可视化\n",
    "\n",
    "+ 运行prediction.py\n",
    "+ 下图为基于多状态下训练完备的eHDNN模型实现对攻角3.75°（泛化状态）下非定常抖振流场单周期内的变化预测结果（展示压强场）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ca937",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/375_pressure_cfd.gif\" title=\"cfd\" width=\"200\"/>\n",
    "    <img src=\"./images/375_pressure_prediction.gif\" title=\"prediction\" width=\"200\"/>\n",
    "    <img src=\"./images/375_pressure_abserror.gif\" title=\"abs error\" width=\"200\"/>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
