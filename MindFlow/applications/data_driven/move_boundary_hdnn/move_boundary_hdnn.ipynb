{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda19887",
   "metadata": {},
   "source": [
    "\n",
    "# Prediction of Unsteady Flow Field with Moving Boundary\n",
    "\n",
    "## Overview\n",
    "\n",
    "As an important tool to simulate and analyze fluid motion through numerical methods, CFD greatly facilitates the scientific research of fluid mechanics related issues, and plays an important role in providing accurate data and insights in the fields of design, optimization and research. One of the representative and research value problems in fluid mechanics is to simulate the unsteady flow field system with moving boundary to analyze the force of the moving structure in the flow field, which can optimize the design of the moving structure in engineering, and provide scheme strategies for the shape optimization of aerospace vehicles and navigation vehicles. High precision computational fluid dynamics (CFD) can accurately simulate the evolution of flow field and the stress of structure, but the high-precision dynamic boundary problem requires a large number of grids, which leads to huge hardware consumption and computational time cost. In addition, the construction of dynamic grids is also particularly time-consuming.\n",
    "\n",
    "When CFD is applied to complex problems, the amount of calculation is huge and the calculation accuracy needs to be improved. An effective solution is given in the field of intelligent fluid mechanics. Deep learning can learn the evolution relationship between flow conditions and flow field through deep neural network, and quickly realize high-precision prediction and reconstruction of flow field. In order to efficiently solve the problem of reconstructing the flow field at the moving boundary, a hybrid depth neural network (hdnn) is proposed to reconstruct the unsteady flow field at the moving boundary, and fast predict the flow field based on it.\n",
    "\n",
    "## Problem description\n",
    "\n",
    "The relevant dimensions of the flow field are shown in the figure, where Y = Asin(2πft) represents the motion expression of the cylinder in a simple harmonic motion in the vertical direction, a is the amplitude, f is the frequency; D stands for cylinder diameter; The rectangular boundary represents the computational domain. When the uniform incoming flow flows through a moving cylinder, under the influence of the interaction between the fluid and the solid, a series of complex flow phenomena will be formed behind the cylinder, such as boundary layer separation, alternating Karman vortex street and so on, and evolve into a non-uniform flow field whose physical quantities change periodically with time.\n",
    "\n",
    "## Technology path\n",
    "\n",
    "The specific process of mindflow to solve this problem is as follows:\n",
    "\n",
    "1.Create data sets based on CFD numerical simulation results.\n",
    "\n",
    "2.The model is built using mindspire deep learning framework.\n",
    "\n",
    "3.Define the optimizer and loss function.\n",
    "\n",
    "4.Use mindspire's instant compilation to accelerate model training.\n",
    "\n",
    "5.Use the trained model for reasoning and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af9033",
   "metadata": {},
   "source": [
    "![p1.png](./images/p1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39552eaf",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "The basic framework of HDNN consists of convolutional neural network (CNN), convolutional long short-term memory network (ConvLSTM) and deconvolution neural network (DeCNN). CNN reduces the dimensionality of the time series flow field and achieves feature extraction; ConvLSTM learns low dimensional spatiotemporal features and makes predictions; Finally, DeCNN achieves reconstruction of predicted flow fields\n",
    "\n",
    "+ Input layer: Input historical flow field\n",
    "+ Convolutional layer: Using multi-layer CNN to reduce the dimensionality of the input flow field and extract high-dimensional spatiotemporal flow characteristics\n",
    "+ Memory layer: learning the evolution of spatiotemporal characteristics of low dimensional spatial flow fields through ConvLSTM and predicting the next moment\n",
    "+ Deconvolution output layer: Restores the low-dimensional features of the predicted flow field to high-dimensional space, reconstructs the transient flow field at the next moment through multi-layer DeCNN, and outputs visual prediction results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5c41",
   "metadata": {},
   "source": [
    "![HDNN.jpg](./images/HDNN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f317de2",
   "metadata": {},
   "source": [
    "## Training dataset\n",
    "\n",
    "The dataset is constructed from multidimensional matrix flow field snapshot matrix constructed from numerical simulation of unsteady two-dimensional cylindrical flow field data\n",
    "\n",
    "+ A two-dimensional cylinder undergoes one-dimensional harmonic vibration in a uniform flow field, with vibration frequencies f (Hz) of 1.25, 1.43, 1.67, and 2.00, and amplitude ratios A/D of 0.5, 0.6, 0.7, and 0.8, respectively. Pairwise combination for a total of 16 sets of motion states\n",
    "+ The dataset is a series of unsteady flow field data in a certain state (f, A/D)\n",
    "+ Each flow field snapshot contains three channels, representing the pressure distribution information, horizontal velocity information, and vertical velocity information of the flow field. The size of the multi-dimensional matrix flow field snapshot matrix is: T × C × H × W (C is the number of channels, H, W are the height and width of the snapshot, respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2847f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, data_sink, jit\n",
    "from mindflow.utils import load_yaml_config\n",
    "\n",
    "from src import my_train_dataset, AEnet, save_loss_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7406dd",
   "metadata": {},
   "source": [
    "## Training environment\n",
    "\n",
    "+ The training adopts the static graphical model of Mindspot framework (GRAPH)\n",
    "+ Train on CPU, GPU, or Ascend (single card)\n",
    "+ The cylindrical vibration frequencies f (Hz) in the training dataset are 1.25, 1.43, and 1.67, respectively, and the amplitude ratios A/D are 0.5, 0.6, and 0.7, respectively. Pairwise combination for a total of 9 sets of motion states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c6d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ca2c",
   "metadata": {},
   "source": [
    "## Training hyperparameter\n",
    "\n",
    "Obtain hyperparameters for models, data, and optimizers from config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e3ba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"cylinder around flow ROM\")\n",
    "\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False, choices=[True, False],\n",
    "                    help=\"Whether to save intermediate compilation graphs\")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./summary\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'GPU','Ascend'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0, help=\"ID of the target device\")\n",
    "parser.add_argument(\"--data_list\", type=list, default=['0.00', '0.25', '0.35', '0.45'],\n",
    "                    help=\"The type for training, [0.00, 0.25, 0.35, 0.45] for multi_state training /n\"\n",
    "                         \"[0.25],....,[0.45] for single_state training\")\n",
    "parser.add_argument('--batch_size', type=int, default=16, help=\"mini batch_size\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs, save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target, device_id=args.device_id)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "\n",
    "config = load_yaml_config(args.config_file_path)\n",
    "data_params = config[\"data\"]\n",
    "model_params = config[\"model\"]\n",
    "optimizer_params = config[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53d5ec",
   "metadata": {},
   "source": [
    "## Training process file save path\n",
    "\n",
    "Save the trained model file in a folder every certain number of training sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa53aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = optimizer_params[\"ckpt_dir\"]\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505908fc",
   "metadata": {},
   "source": [
    "## Constructing neural network and optimizer\n",
    "\n",
    "The convolutional layer of the neural network has a total of 12 layers, ConvLSTM has 1 layer, and deconvolution has a total of 12 layers\n",
    "\n",
    "The Loss function uses the Mean squared error Loss function, and the optimizer uses the Adam (Adaptive Moment Estimation) optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e0f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AEnet(in_channels=model_params[\"in_channels\"],\n",
    "              num_layers=model_params[\"num_layers\"],\n",
    "              kernel_size=model_params[\"kernel_size\"],\n",
    "              num_convlstm_layers=model_params[\"num_convlstm_layers\"])\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = nn.Adam(params=model.trainable_params(), learning_rate=optimizer_params[\"lr\"])\n",
    "if use_ascend:\n",
    "    from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(model, 'O1')\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d32ff9",
   "metadata": {},
   "source": [
    "## Training framework\n",
    "\n",
    "Define the forward propagation function forward_ Fn, compare the predicted value with the true value to obtain the loss value and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e34bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(inputs, velocity, label):\n",
    "    pred = model(inputs, velocity)\n",
    "    loss = loss_func(pred, label)\n",
    "\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faacf783",
   "metadata": {},
   "source": [
    "## Dataset loading\n",
    "\n",
    "To my_train_dataset parameter transfer to obtain training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe1356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"==================Load data sample ===================\")\n",
    "dataset_train, dataset_eval = my_train_dataset(data_params[\"data_dir\"],\n",
    "                                               data_params[\"time_steps\"],\n",
    "                                               args.data_list)\n",
    "print(f\"======================End Load========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7331a",
   "metadata": {},
   "source": [
    "## Data sink and model training\n",
    "\n",
    "Define train_ Step and Eval_ Step and use data_ Sink acceleration training, output the loss value and usage time during the training process, and save the model file every certain training round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c63294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"====================Start train=======================\")\n",
    "@jit\n",
    "def train_step(inputs, velocity, label):\n",
    "    loss, grads = grad_fn(inputs, velocity, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        if all_finite(grads):\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    loss = ops.depend(loss, optimizer(grads))\n",
    "    return loss\n",
    "\n",
    "@jit\n",
    "def eval_step(inputs, velocity, label):\n",
    "    loss = forward_fn(inputs, velocity, label)\n",
    "    loss = ops.sqrt(loss)\n",
    "    return loss\n",
    "\n",
    "train_sink_process = data_sink(train_step, dataset_train, sink_size=1)\n",
    "eval_sink_process = data_sink(eval_step, dataset_eval, sink_size=1)\n",
    "train_data_size, eval_data_size = dataset_train.get_dataset_size(), dataset_eval.get_dataset_size()\n",
    "\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = []\n",
    "\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    train_losses = 0\n",
    "    valid_losses = 0\n",
    "\n",
    "    local_time_beg = time.time()\n",
    "    model.set_train(True)\n",
    "\n",
    "    for _ in range(train_data_size):\n",
    "        step_train_loss = ops.squeeze(train_sink_process(), axis=())\n",
    "        step_train_loss = step_train_loss.asnumpy().item()\n",
    "        train_losses += step_train_loss\n",
    "\n",
    "    train_loss = train_losses / train_data_size\n",
    "    avg_train_losses.append(train_loss)\n",
    "\n",
    "    print(f\"epoch: {epoch}, epoch average train loss: {train_loss :.6f}, \"\n",
    "          f\"epoch time: {(time.time() - local_time_beg):.2f}s\")\n",
    "\n",
    "    if epoch % optimizer_params[\"eval_interval\"] == 0:\n",
    "        print(f\"=================Start Evaluation=====================\")\n",
    "\n",
    "        eval_time_beg = time.time()\n",
    "        model.set_train(False)\n",
    "        for _ in range(eval_data_size):\n",
    "            step_eval_loss = ops.squeeze(eval_sink_process(), axis=())\n",
    "            step_eval_loss = step_eval_loss.asnumpy().item()\n",
    "            valid_losses += step_eval_loss\n",
    "\n",
    "        valid_loss = valid_losses / eval_data_size\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        print(f\"epoch: {epoch}, epoch average valid loss: {valid_loss :.6f}, \"\n",
    "              f\"epoch time: {(time.time() - eval_time_beg):.2f}s\")\n",
    "        print(f\"==================End Evaluation======================\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(model, f\"{ckpt_dir}/net_{epoch}.ckpt\")\n",
    "\n",
    "save_loss_curve(avg_train_losses, 'Epoch', 'avg_train_losses', 'Avg_train_losses Curve', 'Avg_train_losses.png')\n",
    "save_loss_curve(avg_valid_losses, 'Epoch', 'avg_valid_losses', 'Avg_valid_losses Curve', 'Avg_valid_losses.png')\n",
    "\n",
    "print(f\"=====================End train========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1262b22",
   "metadata": {},
   "source": [
    "## Set training conditions for parameter transmission\n",
    "\n",
    "When running the file, pass in the necessary parameters through the parameter parser to start training, and print the process and device id, as well as the total training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505f3e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Process ID:\", os.getpid())\n",
    "    print(f\"device id: {args.device_id}\")\n",
    "    start_time = time.time()\n",
    "    train()\n",
    "    print(f\"End-to-End total time: {(time.time() - start_time):.2f}s\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bcfdbdd",
   "metadata": {},
   "source": [
    "Process ID: 2801010\n",
    "device id: 0\n",
    "==================Load data sample ===================\n",
    "======================End Load========================\n",
    "\n",
    "====================Start train=======================\n",
    "epoch: 1, epoch average train loss: 0.069304, epoch time: 51.62s\n",
    "epoch: 2, epoch average train loss: 0.011798, epoch time: 24.36s\n",
    "epoch: 3, epoch average train loss: 0.010980, epoch time: 16.55s\n",
    "epoch: 4, epoch average train loss: 0.010644, epoch time: 24.14s\n",
    "epoch: 5, epoch average train loss: 0.010608, epoch time: 22.38s\n",
    "epoch: 6, epoch average train loss: 0.010324, epoch time: 21.66s\n",
    "epoch: 7, epoch average train loss: 0.010152, epoch time: 32.79s\n",
    "epoch: 8, epoch average train loss: 0.009601, epoch time: 24.62s\n",
    "epoch: 9, epoch average train loss: 0.009147, epoch time: 22.19s\n",
    "epoch: 10, epoch average train loss: 0.008809, epoch time: 19.52s\n",
    "=================Start Evaluation=====================\n",
    "epoch: 10, epoch average valid loss: 0.098904, epoch time: 12.86s\n",
    "==================End Evaluation======================\n",
    "\n",
    "...\n",
    "\n",
    "epoch: 91, epoch average train loss: 0.000274, epoch time: 28.49s\n",
    "epoch: 92, epoch average train loss: 0.000280, epoch time: 27.60s\n",
    "epoch: 93, epoch average train loss: 0.000231, epoch time: 20.99s\n",
    "epoch: 94, epoch average train loss: 0.000297, epoch time: 18.26s\n",
    "epoch: 95, epoch average train loss: 0.000417, epoch time: 21.94s\n",
    "epoch: 96, epoch average train loss: 0.000228, epoch time: 27.41s\n",
    "epoch: 97, epoch average train loss: 0.000232, epoch time: 18.61s\n",
    "epoch: 98, epoch average train loss: 0.000250, epoch time: 26.81s\n",
    "epoch: 99, epoch average train loss: 0.000217, epoch time: 21.16s\n",
    "epoch: 100, epoch average train loss: 0.000244, epoch time: 18.09s\n",
    "=================Start Evaluation=====================\n",
    "epoch: 100, epoch average valid loss: 0.015813, epoch time: 15.06s\n",
    "==================End Evaluation======================\n",
    "=====================End train========================\n",
    "End-to-End total time: 2575.05s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aac646",
   "metadata": {},
   "source": [
    "## Visualization of predicted flow field results\n",
    "\n",
    "+ The moving boundary flow field prediction is started by executing eval.py, which can be divided into two prediction methods: single step flow field prediction (infer_mode is \"one\") and continuous flow field prediction within a vibration period (infer_mode is \"cycle\"); Single step flow field prediction only predicts the flow field of one time step at the next moment, while continuous flow field prediction continuously predicts the flow field of a complete cycle\n",
    "+ The following figure shows the results of a fully trained HDNN model for one-step prediction and one complete cycle prediction of unsteady moving boundaries with a vibration frequency of 1.43Hz and an amplitude of 0.8 (amplitude ratio generalization state) (displaying pressure field, horizontal velocity field, and vertical velocity field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ca937",
   "metadata": {},
   "source": [
    "![pred_single_step_puv.jpg](./images/pred_single_step_puv.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0462a4d",
   "metadata": {},
   "source": [
    "![pred_cycle_puv.jpg](./images/pred_cycle_puv.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
