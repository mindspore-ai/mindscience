{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda19887",
   "metadata": {},
   "source": [
    "\n",
    "# CAE-LSTM Reduced Order Model——Shu-Osher problem\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In order to effectively reduce the design cost and cycle time of using CFD methods, the reduced-order model (ROM) has gained wide attention in recent years. For complex compressible flows, using linear methods such as Proper Orthogonal Decomposition (POD) for flow field dimensionality reduction requires a large number of modes to ensure the reconstruction accuracy. It has been shown that the modes number can be effectively reduced by using nonlinear dimensionality reduction methods. Convolutional Autoencoder (CAE) is a kind of neural network composed of encoder and decoder, which can realize data dimensionality reduction and recon-struction, and can be regarded as a nonlinear extension of POD method. CAE is used for nonlinear dimension-ality reduction, and Long Short-Term Memory (LSTM) is used for time evolution. The CAE-LSTM can obtain high reconstruction and prediction accuracy on the premise of using less latents for unsteady compressible flows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39552eaf",
   "metadata": {},
   "source": [
    "## Framework of CAE-LSTM\n",
    "\n",
    "The CAE-LSTM reduced order model uses a CAE network to reduce the dimensionality of the flow field, extract the characteristics of the flow data, compress it into the hidden space of the encoder, and then use the LSTM network to perform coefficient time evolution on the free variables in the hidden space to obtain the free variables at other times of flow. Then, the decoder of the CAE network decodes the evolved free variables and reconstructs the flow field flow data at the corresponding time. The construction of the CAE-LSTM flow reduction model relies on the data reduction of the CAE network and the coefficient time evolution of the LSTM network. Compared with existing methods such as POD/DMD, using CAE networks for nonlinear dimensionality reduction of flow field data and LSTM networks for equation free evolution of free variables can achieve higher compression ratios and improve the efficiency of flow field prediction while ensuring the accuracy of the flow field reduction model.\n",
    "\n",
    "+ Input：Input the flow field for a period of time.\n",
    "+ Compression：Extract high-dimensional spatiotemporal flow characteristics by dimensionality reduction of the flow field using the encoder of CAE.\n",
    "+ Evolution：Learning the evolution of spatiotemporal characteristics of low dimensional spatial flow fields through LSTM and predicting the next moment.\n",
    "+ Reconstruction：Restore the predicted low-dimensional features of the flow field to high-dimensional space through the decoder of CAE.\n",
    "+ Output：Output the predicted results of the transient flow field at the next moment.\n",
    "\n",
    "The first step is to train the CAE network. After the training is completed, the CAE encoder is used to obtain the low dimensional features of the flow field. This low dimensional feature is used as the dataset of the LSTM network for LSTM network training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5c41",
   "metadata": {},
   "source": [
    "![CAE-LSTM.png](./images/CAE-LSTM1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7406dd",
   "metadata": {},
   "source": [
    "## Training environment\n",
    "\n",
    "Import the required function library for training, where src includes dataset creation functions, network models, and training loss visualization functions.\n",
    "\n",
    "The static GRAPH of Mindspore framework is adopted for training. Training can be done on GPU(default) or Ascend(single card)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17230db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, ops, context, save_checkpoint, set_seed, jit, data_sink\n",
    "from mindflow.utils import load_yaml_config\n",
    "\n",
    "from src import create_cae_dataset, CaeNet, plot_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3ba84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa53aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='cae net for shu_osher')\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Context mode, support 'GRAPH', 'PYNATIVE'\")\n",
    "parser.add_argument(\"--save_graphs\", type=bool, default=False, choices=[True, False],\n",
    "                    help=\"Whether to save intermediate compilation graphs\")\n",
    "parser.add_argument(\"--save_graphs_path\", type=str, default=\"./graphs\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"GPU\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'Ascend', 'GPU'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0, help=\"ID of the target device\")\n",
    "parser.add_argument(\"--config_file_path\", type=str, default=\"./config.yaml\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE if args.mode.upper().startswith(\"GRAPH\") else context.PYNATIVE_MODE,\n",
    "                    save_graphs=args.save_graphs,\n",
    "                    save_graphs_path=args.save_graphs_path,\n",
    "                    device_target=args.device_target,\n",
    "                    device_id=args.device_id)\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5ca2c",
   "metadata": {},
   "source": [
    "## CAE training parameter settings\n",
    "\n",
    "Import parameter configurations for the dataset, CAE model, and optimizer from the config.yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e0f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml_config(args.config_file_path)\n",
    "data_params = config[\"cae_data\"]\n",
    "model_params = config[\"cae_model\"]\n",
    "optimizer_params = config[\"cae_optimizer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53d5ec",
   "metadata": {},
   "source": [
    "The default path for saving loss files during training is optimizer_params [\"summary_dir\"], the weight parameters are saved in the ckpt folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e34bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dir = optimizer_params[\"summary_dir\"]\n",
    "if not os.path.exists(summary_dir):\n",
    "    os.mkdir(summary_dir)\n",
    "ckpt_dir = os.path.join(summary_dir, 'ckpt')\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505908fc",
   "metadata": {},
   "source": [
    "## Construct CAE neural network\n",
    "\n",
    "The CAE network consists of six layers of convolution and maximum pooling to form an encoder, and seven layers of convolution and upsampling to form a decoder. Use MSELoss loss function and Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe1356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cae = CaeNet(model_params[\"data_dimension\"], model_params[\"conv_kernel_size\"], model_params[\"maxpool_kernel_size\"],\n",
    "             model_params[\"maxpool_stride\"], model_params[\"encoder_channels\"], model_params[\"decoder_channels\"])\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "cae_opt = nn.Adam(cae.trainable_params(), optimizer_params[\"lr\"], weight_decay=optimizer_params[\"weight_decay\"])\n",
    "\n",
    "if use_ascend:\n",
    "    from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(cae, 'O1')\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea2da0",
   "metadata": {},
   "source": [
    "## CAE dataset\n",
    "\n",
    "Dataset download address: data_driven/cae-lstm/shu_osher/dataset\n",
    "\n",
    "The dataset in this case is the numerical simulation results of a one-dimensional shu-osher problem, the Shu-Osher problem is a typical one-dimensional shock wave interaction problem. The coordinate range is \\[-5, 5\\], and the calculation time t ranges from \\[0, 1.8\\]. A total of 2093 flow field snapshots, each with a matrix size of 512.\n",
    "\n",
    "After importing the dataset, perform data sinking settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb8487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cae_dataset, _ = create_cae_dataset(data_params[\"data_path\"], data_params[\"batch_size\"])\n",
    "\n",
    "sink_process = data_sink(train_step, cae_dataset, sink_size=1)\n",
    "train_data_size = cae_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771dfcdf",
   "metadata": {},
   "source": [
    "## CAE training\n",
    "\n",
    "Build forward_fn and train_step, start training the CAE network and visualize the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f16d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid:4071\n",
      "====================Start cae train=======================\n",
      "epoch: 1 train loss: 0.22447173 epoch time: 16.22s\n",
      "epoch: 2 train loss: 0.07746988 epoch time: 0.69s\n",
      "epoch: 3 train loss: 0.051422045 epoch time: 0.69s\n",
      "epoch: 4 train loss: 0.05668847 epoch time: 0.70s\n",
      "epoch: 5 train loss: 0.042482834 epoch time: 0.70s\n",
      "...\n",
      "epoch: 4396 train loss: 0.0013400748 epoch time: 0.69s\n",
      "epoch: 4397 train loss: 0.001484146 epoch time: 0.69s\n",
      "epoch: 4398 train loss: 0.0012656535 epoch time: 0.72s\n",
      "epoch: 4399 train loss: 0.0015285912 epoch time: 0.71s\n",
      "epoch: 4400 train loss: 0.0011815348 epoch time: 0.74s\n",
      "====================End cae train=======================\n"
     ]
    }
   ],
   "source": [
    "def forward_fn(data, label):\n",
    "    logits = cae(data)\n",
    "    loss = loss_fn(logits, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, cae_opt.parameters, has_aux=False)\n",
    "\n",
    "@jit\n",
    "def train_step(data, label):\n",
    "    loss, grads = grad_fn(data, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        if all_finite(grads):\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    loss = ops.depend(loss, cae_opt(grads))\n",
    "    return loss\n",
    "\n",
    "print(f\"====================Start cae train=======================\")\n",
    "train_loss = []\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    local_time_beg = time.time()\n",
    "    cae.set_train()\n",
    "    epoch_train_loss = 0\n",
    "    for _ in range(train_data_size):\n",
    "        epoch_train_loss = ops.squeeze(sink_process(), axis=())\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(f\"epoch: {epoch} train loss: {epoch_train_loss} epoch time: {time.time() - local_time_beg:.2f}s\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(cae, f\"{ckpt_dir}/cae_{epoch}.ckpt\")\n",
    "print(f\"=====================End cae train========================\")\n",
    "plot_train_loss(train_loss, summary_dir, optimizer_params[\"epochs\"], \"cae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a43727",
   "metadata": {},
   "source": [
    "## CAE flow field reconstruction results\n",
    "\n",
    "After training the CAE network, run cae_prediction.py to view the training results of CAE to determine whether to continue training the LSTM network\n",
    "\n",
    "The following figures show the real flow field, CAE flow field reconstruction results, and the error curves between them. The first two flow field results show the variation of density at different x positions in the flow field over time, while the third error curve shows the average relative error of the CAE reconstructed flow field and the real flow field label over time. The error remains below 0.02 for most of the time, meeting the accuracy requirements for flow field reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c7619",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/true.gif\" title=\"cae_train_loss\" width=\"300\"/>\n",
    "    <img src=\"./images/cae.gif\" title=\"cae_prediction\" width=\"300\"/>\n",
    "    <img src=\"./images/cae_error.png\" title=\"cae_error\" width=\"300\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e4826",
   "metadata": {},
   "source": [
    "## LSTM framework and training Settings\n",
    "\n",
    "The construction of LSTM network framework, training environment, and other related processing are similar to those of CAE network.\n",
    "\n",
    "Firstly, import the LSTM network dataset setting parameters, LSTM model, and optimizer parameter settings. The default training loss save path is optimizer_params [\"summary_dir\"], the weight parameters are saved in the ckpt folder. The network consists of multiple LSTM layers and a full connection layer, using MSELoss loss function and Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbef106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare params\n",
    "config = load_yaml_config(args.config_file_path)\n",
    "data_params = config[\"lstm_data\"]\n",
    "model_params = config[\"lstm_model\"]\n",
    "optimizer_params = config[\"lstm_optimizer\"]\n",
    "\n",
    "# prepare summary file\n",
    "summary_dir = optimizer_params[\"summary_dir\"]\n",
    "ckpt_dir = os.path.join(summary_dir, 'ckpt')\n",
    "\n",
    "# prepare model\n",
    "lstm = Lstm(model_params[\"latent_size\"], model_params[\"hidden_size\"], model_params[\"num_layers\"])\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "lstm_opt = nn.Adam(lstm.trainable_params(), optimizer_params[\"lr\"], weight_decay=optimizer_params[\"weight_decay\"])\n",
    "if use_ascend:\n",
    "    from mindspore.amp import DynamicLossScaler, auto_mixed_precision, all_finite\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(lstm, 'O1')\n",
    "else:\n",
    "    loss_scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a08fc",
   "metadata": {},
   "source": [
    "## LSTM dataset loading and processing\n",
    "\n",
    "The LSTM network dataset is obtained by the CAE encoder, and data sinking settings are performed after creating the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6e5aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "latent_true = cae_prediction()\n",
    "lstm_dataset, _ = create_lstm_dataset(latent_true, data_params[\"batch_size\"], data_params[\"time_size\"],\n",
    "                                      data_params[\"latent_size\"], data_params[\"time_window\"],\n",
    "                                      data_params[\"gaussian_filter_sigma\"])\n",
    "\n",
    "# data sink\n",
    "sink_process = data_sink(train_step, lstm_dataset, sink_size=1)\n",
    "train_data_size = lstm_dataset.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab5ec56",
   "metadata": {},
   "source": [
    "## LSTM training\n",
    "\n",
    "Build forward_fn and train_step, start training the LSTM network and visualize the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89b97708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid:1250\n",
      "====================Start lstm train=======================\n",
      "epoch: 1 train loss: 3.9012916 epoch time: 7.68s\n",
      "epoch: 2 train loss: 5.255037 epoch time: 4.16s\n",
      "epoch: 3 train loss: 3.9790413 epoch time: 4.25s\n",
      "epoch: 4 train loss: 4.9073987 epoch time: 4.19s\n",
      "epoch: 5 train loss: 4.960736 epoch time: 4.20s\n",
      "...\n",
      "epoch: 4396 train loss: 0.0003251157 epoch time: 4.15s\n",
      "epoch: 4397 train loss: 0.0002166091 epoch time: 4.16s\n",
      "epoch: 4398 train loss: 0.00026683844 epoch time: 4.19s\n",
      "epoch: 4399 train loss: 0.00017061326 epoch time: 4.21s\n",
      "epoch: 4400 train loss: 0.00028196868 epoch time: 4.11s\n",
      "====================End lstm train=======================\n"
     ]
    }
   ],
   "source": [
    "# Define forward function\n",
    "def forward_fn(data, label):\n",
    "    logits = lstm(data)\n",
    "    loss = loss_fn(logits, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "# Get gradient function\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, lstm_opt.parameters, has_aux=False)\n",
    "\n",
    "@jit\n",
    "def train_step(data, label):\n",
    "    loss, grads = grad_fn(data, label)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "        if all_finite(grads):\n",
    "            grads = loss_scaler.unscale(grads)\n",
    "    loss = ops.depend(loss, lstm_opt(grads))\n",
    "    return loss\n",
    "\n",
    "print(f\"====================Start lstm train=======================\")\n",
    "train_loss = []\n",
    "for epoch in range(1, optimizer_params[\"epochs\"] + 1):\n",
    "    local_time_beg = time.time()\n",
    "    lstm.set_train()\n",
    "    epoch_train_loss = 0\n",
    "    for _ in range(train_data_size):\n",
    "        epoch_train_loss = ops.squeeze(sink_process(), axis=())\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    print(f\"epoch: {epoch} train loss: {epoch_train_loss} epoch time: {time.time() - local_time_beg:.2f}s\")\n",
    "\n",
    "    if epoch % optimizer_params[\"save_ckpt_interval\"] == 0:\n",
    "        save_checkpoint(lstm, f\"{ckpt_dir}/lstm_{epoch}.ckpt\")\n",
    "print(f\"=====================End lstm train========================\")\n",
    "plot_train_loss(train_loss, summary_dir, optimizer_params[\"epochs\"], \"lstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aac646",
   "metadata": {},
   "source": [
    "## Visualization of predicted flow field results\n",
    "\n",
    "Run cae_lstm_prediction.py to view the prediction results of the CAE-LSTM reduced order model\n",
    "\n",
    "The following figures show the actual flow field, the predicted results of the CAE-LSTM network, and the corresponding average relative error. The error of CAE-LSTM prediction results is greater than that of CAE reconstruction because the former has more LSTM evolution error than the latter, but the overall prediction time error remains below 0.04, meeting the accuracy requirements of flow field prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ba22d",
   "metadata": {},
   "source": [
    "<figure class=\"harf\">\n",
    "    <img src=\"./images/true2.gif\" title=\"cae_prediction\" width=\"300\"/>\n",
    "    <img src=\"./images/cae_lstm.gif\" title=\"cae_lstm_prediction\" width=\"300\"/>\n",
    "    <img src=\"./images/cae_lstm_error.png\" title=\"cae_lstm_error\" width=\"300\"/>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
